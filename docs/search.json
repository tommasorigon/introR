[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "L’insegnamento di Analisi Statistica Multivariata (15 CFU) è articolato nelle seguenti parti:\nNota: i dettagli legati alle propedeuticità, alla registrazione del voto, al calendario degli esami e al salto d’appello sono spiegate nella pagina Elearning di Analisi Statistica Multivariata."
  },
  {
    "objectID": "index.html#materiale-didattico",
    "href": "index.html#materiale-didattico",
    "title": "R per l’analisi statistica multivariata",
    "section": "Materiale didattico",
    "text": "Materiale didattico\nIl materiale didattico di ciascuna lezione è scaricabile utilizzando i collegamenti ipertestuali. Si precisa che questa pagina web è soggetta a modifiche, quindi si prega di controllare l’ultima versione aggiornata.\n\nIl software R\n\nR è un software open source ed è possibile scaricarlo al link https://cloud.r-project.org.\nL’uso di Rstudio è facoltativo in questo corso, anche se fortemente consigliato. È possibile scaricarlo al link https://rstudio.com/products/rstudio/.\nLa documentazione del software R è parte integrante del materiale didattico.\n\n\n\nTesti di riferimento\n\nAlbert, J. & M. Rizzo (2012). R by Example. Springer.\n\nRobert, C. & G. Casella (2010). Introducing Monte Carlo Methods with R. Springer\n\n\n\nTesti di consultazione\n\nIl materiale didattico aggiuntivo fornito su questa pagina web.\nAdler, J. (2012). R in a nutshell. O’Reilly.\nGrolemund, G. & Wickham, H. (2016). R for Data Science. O’Reilly.\nVenables, W. N., Smith D. M. & the R Core Team (2021). An Introduction to R.\n\n\n\nMateriale didattico\nLa sigla AR corrisponde al libro di Albert & Rizzo. La sigla RC corrisponde al libro Robert & Casella.\n\n\n\nArgomenti\nMateriale didattico\nMateriale aggiuntivo\nSezioni libro di testo\n\n\n\n\nIntroduzione al corso\nUnità introduttiva\n\n\n\n\n\nINTRODUZIONE AD R\n\n\n\n\nA-B-C: calcolo scientifico ed algebra lineare\nUnità A\nUnità A (Python)\nCodice R\nAR §1.1, §1.3, §A1 — §A3\n\n\nElementi di programmazione\nUnità B\nCodice R\nAR §1.2, §1.6 — §1.8\n\n\nI dataframes\nUnità C\nCodice R\nAR §1.4 — §1.5\n\n\nEsercizi\nEsercizi 1\nsoluzione.R\n\n\n\n\nSTATISTICA DESCRITTIVA\n\n\n\n\nAnalisi descrittiva dei dati dde\nUnità D\nCodice R\nAR §2.1 — §2.3, §2.7\n\n\nAnalisi descrittiva dei dati emoglobina\nUnità E\nCodice R\nAR §2.1 — §2.3, §2.7\n\n\nEsercitazione\nUnità F\nCodice R\nAR 7.1, §7.2\n\n\nAnalisi descrittiva dei dati titanic\nUnità G\nCodice R\nAR §3.1 — §3.5\n\n\nEsercizi\nEsercizi 2\nsoluzione.R\n\n\n\n\nCALCOLO DELLE PROBABILITÀ\n\n\n\n\nVariabili aleatorie\nUnità H\nCodice R\nRC §2.1, §2.2\n\n\nMetodi Monte Carlo\nUnità I\nCodice R\nAR §11.1 — §11.5, §13.1, §13.2; RC §3.1, §3.2\n\n\nEsercizi\nEsercizi 3\nsoluzione.R\n\n\n\n\nINFERENZA STATISTICA\n\n\n\n\nMetodi numerici per l’analisi di verosimiglianza\nUnità K\nCodice R\nRC §5.1, §5.2\n\n\nProprietà degli stimatori\nUnità M\nCodice R\nAR §13.3\n\n\nEsercizi\nEsercizi 4\nsoluzione.R\n\n\n\n\nLEZIONI AGGIUNTIVE\n\n\n\n\nCasinò, roulette e metodi Monte Carlo\nUnità J\nCodice R\nAR §11.2\n\n\nMinimi quadrati non lineari\nUnità L\nCodice R\n\n\n\n\nESAMI PASSATI\n\n\n\n\nEsame 22 Febbraio 2022\nEsame\nsoluzione.R\n\n\n\nEsame 4 Febbraio 2022\nEsame\nsoluzione.R\n\n\n\nEsame 19 Novembre 2021\nEsame\nsoluzione.R\n\n\n\nEsame 22 Luglio 2021\nEsame\nsoluzione.R\n\n\n\nEsame 30 Giugno 2021\nEsame\nsoluzione.R\n\n\n\nEsame 24 Febbraio 2021\nEsame\nsoluzione.R\n\n\n\nEsame 08 Febbraio 2021\nEsame\nsoluzione.R\n\n\n\n\n\n\nApprofondimenti\n\nArticoli scientifici (in inglese)\n\nHyndman, R. J. and Yanan, F. (1996). Sample quantiles in statistical packages. The American Statistician 50(4), 361–365.\nHitchcock (2003). A history of the Metropolis-Hastings algorithm. The American Statistician 57(4), 254–257.\nOldford (2016). Self-calibrating quantile–quantile plots. The American Statistician 70(1), 74–90."
  },
  {
    "objectID": "index.html#modalità-desame",
    "href": "index.html#modalità-desame",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modalità d’esame",
    "text": "Modalità d’esame\nL’esame si svolge tramite computer e consiste tipicamente in \\(3\\) esercizi da svolgere in R. L’esame si svolgerà sulla Piattaforma Esami Informatizzati.\nLo studente all’esame può consultare sia la documentazione ufficiale di R che il codice utilizzato a lezione, disponibile a questo link.\nPer visionare la prova, è possibile venire a ricevimento. Per ulteriori informazioni relative alla registrazione del voto, al calendario delle verbalizzazioni e al salto d’appello si visiti la pagina elearning di Analisi Statistica Multivariata."
  },
  {
    "objectID": "index.html#propedeuticità",
    "href": "index.html#propedeuticità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Propedeuticità",
    "text": "Propedeuticità\nSi veda la pagina elearning di Analisi Statistica Multivariata."
  },
  {
    "objectID": "index.html#ricevimento",
    "href": "index.html#ricevimento",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ricevimento",
    "text": "Ricevimento\nPer fissare un appuntamento, si prega di contattare il docente in anticipo via posta elettronica all’indirizzo tommaso.rigon@unimib.it. Il ricevimento è fissato ogni martedì alle ore 17.30."
  },
  {
    "objectID": "lezioni/un_G.html",
    "href": "lezioni/un_G.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Dati qualitativi\nTabelle di contingenza\nDistribuzioni condizionate\nIndipendenza e indice di connessione \\(\\chi^2\\)\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_G.html#descrizione-del-problema",
    "href": "lezioni/un_G.html#descrizione-del-problema",
    "title": "R per l’analisi statistica multivariata",
    "section": "Descrizione del problema",
    "text": "Descrizione del problema\nDopo il disastro del Titanic, una commissione d’inchiesta del British Board of Trade ha compilato una lista di tutti i 1316 passeggeri includendo le seguenti informazioni:\n\nl’esito (salvato, non salvato)\nla classe (I, II, III) in cui viaggiavano\nil sesso, l’età, etc.\n\nIn questa unità ci limitiamo a considerare le informazioni sull’esito e la classe.\n\n\n\n\n\n\nNota\n\n\n\nOvviamente, si tratta degli stessi dati considerati nell’unità O del corso Statistica I."
  },
  {
    "objectID": "lezioni/un_G.html#importazione-dei-dati-titanic",
    "href": "lezioni/un_G.html#importazione-dei-dati-titanic",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione dei dati titanic",
    "text": "Importazione dei dati titanic\nCome fatto in precedenza, anzitutto è necessario scaricare il file titanic.csv e salvarlo nel proprio computer. Link al file\n\ntitanic <- read.table(\"../dataset/titanic.csv\", header = TRUE, sep = \",\", stringsAsFactors = TRUE)\n\nIn alternativa, possiamo semplice ottenerli usando il link:\n\npath <- \"https://tommasorigon.github.io/introR/data/titanic.csv\"\ntitanic <- read.table(path, header = TRUE, sep = \",\", stringsAsFactors = TRUE)\n\n\nstr(titanic)\n\n'data.frame':   1316 obs. of  2 variables:\n $ Salvato: Factor w/ 2 levels \"No\",\"Si\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Classe : Factor w/ 3 levels \"I\",\"II\",\"III\": 1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "lezioni/un_G.html#le-frequenze-assolute-e-relative-marginali",
    "href": "lezioni/un_G.html#le-frequenze-assolute-e-relative-marginali",
    "title": "R per l’analisi statistica multivariata",
    "section": "Le frequenze assolute e relative (marginali)",
    "text": "Le frequenze assolute e relative (marginali)\nPossiamo ottenere le frequenze assolute (marginali) delle due variabili usando il comando summary:\n\nsummary(titanic)\n\n Salvato  Classe   \n No:817   I  :325  \n Si:499   II :285  \n          III:706  \n\n\nOvviamente, possiamo ottenere le frequenze assolute e relative anche usando il comando table. Ad esempio per la variabile classe, possiamo utilizzare:\n\nfreq_abs_classe <- table(titanic$Classe)\nfreq_rel_classe <- freq_abs_classe / sum(freq_abs_classe)\ntab_summary <- cbind(freq_abs_classe, freq_rel_classe)\ntab_summary\n\n    freq_abs_classe freq_rel_classe\nI               325       0.2469605\nII              285       0.2165653\nIII             706       0.5364742"
  },
  {
    "objectID": "lezioni/un_G.html#frequenze-congiunte",
    "href": "lezioni/un_G.html#frequenze-congiunte",
    "title": "R per l’analisi statistica multivariata",
    "section": "Frequenze congiunte",
    "text": "Frequenze congiunte\nUna sintesi che possiamo operare consiste nel costruire una tabella, detta tabella di contingenza oppure tabella a doppia entrata.\nIn R si usa anche in questo caso il comando table, con due argomenti:\n\ntab <- table(titanic$Salvato, titanic$Classe)\ntab\n\n    \n       I  II III\n  No 122 167 528\n  Si 203 118 178\n\n\nIn questa tabella sono riportate le frequenze congiunte, ad esempio, il valore \\(203\\) rappresenta il numero di passeggeri che viaggiavano in I classe e che sono sopravvissuti."
  },
  {
    "objectID": "lezioni/un_G.html#tabella-di-contingenza",
    "href": "lezioni/un_G.html#tabella-di-contingenza",
    "title": "R per l’analisi statistica multivariata",
    "section": "Tabella di contingenza",
    "text": "Tabella di contingenza\nSiano \\(x\\) ed \\(y\\) due variabili aventi modalità \\(c_1,\\dots,c_h\\) e \\(d_1,\\dots,d_k\\), rispettivamente.\nUna tabella di contingenza (a due variabili) per le coppie di dati \\((x_1,y_1),\\dots,(x_n,y_n)\\) si presenta nella seguente forma:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabile \\(y\\)\n\n\n\n\n\n\n\nVariabile \\(x\\)\n\\(d_1\\)\n\\(\\dots\\)\n\\(d_j\\)\n\\(\\dots\\)\n\\(d_k\\)\nTotale\n\n\n\\(c_1\\)\n\\(n_{11}\\)\n\\(\\dots\\)\n\\(n_{1j}\\)\n\\(\\dots\\)\n\\(n_{1k}\\)\n\\(n_{1+}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(c_i\\)\n\\(n_{i1}\\)\n\\(\\dots\\)\n\\(n_{ij}\\)\n\\(\\dots\\)\n\\(n_{ik}\\)\n\\(n_{i+}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(c_h\\)\n\\(n_{h1}\\)\n\\(\\dots\\)\n\\(n_{hj}\\)\n\\(\\dots\\)\n\\(n_{hk}\\)\n\\(n_{h+}\\)\n\n\nTotale\n\\(n_{+1}\\)\n\\(\\dots\\)\n\\(n_{+j}\\)\n\\(\\dots\\)\n\\(n_{+k}\\)\n\\(n\\)\n\n\n\nLa frequenza \\(n_{ij}\\) è il numero di unità statistica che presentano contemporaneamente le modalità \\(c_i\\) e \\(d_j\\)."
  },
  {
    "objectID": "lezioni/un_G.html#tabella-di-contingenza-frequenze-relative",
    "href": "lezioni/un_G.html#tabella-di-contingenza-frequenze-relative",
    "title": "R per l’analisi statistica multivariata",
    "section": "Tabella di contingenza, frequenze relative",
    "text": "Tabella di contingenza, frequenze relative\nDividendo per \\(n\\) ciascun termine della precedente tabella, si ottiene inoltre:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabile \\(y\\)\n\n\n\n\n\n\n\nVariabile \\(x\\)\n\\(d_1\\)\n\\(\\dots\\)\n\\(d_j\\)\n\\(\\dots\\)\n\\(d_k\\)\nTotale\n\n\n\\(c_1\\)\n\\(f_{11}\\)\n\\(\\dots\\)\n\\(f_{1j}\\)\n\\(\\dots\\)\n\\(f_{1k}\\)\n\\(f_{1+}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(c_i\\)\n\\(f_{i1}\\)\n\\(\\dots\\)\n\\(f_{ij}\\)\n\\(\\dots\\)\n\\(f_{ik}\\)\n\\(f_{i+}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(c_h\\)\n\\(f_{h1}\\)\n\\(\\dots\\)\n\\(f_{hj}\\)\n\\(\\dots\\)\n\\(f_{hk}\\)\n\\(f_{h+}\\)\n\n\nTotale\n\\(f_{+1}\\)\n\\(\\dots\\)\n\\(f_{+j}\\)\n\\(\\dots\\)\n\\(f_{+k}\\)\n\\(1\\)\n\n\n\nLa frequenza relativa \\(f_{ij} = n_{ij} / n\\) è quindi la frazione di osservazioni che presentano contemporaneamente le modalità \\(c_i\\) e \\(d_j\\)."
  },
  {
    "objectID": "lezioni/un_G.html#frequenze-congiunte-marginali",
    "href": "lezioni/un_G.html#frequenze-congiunte-marginali",
    "title": "R per l’analisi statistica multivariata",
    "section": "Frequenze congiunte & marginali",
    "text": "Frequenze congiunte & marginali\nLe tabelle descritte nei paragrafi precedenti si ottengono in R come segue:\n\naddmargins(tab) # Aggiunge le distribuzioni marginali (assolute)\n\n     \n         I   II  III  Sum\n  No   122  167  528  817\n  Si   203  118  178  499\n  Sum  325  285  706 1316\n\n\n\ntab_rel <- prop.table(tab) # Comando alternativo: table(tab) / sum(tab)\ntab_rel\n\n    \n              I         II        III\n  No 0.09270517 0.12689970 0.40121581\n  Si 0.15425532 0.08966565 0.13525836\n\n\n\naddmargins(tab_rel) # Aggiunge le distribuzioni marginali relative\n\n     \n               I         II        III        Sum\n  No  0.09270517 0.12689970 0.40121581 0.62082067\n  Si  0.15425532 0.08966565 0.13525836 0.37917933\n  Sum 0.24696049 0.21656535 0.53647416 1.00000000"
  },
  {
    "objectID": "lezioni/un_G.html#distribuzioni-condizionate-i",
    "href": "lezioni/un_G.html#distribuzioni-condizionate-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzioni condizionate I",
    "text": "Distribuzioni condizionate I\n\nDistribuzione condizionata \\((x \\mid y = d_j)\\)\nLa \\(j\\)-esima colonna mostra la distribuzione di \\(x\\) condizionata ad \\(y = d_j\\) oppure, equivalentemente, la distribuzione di \\(x\\) dato \\(y = d_j\\).\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuzione \\(x \\mid y = d_j\\)\n\\(c_1\\)\n\\(\\dots\\)\n\\(c_i\\)\n\\(\\dots\\)\n\\(c_h\\)\nTotale\n\n\n\n\nFrequenze assolute\n\\(n_{1j}\\)\n\\(\\dots\\)\n\\(n_{ij}\\)\n\\(\\dots\\)\n\\(n_{hj}\\)\n\\(n_{+j}\\)\n\n\nFrequenze relative\n\\(n_{1j} / n_{+j}\\)\n\\(\\dots\\)\n\\(n_{ij} / n_{+j}\\)\n\\(\\dots\\)\n\\(n_{hj} / n_{+j}\\)\n\\(1\\)\n\n\n\n\n\nDistribuzione condizionata \\((y \\mid x = c_i)\\)\nLa \\(i\\)-esima riga mostra la distribuzione di \\(y\\) condizionata ad \\(x = c_i\\) oppure, equivalentemente, la distribuzione di \\(y\\) dato \\(x = c_i\\).\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuzione \\(y \\mid x = c_i\\)\n\\(d_1\\)\n\\(\\dots\\)\n\\(d_j\\)\n\\(\\dots\\)\n\\(d_k\\)\nTotale\n\n\n\n\nFrequenze assolute\n\\(n_{i1}\\)\n\\(\\dots\\)\n\\(n_{ij}\\)\n\\(\\dots\\)\n\\(n_{ik}\\)\n\\(n_{i+}\\)\n\n\nFrequenze relative\n\\(n_{i1} / n_{i+}\\)\n\\(\\dots\\)\n\\(n_{ij} / n_{i+}\\)\n\\(\\dots\\)\n\\(n_{ik} / n_{i+}\\)\n\\(1\\)"
  },
  {
    "objectID": "lezioni/un_G.html#distribuzioni-condizionate-ii",
    "href": "lezioni/un_G.html#distribuzioni-condizionate-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzioni condizionate II",
    "text": "Distribuzioni condizionate II\nIl comando prop.table consente anche di calcolare le frequenze condizionate relative.\nLa distribuzione di ciascuna classe, condizionata all’esito è:\n\nprop.table(tab, 1)\n\n    \n             I        II       III\n  No 0.1493268 0.2044064 0.6462668\n  Si 0.4068136 0.2364729 0.3567134\n\n\nLa distribuzione di ciascun esito, condizionata alla classe è:\n\nprop.table(tab, 2)\n\n    \n             I        II       III\n  No 0.3753846 0.5859649 0.7478754\n  Si 0.6246154 0.4140351 0.2521246"
  },
  {
    "objectID": "lezioni/un_G.html#contingenze-ed-indice-chi2-di-pearson",
    "href": "lezioni/un_G.html#contingenze-ed-indice-chi2-di-pearson",
    "title": "R per l’analisi statistica multivariata",
    "section": "Contingenze ed indice \\(\\chi^2\\) di Pearson",
    "text": "Contingenze ed indice \\(\\chi^2\\) di Pearson\nLe contingenze sono pari alla differenza tra frequenze osservate e frequenze attese, sotto l’ipotesi di indipendenza: \\[\n(\\text{contingenza}_{ij}) = n_{ij} - \\hat{n}_{ij}, \\qquad i=1,\\dots,h,\\quad j=1,\\dots,k.\n\\]\nSi consulti l’unità O di Statistica I per la definizione di frequenze attese.\nL’indice di connessione \\(\\chi^2\\) è definito come \\[\n\\chi^2 = \\sum_{i=1}^h\\sum_{j=1}^k \\frac{(n_{ij} - \\hat{n}_{ij})^2}{\\hat{n}_{ij}} = n\\left(\\sum_{i=1}^h\\sum_{j=1}^k\\frac{f_{ij}^2}{f_{i+}f_{+j}} - 1\\right).\n\\]\nSi scriva una funzione R chiamata chi_squared(x, y) che calcola l’indice \\(\\chi^2\\) di Pearson.\n\nSoluzione\n\nchi_squared <- function(x, y) {\n  nn <- table(x, y)\n  n <- sum(nn)\n  ff <- nn / n # Frequenze relative congiunte\n  f_x <- table(x) / n # Frequenze relative marginali di x\n  f_y <- table(y) / n # Frequenze relative marginali di y\n  S <- 0\n  for (i in 1:length(f_x)) {\n    for (j in 1:length(f_y)) {\n      S <- S + ff[i, j]^2 / (f_x[i] * f_y[j])\n    }\n  }\n  n * (S - 1)\n}\nchi_squared(titanic$Salvato, titanic$Classe)\n\n     No \n133.052 \n\n\n\n\nSoluzione (alternativa, più concisa)\nLa soluzione seguente fa uso delle funzioni apply e outer.\n\nchi_squared <- function(x, y) {\n  nn <- table(x, y)\n  n <- sum(nn)\n  ff <- nn / n\n  f_x <- apply(ff, 1, sum)\n  f_y <- apply(ff, 2, sum)\n  f_e <- outer(f_x, f_y) # Prodotto \"esterno\" tra vettori\n  n * (sum(ff^2 / f_e) - 1)\n}\nchi_squared(titanic$Salvato, titanic$Classe)\n\n[1] 133.052\n\n\nInfine, si noti che la funzione chisq.test produce lo stesso risultato.\n\nchisq.test(table(titanic$Salvato, titanic$Classe))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(titanic$Salvato, titanic$Classe)\nX-squared = 133.05, df = 2, p-value < 2.2e-16"
  },
  {
    "objectID": "lezioni/un_G.html#esercizio-riassuntivo",
    "href": "lezioni/un_G.html#esercizio-riassuntivo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo",
    "text": "Esercizio riassuntivo\n\nContingenze ed indice \\(\\chi^2\\) di Pearson\nLe contingenze sono pari alla differenza tra frequenze osservate e frequenze attese, sotto l’ipotesi di indipendenza: \\[\n(\\text{contingenza}_{ij}) = n_{ij} - \\hat{n}_{ij}, \\qquad i=1,\\dots,h,\\quad j=1,\\dots,k.\n\\]\nSi consulti l’unità O di Statistica I per la definizione di frequenze attese.\nL’indice di connessione \\(\\chi^2\\) è definito come \\[\n\\chi^2 = \\sum_{i=1}^h\\sum_{j=1}^k \\frac{(n_{ij} - \\hat{n}_{ij})^2}{\\hat{n}_{ij}} = n\\left(\\sum_{i=1}^h\\sum_{j=1}^k\\frac{f_{ij}^2}{f_{i+}f_{+j}} - 1\\right).\n\\]\nSi scriva una funzione R chiamata chi_squared(x, y) che calcola l’indice \\(\\chi^2\\) di Pearson.\n\n\nSoluzione\n\nchi_squared <- function(x, y) {\n  nn <- table(x, y)\n  n <- sum(nn)\n  ff <- nn / n # Frequenze relative congiunte\n  f_x <- table(x) / n # Frequenze relative marginali di x\n  f_y <- table(y) / n # Frequenze relative marginali di y\n  S <- 0\n  for (i in 1:length(f_x)) {\n    for (j in 1:length(f_y)) {\n      S <- S + ff[i, j]^2 / (f_x[i] * f_y[j])\n    }\n  }\n  n * (S - 1)\n}\nchi_squared(titanic$Salvato, titanic$Classe)\n\n     No \n133.052 \n\n\n\n\nSoluzione (alternativa, più concisa)\nLa soluzione seguente fa uso delle funzioni apply e outer.\n\nchi_squared <- function(x, y) {\n  nn <- table(x, y)\n  n <- sum(nn)\n  ff <- nn / n\n  f_x <- apply(ff, 1, sum)\n  f_y <- apply(ff, 2, sum)\n  f_e <- outer(f_x, f_y) # Prodotto \"esterno\" tra vettori\n  n * (sum(ff^2 / f_e) - 1)\n}\nchi_squared(titanic$Salvato, titanic$Classe)\n\n[1] 133.052\n\n\nInfine, si noti che la funzione chisq.test produce lo stesso risultato.\n\nchisq.test(table(titanic$Salvato, titanic$Classe))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(titanic$Salvato, titanic$Classe)\nX-squared = 133.05, df = 2, p-value < 2.2e-16"
  },
  {
    "objectID": "lezioni/un_F.html",
    "href": "lezioni/un_F.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Svolgimento di un tema d’esame di Statistica I\nModello di regressione lineare semplice\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_F.html#descrizione-del-problema",
    "href": "lezioni/un_F.html#descrizione-del-problema",
    "title": "R per l’analisi statistica multivariata",
    "section": "Descrizione del problema",
    "text": "Descrizione del problema\nPer \\(n = 17\\) luoghi nelle Alpi viene misurata la pressione atmosferica (inHg, ovvero “inches of mercury”) e la temperatura di ebollizione dell’acqua (in gradi Fahrenheit).\nI dati provengono da un esperimento condotto dal fisico scozzese Forbes nel 1857.\nForbes era interessato a stimare l’altitudine tramite la pressione. Tuttavia, il barometro all’epoca era uno strumento pesante e costoso.\nIn montagna infatti l’acqua bolle ad una temperatura diversa, per cui è possibile cercare di stimare la pressione a partire dalla temperatura di ebollizione.\n\n\n\n\n\n\nNota\n\n\n\nI dati seguenti sono gli stessi dell’esame di Statistica I del 11 Novembre 2020, che trovate sul sito web."
  },
  {
    "objectID": "lezioni/un_F.html#importazione-dei-dati-forbes",
    "href": "lezioni/un_F.html#importazione-dei-dati-forbes",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione dei dati forbes",
    "text": "Importazione dei dati forbes\nCome fatto in precedenza, anzitutto è necessario scaricare il file forbes.csv e salvarlo nel proprio computer. Link al file\n\nforbes <- read.table(\"../dataset/forbes.csv\", header = TRUE, sep = \",\")\n\nIn alternativa, possiamo semplice ottenerli usando il link:\n\npath <- \"https://tommasorigon.github.io/introR/data/forbes.csv\"\nforbes <- read.table(path, header = TRUE, sep = \",\")\n\n\nstr(forbes)\n\n'data.frame':   17 obs. of  2 variables:\n $ bp  : num  194 194 198 198 199 ...\n $ pres: num  20.8 20.8 22.4 22.7 23.1 ..."
  },
  {
    "objectID": "lezioni/un_F.html#operazioni-preliminari",
    "href": "lezioni/un_F.html#operazioni-preliminari",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni preliminari",
    "text": "Operazioni preliminari\nPer motivi interpretativi, convertiamo la temperatura da gradi Farenheit a gradi Celsius, ricordando che\n\\[\n(\\text{``Fahrenheit''}) = 32 + \\frac{9}{5}(\\text{``Celsius''}).\n\\]\n\ncolnames(forbes) <- c(\"TempF\", \"Pressione\") # Cambio i nomi alle variabili\n\nforbes$TempC <- round((forbes$TempF - 32) * 5 / 9, 2) # Da Fahrenheit a Celsius\nsummary(forbes)\n\n     TempF         Pressione         TempC       \n Min.   :194.3   Min.   :20.79   Min.   : 90.17  \n 1st Qu.:199.4   1st Qu.:23.15   1st Qu.: 93.00  \n Median :201.3   Median :24.01   Median : 94.06  \n Mean   :203.0   Mean   :25.06   Mean   : 94.97  \n 3rd Qu.:208.6   3rd Qu.:27.76   3rd Qu.: 98.11  \n Max.   :212.2   Max.   :30.06   Max.   :100.11  \n\n\nCome mai approssimiamo i valori utilizzando round? Per motivi estetici: in questo modo si ottengono risultati identici alla prova d’esame di Statistica I."
  },
  {
    "objectID": "lezioni/un_F.html#istogramma",
    "href": "lezioni/un_F.html#istogramma",
    "title": "R per l’analisi statistica multivariata",
    "section": "Istogramma",
    "text": "Istogramma\n\n\n\n\n\n\nDomanda 1\n\n\n\nSi disegni un istogramma della variabile temperatura, scegliendo un numero appropriato di classi equispaziate e giustificandone la scelta.\nSi aggiungano a questi grafici gli “abbellimenti” grafici ritenuti necessari (nomi delle variabili, titolo, etc).\n\n\n\nSoluzione\nPossiamo decidere di specificare in autonomia gli intervalli delle classi oppure di lasciare ad R questa scelta.\n\npar(mfrow = c(1, 2)) # Divido la finestra grafica in 2 parti\n\n# Opzione 1, per un totale di 6 classi equispaziate\nhist(forbes$TempC) # Equivalente a: hist(forbes$TempC, breaks = \"sturges\") \n\n# Opzione 2, definisco manualmente 5 classi equispaziate\nbreaks <- c(90, 92.5, 95, 97.5, 100, 102.5)\nhist(forbes$TempC, breaks = breaks)\n\n\n\n\nLa soluzione di sinistra fa uso di \\(6\\) classi. Viceversa, quella di sinistra fa uso di \\(5\\) classi, come nella soluzione dell’esame."
  },
  {
    "objectID": "lezioni/un_F.html#indici-di-posizione",
    "href": "lezioni/un_F.html#indici-di-posizione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione",
    "text": "Indici di posizione\n\n\n\n\n\n\nDomanda 2\n\n\n\nSi ottengano la media aritmetica di entrambe le variabili tempC e pressione. Quanto vale la temperatura di ebollizione media espressa in gradi Fahrenheit? Si risponda senza calcolare tutti i valori della variabile tempF.\n\n\n\nSoluzione\nAbbiamo già calcolato la medie tramite il comando summary, per completezza:\n\n# Prima parte della domanda\nmean(forbes$TempC)\n\n[1] 94.97353\n\nmean(forbes$Pressione)\n\n[1] 25.05882\n\n\n\n# Seconda parte della domanda \n32 + 9 / 5 * mean(forbes$TempC) # Utilizzo proprietà della media\n\n[1] 202.9524\n\nmean(forbes$TempF) # Non richiesto, calcola la media a partire dai dai dati trasformati\n\n[1] 202.9529\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nCome mai le medie calcolate nella seconda parte differiscono leggermente? A cosa può essere dovuto?"
  },
  {
    "objectID": "lezioni/un_F.html#indici-di-variabilità",
    "href": "lezioni/un_F.html#indici-di-variabilità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di variabilità",
    "text": "Indici di variabilità\n\n\n\n\n\n\nDomanda 3\n\n\n\nSi ottenga la varianza delle variabili tempC e pressione.\n\n\n\nSoluzione\nDato che tornerà utile in seguito, definiamo la funzione my_var che calcola la varianza.\n\n# Si, la funzione è definita in un'unica riga e non c'è nulla di male in questo\nmy_var <- function(x) mean(x^2) - mean(x)^2 \n\n# Calcolo delle due varianze\nmy_var(forbes$TempC)\n\n[1] 9.630811\n\nmy_var(forbes$Pressione)\n\n[1] 8.584575\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi ottengano i momenti secondi delle variabili tempC e pressione."
  },
  {
    "objectID": "lezioni/un_F.html#covarianza-e-correlazione",
    "href": "lezioni/un_F.html#covarianza-e-correlazione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Covarianza e correlazione",
    "text": "Covarianza e correlazione\n\n\n\n\n\n\nDomanda 4\n\n\n\nSi disegni un opportuno grafico che aiuti a comprendere la relazione tra le due variabili. Si calcoli quindi la correlazione.\n\n\n\nSoluzione\nPer la prima parte della domanda, abbiamo bisogno del nuovo comando plot, che può essere usato (tra le altre cose!) per costruire un diagramma a dispersione.\nForniamo due versioni dello stesso grafico; la seconda contiene dei miglioramenti estetici.\n\npar(mfrow = c(1, 1)) # Vogliamo mostrare un grafico alla volta\nplot(forbes$TempC, forbes$Pressione)\n\n\n\nplot(forbes$TempC, forbes$Pressione, pch = 16, xlab = \"Temperatura\", ylab = \"Pressione\")\n\n\n\n\nÈ quindi evidente che i dati siano circa (anche se non perfettamente) allineati\nPer la seconda parte di domanda (correlazione), dobbiamo anzitutto ottenere la covarianza tra due variabili.\nLa covarianza tra due insiemi di dati \\(x_1,\\dots,x_n\\) e \\(y_1,\\dots,y_n\\) è definita come\n\\[\n\\text{cov}(x,y) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) = \\frac{1}{n}\\sum_{i=1}^nx_i y_i - \\bar{x}\\bar{y}.\n\\]\nDefiniamo quindi la funzione my_cov, che calcola appunto la covarianza:\n\nmy_cov <- function(x, y) mean(x * y) - mean(x) * mean(y)\nmy_cov(forbes$TempC, forbes$Pressione) # = my_cov(forbes$Pressione, forbes$TempC)\n\n[1] 9.067404\n\n\nIn R esiste anche il comando cov che, come nel caso della varianza, divide la sommatoria per \\((n - 1)\\) e non \\(n\\) per motivi legati all’inferenza statistica:\n\ncov(forbes$Pressione, forbes$TempC) # = 17 / 16 * my_cov(forbes$TempC, forbes$Pressione)\n\n[1] 9.634117\n\n\nL’indice di è definito come: \\[\n\\rho = \\frac{\\text{cov}(x,y)}{\\sqrt{\\text{var}(x) \\text{var}(y)}}.\n\\]\nPertanto, possiamo calcolare la correlazione nei modo seguente:\n\nmy_cov(forbes$TempC, forbes$Pressione) / sqrt(my_var(forbes$TempC) * my_var(forbes$Pressione))\n\n[1] 0.9972227\n\ncov(forbes$TempC, forbes$Pressione) / sqrt(var(forbes$TempC) * var(forbes$Pressione))\n\n[1] 0.9972227\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nCome mai i risultati dei due comandi coincidono? Si verifichi questo fatto svolgendo analiticamente (carta e penna) i conti.\n\n\nIn R esiste anche il comando cor, che permette di ottenere la correlazione\n\ncorrelation <- cor(forbes$TempC, forbes$Pressione)\ncorrelation\n\n[1] 0.9972227"
  },
  {
    "objectID": "lezioni/un_F.html#modello-di-regressione-lineare",
    "href": "lezioni/un_F.html#modello-di-regressione-lineare",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello di regressione lineare",
    "text": "Modello di regressione lineare\n\n\n\n\n\n\nDomanda 5\n\n\n\nSi ottenga la retta ai minimi quadrati per la relazione tra tempC e pressione e la si disegni nel grafico ottenuto in precedenza.\n\n\n\nSoluzione\nAnzitutto ricordiamo che in un modello lineare del tipo \\(y_i = \\alpha + \\beta x_i + \\epsilon_i\\), le stime ai minimi quadrati sono pari a \\[\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\:\\bar{x}, \\qquad \\hat{\\beta}  = \\frac{\\text{cov}(x,y)}{\\text{var}(x)}.\n\\]\nPertanto, possiamo calcolare la correlazione nei modo seguente:\n\n# Coefficiente angolare\nbeta_hat <- my_cov(forbes$TempC, forbes$Pressione) / my_var(forbes$TempC)\n# Intercetta\nalpha_hat <- mean(forbes$Pressione) - mean(forbes$TempC) * beta_hat\n\nc(alpha_hat, beta_hat)\n\n[1] -64.3587103   0.9414995\n\n\n\nplot(forbes$TempC, forbes$Pressione, pch = 16, xlab = \"Temperatura\", ylab = \"Pressione\")\nabline(a = alpha_hat, b = beta_hat)\n\n\n\n\n\n\n\n\n\n\nDomanda 6\n\n\n\nIn base al modello stimato, se la temperatura di ebollizione dell’acqua è pari 97 gradi Celsius, a quanto è pari la pressione?\n\n\n\n\nSoluzione\nUtilizzando le stime ottenute, possiamo calcolare rapidamente i valori previsti:\n\nx <- seq(from = 90, to = 100, length = 20)\nalpha_hat + beta_hat * x\n\n [1] 20.37625 20.87177 21.36730 21.86283 22.35835 22.85388 23.34940 23.84493\n [9] 24.34046 24.83598 25.33151 25.82703 26.32256 26.81809 27.31361 27.80914\n[17] 28.30467 28.80019 29.29572 29.79124\n\n\nIn particolare, quando tempC = 97 si ha che:\n\nalpha_hat + beta_hat * 97\n\n[1] 26.96674\n\n\n\n\n\n\n\n\nDomanda 7\n\n\n\nSi ottenga un indice di bontà di adattamento ai dati della curva ottenuta.\n\n\n\n\nSoluzione\nIl coefficiente \\(R^2\\) per un modello di regressione lineare semplice è definito come: \\[\nR^2 = 1 - \\frac{\\text{var}(r)}{\\text{var}(y)} = \\rho^2,\n\\] dove \\(r_1,\\dots,r_n\\) sono i residui.\nAnzitutto quindi calcoliamo i residui:\n\nresiduals <- forbes$Pressione - (alpha_hat + beta_hat * forbes$TempC)\n\nIl coefficiente \\(R^2\\) può quindi essere ottenuto in due modi diversi:\n\ncorrelation^2\n\n[1] 0.994453\n\n1 - my_var(residuals) / my_var(forbes$Pressione)\n\n[1] 0.994453"
  },
  {
    "objectID": "lezioni/un_F.html#esercizio-riassuntivo",
    "href": "lezioni/un_F.html#esercizio-riassuntivo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo",
    "text": "Esercizio riassuntivo\nSi consideri l’esame di Statistica I del 28 Gennaio 2021, disponibile a questo link\nSi risolva l’esercizio 2 dell’esame usando il software R.\n\n\n\n\n\n\nSuggerimento\n\n\n\nPer poter importare piccole quantità di dati in R, è possibile usare il comando scan."
  },
  {
    "objectID": "lezioni/un_D.html",
    "href": "lezioni/un_D.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Frequenze assolute, relative\nLa funzione di ripartizione\nRappresentazioni grafiche (boxplot, istogrammi)\nIndici di posizione (media, mediana, quantili)\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_D.html#il-problema-epidemiologico",
    "href": "lezioni/un_D.html#il-problema-epidemiologico",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il problema epidemiologico",
    "text": "Il problema epidemiologico\nIl DDT è estremamente efficace contro le zanzare da malaria ed è pertanto largamente usato in zone in cui la malaria è endemica.\nAl tempo stesso, il DDT potrebbe costituire un rischio per la salute, specialmente nel caso di donne in gravidanza.\nPer un campione di \\(n = 2312\\) donne in gravidanza, viene misurato il DDE, ovvero una sostanza connessa al DDT, presente nel siero materno durante il terzo trimestre della gravidanza.\nLa variabile GAD (Gestational Age at Delivery) misura invece a quale giorno della gravidanza è avvenuto il parto.\n\n\n\n\n\n\nDomanda di ricerca\n\n\n\nLa quantità di DDE è maggiore tra donne che hanno partorito prematuramente?"
  },
  {
    "objectID": "lezioni/un_D.html#importazione-dei-dati-dde",
    "href": "lezioni/un_D.html#importazione-dei-dati-dde",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione dei dati dde",
    "text": "Importazione dei dati dde\nPer poter procedere con i prossimi comandi, è necessario scaricare il file dde.csv e salvarlo nel proprio computer. Link al file\n\ndde <- read.table(\"../dataset/dde.csv\", header = TRUE, sep = \",\")\n\nIn alternativa, possiamo semplice ottenerli usando il link:\n\ndde <- read.table(\"https://tommasorigon.github.io/introR/dataset/dde.csv\",\n  header = TRUE, sep = \",\"\n) # Scarica il file da internet\n\n\nstr(dde)\n\n'data.frame':   2312 obs. of  2 variables:\n $ DDE: num  24.6 15.6 54.8 15 33.5 ...\n $ GAD: int  292 289 252 285 281 283 277 284 293 277 ...\n\n\nSi noti la presenza di una nuova tipologia di variabile, ovvero integer, ovvero numeri interi."
  },
  {
    "objectID": "lezioni/un_D.html#operazioni-preliminari",
    "href": "lezioni/un_D.html#operazioni-preliminari",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni preliminari",
    "text": "Operazioni preliminari\nUn totale di \\(361\\) donne hanno partorito prematuramente, ovvero prima della conclusione della 37a settimana.\nPer verificare questo, dividiamo la variabile DDE in due gruppi.\n\ndde_preterm <- dde$DDE[dde$GAD < 37 * 7] # Gruppo parto prematuro\ndde_non_preterm <- dde$DDE[dde$GAD >= 37 * 7] # Gruppo parto non prematuro\n\nlength(dde_preterm) # Numerosità campionaria gruppo 1\n\n[1] 361\n\nlength(dde_non_preterm) # Numerosità campionaria gruppo 2\n\n[1] 1951\n\n\nIl primo gruppo (variabile dde_preterm) fa riferimento ai parti prematuri e comprende \\(361\\) osservazioni.\nIl secondo gruppo (variabile dde_non_preterm) considera i parti non prematuri e comprende le restanti \\(1951\\) osservazioni."
  },
  {
    "objectID": "lezioni/un_D.html#suddivisione-in-intervalli",
    "href": "lezioni/un_D.html#suddivisione-in-intervalli",
    "title": "R per l’analisi statistica multivariata",
    "section": "Suddivisione in intervalli",
    "text": "Suddivisione in intervalli\nPer sintetizzare i dati tramite frequenze, possiamo suddividere l’intervallo che contiene tutti i valori osservati (ovvero \\((0,180]\\)) in un certo numero di sotto-intervalli.\nIn primo luogo, definiamo i \\(10\\) sotto-intervalli di lunghezza \\(18\\), chiusi a destra tramite il comando cut:\n\nbreaks <- 18 * (0:10) # Definizione degli intervalli. Usiamo 10 intervalli di lunghezza 18.\n\ndde_preterm_class <- cut(dde_preterm, breaks = breaks)\ndde_non_preterm_class <- cut(dde_non_preterm, breaks = breaks)\n\nhead(dde_preterm_class)\n\n[1] (54,72] (18,36] (18,36] (0,18]  (0,18]  (18,36]\n10 Levels: (0,18] (18,36] (36,54] (54,72] (72,90] (90,108] ... (162,180]\n\n\nIn questo modo, abbiamo trasformato una variabile numeric in una variabile factor."
  },
  {
    "objectID": "lezioni/un_D.html#frequenze-assolute",
    "href": "lezioni/un_D.html#frequenze-assolute",
    "title": "R per l’analisi statistica multivariata",
    "section": "Frequenze assolute",
    "text": "Frequenze assolute\nLe frequenze assolute \\(n_1,\\dots, n_k\\) si ottengono quindi tramite il comando table, il quale ha senso di essere applicato su variabili di tipo factor.\nLa funzione table conteggia quante volte una determinata modalità compare nel vettore.\nEseguiamo questa operazione per entrambi i gruppi di dati:\n\nfreq_abs_preterm <- table(dde_preterm_class)\nfreq_abs_preterm\n\ndde_preterm_class\n   (0,18]   (18,36]   (36,54]   (54,72]   (72,90]  (90,108] (108,126] (126,144] \n       68       164        65        34        14        10         3         1 \n(144,162] (162,180] \n        1         1 \n\nfreq_abs_non_preterm <- table(dde_non_preterm_class)\nfreq_abs_non_preterm\n\ndde_non_preterm_class\n   (0,18]   (18,36]   (36,54]   (54,72]   (72,90]  (90,108] (108,126] (126,144] \n      573       906       308        91        40        19         6         5 \n(144,162] (162,180] \n        2         1"
  },
  {
    "objectID": "lezioni/un_D.html#frequenze-relative",
    "href": "lezioni/un_D.html#frequenze-relative",
    "title": "R per l’analisi statistica multivariata",
    "section": "Frequenze relative",
    "text": "Frequenze relative\nUna volta ottenute le frequenze assolute, è possibile calcolare le frequenze relative.\nSebbene sia possibile usare comando prop.table (lo re-incontreremo in seguito), qui seguiamo una via più diretta.\nSi ricordi infatti che \\(n = n_1 + \\cdots + n_k\\), pertanto possiamo ottenere le frequenze relative \\(f_j = n_j / n\\) come segue:\n\nfreq_rel_preterm <- freq_abs_preterm / sum(freq_abs_preterm)\nround(freq_rel_preterm, digits = 3)\n\ndde_preterm_class\n   (0,18]   (18,36]   (36,54]   (54,72]   (72,90]  (90,108] (108,126] (126,144] \n    0.188     0.454     0.180     0.094     0.039     0.028     0.008     0.003 \n(144,162] (162,180] \n    0.003     0.003 \n\nfreq_rel_non_preterm <- freq_abs_non_preterm / sum(freq_abs_non_preterm)\nround(freq_rel_non_preterm, digits = 3)\n\ndde_non_preterm_class\n   (0,18]   (18,36]   (36,54]   (54,72]   (72,90]  (90,108] (108,126] (126,144] \n    0.294     0.464     0.158     0.047     0.021     0.010     0.003     0.003 \n(144,162] (162,180] \n    0.001     0.001"
  },
  {
    "objectID": "lezioni/un_D.html#organizzazione-dei-risultati",
    "href": "lezioni/un_D.html#organizzazione-dei-risultati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Organizzazione dei risultati",
    "text": "Organizzazione dei risultati\nRaccogliamo quindi i risultati appena ottenuti all’interno di una matrice, per poterli visualizzare meglio.\n\ntab_summary <- cbind(\n  freq_abs_preterm, freq_abs_non_preterm,\n  freq_rel_preterm, freq_rel_non_preterm\n)\n\ncolnames(tab_summary) <- c(\n  \"n_j prematura\",\n  \"n_j non prematura\",\n  \"f_j prematura\",\n  \"f_j non prematura\"\n)\n\nround(tab_summary, 3) # Visualizzazione dei risultati\n\n          n_j prematura n_j non prematura f_j prematura f_j non prematura\n(0,18]               68               573         0.188             0.294\n(18,36]             164               906         0.454             0.464\n(36,54]              65               308         0.180             0.158\n(54,72]              34                91         0.094             0.047\n(72,90]              14                40         0.039             0.021\n(90,108]             10                19         0.028             0.010\n(108,126]             3                 6         0.008             0.003\n(126,144]             1                 5         0.003             0.003\n(144,162]             1                 2         0.003             0.001\n(162,180]             1                 1         0.003             0.001"
  },
  {
    "objectID": "lezioni/un_D.html#gli-istogrammi-i",
    "href": "lezioni/un_D.html#gli-istogrammi-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Gli istogrammi I",
    "text": "Gli istogrammi I\nL’istogramma consente di rappresentare graficamente una distribuzione di frequenza. Per rinfrescare la memoria, si ricordi che nella sua versione più semplice si pone:\n\\[\n\\begin{aligned}\n(\\text{base rettangoli}) &= (\\text{lunghezza intervalli}) \\\\\n(\\text{altezza rettangoli}) &= (\\text{frequenze assolute})\n\\end{aligned}\n\\]\nQuesta definizione non è appropriata se gli intervalli hanno dimensioni diverse.\nIn tal caso, è le altezze dei rettangoli devono essere proporzionali alla densità delle osservazioni nelle singole classi.\nRicapitolando, costruiremo gli istogrammi ponendo\n\\[\n\\begin{aligned}\n(\\text{base rettangoli}) &= (\\text{lunghezza intervalli}) \\\\\n(\\text{altezza rettangoli}) &= \\lambda \\times (\\text{densità}) = \\lambda \\times \\frac{(\\text{frequenze assolute}) }{(\\text{lunghezza intervalli})}\n\\end{aligned}\n\\]\ndove tipicamente si pone \\(\\lambda = 1/n\\)."
  },
  {
    "objectID": "lezioni/un_D.html#gli-istogrammi-ii",
    "href": "lezioni/un_D.html#gli-istogrammi-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Gli istogrammi II",
    "text": "Gli istogrammi II\nConcentriamoci inizialmente solo sul gruppo di nascite non premature, per capire il funzionamento della sintassi di R.\n\npar(mfrow = c(1, 2)) # Divide il grafico in due parti\n\n# Primo grafico, frequenze assolute\nhist(dde_non_preterm,\n  freq = TRUE,\n  breaks = 10, # Utilizzo 10 sotto-intervalli\n  # Da qui in poi stiamo solo aggiungendo dettagli estetici\n  main = \"Nascite non premature\",\n  xlab = \"DDE\",\n  ylab = \"Frequenze assolute\"\n)\n\n# Secondo grafico, densità\nhist(dde_non_preterm,\n  freq = FALSE, # NON vengono usate le frequenze\n  breaks = 10, # Utilizzo 10 sotto-intervalli\n  # Da qui in poi stiamo solo aggiungendo dettagli estetici\n  main = \"Nascite non premature\",\n  xlab = \"DDE\",\n  ylab = \"Densità\"\n)\n\n\n\n\nIstogramma basato sulle frequenze assolute (sinistra) e sulla densità (destra), solamente per il gruppo di nascite non premature."
  },
  {
    "objectID": "lezioni/un_D.html#gli-istogrammi-iii",
    "href": "lezioni/un_D.html#gli-istogrammi-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Gli istogrammi III",
    "text": "Gli istogrammi III\n\n\n\n\n\n\nWarning\n\n\n\nNel caso di intervalli non equispaziati, è obbligatorio utilizzare l’opzione freq = FALSE, altrimenti il grafico prodotto risulta privo di senso.\n\n\n\n# Definizione di intervalli NON equispaziati\nbreaks <- c(5 * 0:10, 70, 90, 110, 130, 150, 170, 190)\n\n# GRAFICO CORRETTO\nhist(dde_non_preterm,\n  freq = FALSE,\n  breaks = breaks,\n  # Da qui in poi stiamo solo aggiungendo dettagli estetici\n  main = \"GRAFICO CORRETTO\", xlab = \"DDE\", ylab = \"Densità\"\n)\n\n\n\n# GRAFICO ERRATO\nhist(dde_non_preterm,\n  freq = TRUE, # NON vengono usate le frequenze\n  breaks = breaks,\n  # Da qui in poi stiamo solo aggiungendo dettagli estetici\n  main = \"GRAFICO ERRATO\", xlab = \"DDE\", ylab = \"Frequenze assolute\"\n)\n\nWarning in plot.histogram(r, freq = freq1, col = col, border = border, angle =\nangle, : the AREAS in the plot are wrong -- rather use 'freq = FALSE'\n\n\n\n\n\nIl grafico di sinistra è corretto e fa uso della nozione di densità spiegata in precedenza. Il grafico di destra è errato.\nFortunatamente R ci avvisa tramite un warning che questa procedura è scorretta."
  },
  {
    "objectID": "lezioni/un_D.html#il-numero-di-intervalli",
    "href": "lezioni/un_D.html#il-numero-di-intervalli",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il numero di intervalli",
    "text": "Il numero di intervalli\nUn numero troppo basso di intervalli comporta una perdita di informazione.\nViceversa, un numero troppo alto di intervalli comporta una perdita di sintesi.\nSi tenga presente che il numero degli intervalli deve dipendere dal numero dei dati.\nSono state proposte varie formule per identificare il “numero ottimale” di intervalli. Vanno però prese come dei suggerimenti e non usate in maniera automatica.\nSturges. Il numero di intervalli, approssimato all’intero più vicino, è \\[\n(\\text{numero di intervalli}) = 1 + \\log_2{n}.\n\\]\nFreedman & Diaconis. Il numero di intervalli, approssimato all’intero più vicino, è \\[\n(\\text{numero di intervalli})  = \\frac{x_{(n)} - x_{(1)}}{2(\\mathcal{Q}_{0.75} - \\mathcal{Q}_{0.25})}n^{1/3}.\n\\]"
  },
  {
    "objectID": "lezioni/un_D.html#il-numero-di-intervalli-ii",
    "href": "lezioni/un_D.html#il-numero-di-intervalli-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il numero di intervalli II",
    "text": "Il numero di intervalli II\nIl numero “ottimale” di intervalli si può ottenere tramite i comandi seguenti:\n\nnclass.Sturges(dde_non_preterm) # Regola di Sturges\n\n[1] 12\n\nnclass.FD(dde_non_preterm) # Regola di Freedman e Diaconis\n\n[1] 54\n\n\n\n\n\n\n\n\nNota\n\n\n\nIl comando hist di R, se non viene specificato diversamente tramite l’opzione breaks, seleziona in automatico intervalli equispaziati tramite la regola di Sturges."
  },
  {
    "objectID": "lezioni/un_D.html#confronto-tra-le-due-distribuzioni",
    "href": "lezioni/un_D.html#confronto-tra-le-due-distribuzioni",
    "title": "R per l’analisi statistica multivariata",
    "section": "Confronto tra le due distribuzioni",
    "text": "Confronto tra le due distribuzioni\nQuesto grafico conclusivo consente finalmente di confrontare le due distribuzioni.\n\nhist(dde_non_preterm, # Gruppo nascite non-premature\n  freq = FALSE,\n  main = \"Nascite non premature\"\n)\n\n\n\nhist(dde_preterm, # Gruppo nascite premature\n  freq = FALSE,\n  main = \"Nascite premature\"\n)\n\n\n\n\nEventualmente, è possibile selezionare una regola diversa ponendo breaks = \"FD\".\nLa distribuzione di “nascite premature” risulta più spostata a destra."
  },
  {
    "objectID": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-i",
    "href": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione di ripartizione empirica I",
    "text": "La funzione di ripartizione empirica I\nUna seconda rappresentazione grafica di uso frequente è la cosiddetta funzione di ripartizione empirica \\(F(x)\\).\nSiano \\(x_1,\\dots,x_n\\) una collezione di dati, allora definiamo \\[\nF(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}(x_i \\le x),\n\\] dove \\(\\mathbb{1}(x_i \\le x)\\) è la funzione indicatrice e vale \\(1\\) se \\(x_i \\le x\\) e \\(0\\) se \\(x_i > x\\).\nIn R, si usa il comando ecdf (empirical cumulative distribution function), ad esempio:\n\necdf(dde_non_preterm)\n\nEmpirical CDF \nCall: ecdf(dde_non_preterm)\n x[1:1585] =    2.5,   2.95,   3.14,  ..., 161.11, 162.29"
  },
  {
    "objectID": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-ii",
    "href": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione di ripartizione empirica II",
    "text": "La funzione di ripartizione empirica II\nIl comando ecdf restituisce come oggetto una vera e propria funzione. Infatti:\n\nF_non_preterm <- ecdf(dde_non_preterm)\nF_non_preterm(c(20, 40, 60)) # Calcola la funzione di ripartizione empirica in 20, 40 e 60\n\n[1] 0.3618657 0.8077909 0.9390056\n\nsum(dde_non_preterm <= 40) / length(dde_non_preterm) # Comando \"manuale\" alternativo\n\n[1] 0.8077909\n\n\nPer farne un grafico, è inoltre sufficiente usare il comando plot:\n\npar(mfrow = c(1, 1))\nplot(ecdf(dde_non_preterm))"
  },
  {
    "objectID": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-ii-1",
    "href": "lezioni/un_D.html#la-funzione-di-ripartizione-empirica-ii-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione di ripartizione empirica II",
    "text": "La funzione di ripartizione empirica II\nPer poter confrontare le funzioni di ripartizione dei due gruppi, la sintassi è leggermente più elaborata:\n\nplot(ecdf(dde_preterm),\n  do.points = FALSE, col = \"blue\",\n  main = \"Blu: parto prematuro. Rosso: parto non prematuro\",\n  xlab = \"DDE\",\n  ylab = \"F(DDE)\"\n)\n\nplot(ecdf(dde_non_preterm), col = \"red\", add = TRUE) # Aggiungo un secondo gruppo\n\n\n\n\nL’opzione do.points = FALSE omette i ``pallini’’ nel grafico ed è stato aggiunta per ragioni esclusivamente estetiche."
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-la-media",
    "href": "lezioni/un_D.html#indici-di-posizione-la-media",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: la media",
    "text": "Indici di posizione: la media\nPer quantificare la differenza tra le due distribuzioni, vogliamo trovare le medie aritmetiche delle variabili dde_preterm e dde_non_preterm.\nIn R ovviamente esiste un comando apposito:\n\nmean(dde_preterm) # Media aritmetica di DDE per donne con parto prematuro\n\n[1] 36.20299\n\nmean(dde_non_preterm) # Media aritmetica di DDE per donne con parto regolare\n\n[1] 29.14199\n\n\nCome ormai ampiamente rilevato, notiamo che il DDE è presente in quantità maggiore tra le donne che hanno partorito prematuramente.\nLa media aritmetica poteva essere ottenuta anche a partire dai comandi che abbiamo incontrato nelle unità precedenti:\n\nn <- length(dde_preterm) # Numerosità campionaria di dde_preterm (=361)\nsum(dde_preterm) / n # Media aritmetica della variabile dde_preterm\n\n[1] 36.20299"
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-la-mediana-i",
    "href": "lezioni/un_D.html#indici-di-posizione-la-mediana-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: la mediana I",
    "text": "Indici di posizione: la mediana I\nLa mediana (Me) di una variabile è il valore centrale della distribuzione, ovvero:\n\\[\n\\text{Me} = \\begin{cases}x_{\\left(\\frac{n+1}{2}\\right)}, &\\qquad \\text{ se } n \\text{ è dispari},  \\\\[10pt] \\left(x_{(n/2)} + x_{(n/2+1)}\\right)/2,&\\qquad \\text{ se } n \\text{ è pari},\\end{cases}\n\\] dove \\(x_{(1)},\\dots,x_{(n)}\\) rappresenta il campione ordinato.\nIn R esiste un comando apposito:\n\nmedian(dde_preterm) # Mediana di DDE per donne con parto prematuro\n\n[1] 29.46\n\nmedian(dde_non_preterm) # Mediana di DDE per donne con parto regolare\n\n[1] 24.04\n\n\nSi noti (come mai?) che la funzione di ripartizione empirica, valutata nella mediana, è circa pari a 0.5.\n\nF_non_preterm(median(dde_non_preterm))\n\n[1] 0.5002563"
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-la-mediana-ii",
    "href": "lezioni/un_D.html#indici-di-posizione-la-mediana-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: la mediana II",
    "text": "Indici di posizione: la mediana II\nLa mediana di una variabile numerica si può anche ottenere “manualmente”.\n\nx <- c(10, 20, 25, 3.5, 28, 62)\nn <- length(x) # Numerosità campionaria\nn # Si noti che n = 6 è pari\n\n[1] 6\n\nx_sort <- sort(x) # Vettore ordinato dei valori di x\nx_sort\n\n[1]  3.5 10.0 20.0 25.0 28.0 62.0\n\npos_med_1 <- n / 2 # Elemento in posizione n/2\npos_med_2 <- n / 2 + 1 # Elemento in posizione n/2+1\n\n(x_sort[pos_med_1] + x_sort[pos_med_2]) / 2 # Mediana di x\n\n[1] 22.5\n\nmedian(x) # Ovviamente, il risultato deve coincidere con:\n\n[1] 22.5\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi ottenga la mediana “manualmente” nel caso in cui il vettore x ha un numero dispari di elementi."
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-i-quantili-i",
    "href": "lezioni/un_D.html#indici-di-posizione-i-quantili-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: i quantili I",
    "text": "Indici di posizione: i quantili I\nSiano \\(x_1,\\dots,x_n\\) un insieme di dati, sia \\(p \\in (0,1)\\) e sia \\(F(x)\\) la funzione di ripartizione empirica. Il quantile-\\(p\\) è quindi pari a\n\\[\n\\mathcal{Q}_p = \\inf\\{ x : F(x) \\ge p \\}.\n\\]\nIn R considerando \\(p = (0.1,0.25,0.75,0.9)\\), ovvero il primo decile, il primo quartile, il terzo quartile ed il nono decile, possiamo usare il comando quantile\n\nquantile(dde_preterm, probs = c(0.1, 0.25, 0.75, 0.9), type = 1)\n\n  10%   25%   75%   90% \n15.07 19.94 45.30 68.01 \n\nquantile(dde_non_preterm, probs = c(0.1, 0.25, 0.75, 0.9), type = 1)\n\n  10%   25%   75%   90% \n12.23 16.73 35.45 50.72 \n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nLo studente si convinca che l’implementazione “manuale” del comando è la seguente:\n\nmin(dde_non_preterm[F_non_preterm(dde_non_preterm) >= 0.25])\n\n[1] 16.73\n\nmin(dde_non_preterm[F_non_preterm(dde_non_preterm) >= 0.75])\n\n[1] 35.45"
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-i-quantili-ii",
    "href": "lezioni/un_D.html#indici-di-posizione-i-quantili-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: i quantili II",
    "text": "Indici di posizione: i quantili II\n\n\n\n\n\n\nNota\n\n\n\nLa definizione di quantile che abbiamo fornito coincide con quella descritta nel corso Statistica I, ma non è l’unica possibile (Come mai? Si riveda Statistica I…).\n\n\nTale definizione si ottiene con l’opzione type = 1, che tuttavia non è il default. Il valore predefinito è invece type = 7.\nSe siete curiosi di conoscere le varie definizioni di quantile, vi ricordo che la documentazione è consultabile tramite il comando: ? quantile.\n\n\n\n\n\n\nNota\n\n\n\nUn difetto del quantile type = 1 è che la mediana non sempre coincide con il quantile \\(\\mathcal{Q}_{0.5}\\). Si trovi un esempio in questo accade e si verifichi che invece il problema viene risolto nel caso type = 7."
  },
  {
    "objectID": "lezioni/un_D.html#indici-di-posizione-i-quantili-iii",
    "href": "lezioni/un_D.html#indici-di-posizione-i-quantili-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Indici di posizione: i quantili III",
    "text": "Indici di posizione: i quantili III\nIn R esistono in totale ben 9 modi per calcolare i quantili.\nFortunatamente, per numerosità campionarie elevate le differenze tendono ad essere trascurabili.\nElenchiamo qui di seguito alcuni esempi per la variabile dde_preterm:\n\ntab <- rbind(\n  quantile(dde_preterm, probs = c(0.1, 0.25, 0.5, 0.75, 0.9), type = 1),\n  quantile(dde_preterm, probs = c(0.1, 0.25, 0.5, 0.75, 0.9), type = 6),\n  quantile(dde_preterm, probs = c(0.1, 0.25, 0.5, 0.75, 0.9), type = 7),\n  quantile(dde_preterm, probs = c(0.1, 0.25, 0.5, 0.75, 0.9), type = 9)\n)\nrownames(tab) <- c(1, 6, 7, 9) # Cambia i nomi alle righe della tabella\ntab\n\n     10%   25%   50%      75%    90%\n1 15.070 19.94 29.46 45.30000 68.010\n6 15.054 19.94 29.46 45.49000 68.738\n7 15.070 19.94 29.46 45.30000 68.010\n9 15.060 19.94 29.46 45.41875 68.465\n\n\n\n\n\n\n\n\nSuggerimento\n\n\n\nCosa fa rbind? Lo abbiamo incontrato nell’unità A."
  },
  {
    "objectID": "lezioni/un_D.html#il-comando-summary",
    "href": "lezioni/un_D.html#il-comando-summary",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il comando summary",
    "text": "Il comando summary\nPer ottenere rapidamente le principali statistiche descrittive di una distribuzione (minimo, massimo, media, mediana e quartili), si usa spesso il comando summary:\n\nsummary(dde_preterm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3.17   19.94   29.46   36.20   45.30  178.06 \n\nsummary(dde_non_preterm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.50   16.73   24.04   29.14   35.40  162.29 \n\n\nIl comando summary può anche essere usato direttamente su un oggetto di tipo data.frame producendo il seguente output:\n\nsummary(dde)\n\n      DDE              GAD       \n Min.   :  2.50   Min.   :194.0  \n 1st Qu.: 17.13   1st Qu.:267.0  \n Median : 24.68   Median :277.0  \n Mean   : 30.24   Mean   :274.9  \n 3rd Qu.: 36.52   3rd Qu.:286.0  \n Max.   :178.06   Max.   :315.0"
  },
  {
    "objectID": "lezioni/un_D.html#i-boxplot",
    "href": "lezioni/un_D.html#i-boxplot",
    "title": "R per l’analisi statistica multivariata",
    "section": "I boxplot",
    "text": "I boxplot\nUna rappresentazione grafica alternativa agli istogrammi sono i boxplot.\nLe statistiche descrittive su cui si basano i boxplot si possono ottenere tramite il comando boxplot.stats, ovvero:\n\nboxplot.stats(dde_preterm)\n\n$stats\n[1]  3.17 19.94 29.46 45.30 83.25\n\n$n\n[1] 361\n\n$conf\n[1] 27.35112 31.56888\n\n$out\n [1]  94.60  99.42 144.86 105.83  90.73 128.47  91.23 102.50 178.06  88.72\n[11] 117.54 108.90 106.70 105.48 109.55 103.88 103.77\n\n\n\nboxplot(dde_preterm, dde_non_preterm) # Produce il grafico"
  },
  {
    "objectID": "lezioni/un_E.html",
    "href": "lezioni/un_E.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Varianza e scarto quadratico medio\nAltre misure di variabilità (campo di variazione, scarto interquartile, MAD)\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_E.html#descrizione-del-problema",
    "href": "lezioni/un_E.html#descrizione-del-problema",
    "title": "R per l’analisi statistica multivariata",
    "section": "Descrizione del problema",
    "text": "Descrizione del problema\nSiamo interessati a confrontare l’efficacia di due diverse metodologie, chiamate A e B, per la misurazione dell’emoglobina nel sangue.\nSi è creato in laboratorio del sangue artificiale contenente 15 grammi di emoglobina ogni \\(100 \\text{cm}^3\\).\nDal composito sono stati estratti in totale \\(n = 360\\) campioni.\nDi questi, in \\(n_A = 180\\) campioni l’emoglobina è stata misurata utilizzando la metodologia A mentre per i restanti \\(n_B = 180\\) campioni è stata usata la metodologia B.\nAlcuni dati sono riportati nella prossima slide. Le differenze tra le diverse misurazioni sono da attribuire in larga parte agli errori di misura delle due diverse metodologie."
  },
  {
    "objectID": "lezioni/un_E.html#importazione-dei-dati-emoglobina",
    "href": "lezioni/un_E.html#importazione-dei-dati-emoglobina",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione dei dati emoglobina",
    "text": "Importazione dei dati emoglobina\nCome fatto in precedenza, anzitutto è necessario scaricare il file emoglobina.csv e salvarlo nel proprio computer. Link al file\n\nemoglobina <- read.table(\"../dataset/emoglobina.csv\", header = TRUE, sep = \",\", stringsAsFactors = TRUE)\n\nIn alternativa, possiamo semplice ottenerli usando il link:\n\npath <- \"https://tommasorigon.github.io/introR/data/emoglobina.csv\"\nemoglobina <- read.table(path, header = TRUE, sep = \",\", stringsAsFactors = TRUE)\n\n\nstr(emoglobina)\n\n'data.frame':   360 obs. of  2 variables:\n $ emoglobina : num  15 15.1 15.2 14.8 15 ...\n $ Metodologia: Factor w/ 2 levels \"A\",\"B\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\nL’opzione stringsAsFactors = TRUE, implica che la variabile Metodologia viene codificata come factor e non come character."
  },
  {
    "objectID": "lezioni/un_E.html#operazioni-preliminari",
    "href": "lezioni/un_E.html#operazioni-preliminari",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni preliminari",
    "text": "Operazioni preliminari\nIn questo formato i dati sono difficili da analizzare, quantomeno senza usare le funzioni avanzate *apply così come gli strumenti del cosiddetto tidyverse.\nPertanto, creiamo le due variabili emo_A ed emo_B, contenenti i valori di emoglobina per le due metodologie.\n\nemo_A <- emoglobina$emoglobina[emoglobina$Metodologia == \"A\"] # Emoglobina gruppo A\nemo_B <- emoglobina$emoglobina[emoglobina$Metodologia == \"B\"] # Emoglobina gruppo B\n\nsummary(emo_A)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  14.44   14.87   15.00   15.00   15.14   15.64 \n\nsummary(emo_B)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  13.83   14.83   15.02   15.02   15.22   15.80 \n\n\n\nboxplot(emoglobina$emoglobina ~ emoglobina$Metodologia,\n  ylab = \"Emoglobina\",\n  xlab = \"Metodologia\"\n)\n\n\n\n\nDa queste prime analisi descrittive si evince che entrambe le metodologie sono, quantomeno in media, ben calibrate. Quale delle due è preferibile?"
  },
  {
    "objectID": "lezioni/un_E.html#la-varianza-i",
    "href": "lezioni/un_E.html#la-varianza-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza I",
    "text": "La varianza I\nRicordiamo che la varianza dei dati \\(x_1,\\dots,x_n\\) è pari a\n\\[\n\\sigma^2  = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 = \\left(\\frac{1}{n}\\sum_{i=1}^n x_i^2\\right) - \\bar{x}^2.\n\\]\nPossiamo quindi calcolare le varianze dei due gruppi “manualmente”:\n\nmean((emo_A - mean(emo_A))^2) # Varianza del gruppo A\n\n[1] 0.0456162\n\nmean((emo_B - mean(emo_B))^2) # Varianza del gruppo B\n\n[1] 0.09901038\n\nmean(emo_A^2) - mean(emo_A)^2 # Varianza del gruppo A, formula alternativa\n\n[1] 0.0456162\n\nmean(emo_B^2) - mean(emo_B)^2 # Varianza del gruppo B, formula alternativa\n\n[1] 0.09901038\n\n\nLa metodologia B è quindi caratterizzata da una variabilità maggiore."
  },
  {
    "objectID": "lezioni/un_E.html#la-varianza-ii",
    "href": "lezioni/un_E.html#la-varianza-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza II",
    "text": "La varianza II\nPer praticità, creiamo una nuova funzione chiamata my_var che calcola la varianza di un generico vettore x. Pertanto avremo:\n\nmy_var <- function(x) {\n  mean(x^2) - mean(x)^2\n}\n\nmy_var(emo_A)\n\n[1] 0.0456162\n\nmy_var(emo_B)\n\n[1] 0.09901038\n\n\nIn R è presente la funzione var, tuttavia questa calcola una quantità leggermente diversa, ovvero \\[\n\\texttt{var(x)} = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2,\n\\] ovvero lo stimatore corretto della varianza quando i dati provengono da una legge gaussiana.\nIl motivo non è chiaro? Verrà presto affrontato a Statistica 2!"
  },
  {
    "objectID": "lezioni/un_E.html#la-varianza-iii",
    "href": "lezioni/un_E.html#la-varianza-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza III",
    "text": "La varianza III\nLa differenza my_var e var è, in pratica, sostanzialmente trascurabile in questo caso, infatti:\n\nvar(emo_A)\n\n[1] 0.04587104\n\nvar(emo_B)\n\n[1] 0.09956351\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi ottenga lo stesso output di my_var utilizzando la funzione var."
  },
  {
    "objectID": "lezioni/un_E.html#scarto-quadratico-medio",
    "href": "lezioni/un_E.html#scarto-quadratico-medio",
    "title": "R per l’analisi statistica multivariata",
    "section": "Scarto quadratico medio",
    "text": "Scarto quadratico medio\nLo scarto quadratico medio è la radice quadrata della varianza, ovvero \\[\n\\text{sqm}(x) = \\sigma = \\sqrt{\\sigma^2}.\n\\]\nCreiamo quindi un’opportuna funzione R chiamata my_sd per il suo calcolo.\nAnche in questo caso, si faccia attenzione che il comando sd di R invece calcola il valore di \\[\n\\texttt{sd(x)} = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\]\n\nmy_sd <- function(x) {\n  sqrt(my_var(x))\n}\n\nmy_sd(emo_A)\n\n[1] 0.2135795\n\nmy_sd(emo_B)\n\n[1] 0.3146591\n\nsd(emo_A)\n\n[1] 0.2141753\n\nsd(emo_B)\n\n[1] 0.3155369"
  },
  {
    "objectID": "lezioni/un_E.html#campo-di-variazione",
    "href": "lezioni/un_E.html#campo-di-variazione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Campo di variazione",
    "text": "Campo di variazione\nIl campo di variazione è la differenza tra minimo e massimo della distribuzione, ovvero \\[\n(\\text{``Campo di variazione''}) = x_{(n)} - x_{(1)},\n\\] dove \\(x_{(1)}\\) e \\(x_{(n)}\\) rappresentano rispettivamente il minimo ed il massimo dei dati.\nSebbene non esista una funzione specifica per il suo calcolo, possiamo usare i seguenti comandi\n\nmax(emo_A) - min(emo_A)\n\n[1] 1.20242\n\nmax(emo_B) - min(emo_B)\n\n[1] 1.97508\n\ndiff(range(emo_A))\n\n[1] 1.20242\n\ndiff(range(emo_B))\n\n[1] 1.97508\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi definisca un’opportuna funzione R che calcola il campo di variazione."
  },
  {
    "objectID": "lezioni/un_E.html#scarto-interquartile",
    "href": "lezioni/un_E.html#scarto-interquartile",
    "title": "R per l’analisi statistica multivariata",
    "section": "Scarto interquartile",
    "text": "Scarto interquartile\nLo scarto interquartile è la differenza tra il terzo ed il primo quartile, ovvero \\[\n(\\text{``Scarto interquartile''}) = \\mathcal{Q}_{0.75} - \\mathcal{Q}_{0.25}.\n\\]\nÈ molto più resistente della varianza in presenza di poche osservazioni estreme.\nLa sua implementazione in R è la seguente:\n\ninterquartile_range <- function(x) {\n  diff(quantile(x, probs = c(0.25, 0.75)))\n}\n\ninterquartile_range(emo_A)\n\n      75% \n0.2699275 \n\ninterquartile_range(emo_B)\n\n      75% \n0.3929925"
  },
  {
    "objectID": "lezioni/un_E.html#mean-absolute-deviation-mads",
    "href": "lezioni/un_E.html#mean-absolute-deviation-mads",
    "title": "R per l’analisi statistica multivariata",
    "section": "Mean absolute deviation (MAD)s",
    "text": "Mean absolute deviation (MAD)s\nL’indice di variabilità MAD (Median Absolute Deviation) è definito come segue \\[\n\\text{MAD} = \\text{Mediana}(|x_1 - \\text{Me}_x|, \\dots, |x_n - \\text{Me}_x|), \\qquad \\text{Me}_x = \\text{Mediana}(x_1,\\dots,x_n).\n\\]\nPer il suo calcolo, creiamo una funzione appropriata:\n\nMAD <- function(x) {\n  median(abs(x - median(x)))\n}\n\nIl MAD della variabili emo_A ed emo_B è quindi pari a\n\nMAD(emo_A)\n\n[1] 0.135795\n\nMAD(emo_B)\n\n[1] 0.198025"
  },
  {
    "objectID": "lezioni/un_E.html#la-funzione-tapply-i",
    "href": "lezioni/un_E.html#la-funzione-tapply-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione tapply I",
    "text": "La funzione tapply I\nEsiste un metodo più elegante e veloce per ottenere questi risultati, basato sulla funzione tapply.\nLa funzione tapply(x, group, fun) applica una certa funzione fun ad un insieme di dati x, per ciascun gruppo group.\nPer esempio, la media aritmetica di emo_A ed emo_B si ottiene come segue:\n\ntapply(emoglobina$emoglobina, emoglobina$Metodologia, mean)\n\n       A        B \n15.00289 15.02171 \n\nwith(emoglobina, tapply(emoglobina, Metodologia, mean)) # In maniera ancora più compatta\n\n       A        B \n15.00289 15.02171"
  },
  {
    "objectID": "lezioni/un_E.html#la-funzione-tapply-ii",
    "href": "lezioni/un_E.html#la-funzione-tapply-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione tapply II",
    "text": "La funzione tapply II\nPertanto, possiamo ottenere i vari indici di variabilità come segue:\n\ntab <- rbind(\n  with(emoglobina, tapply(emoglobina, Metodologia, my_var)),\n  with(emoglobina, tapply(emoglobina, Metodologia, my_sd)),\n  with(emoglobina, tapply(emoglobina, Metodologia, interquartile_range)),\n  with(emoglobina, tapply(emoglobina, Metodologia, MAD))\n)\nrownames(tab) <- c(\"Varianza\", \"Deviazione Standard\", \"Scarto interquartile\", \"MAD\")\ntab\n\n                             A          B\nVarianza             0.0456162 0.09901038\nDeviazione Standard  0.2135795 0.31465915\nScarto interquartile 0.2699275 0.39299250\nMAD                  0.1357950 0.19802500\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi provi ad usare la funzione aggregate per ottenere lo stesso risultato."
  },
  {
    "objectID": "lezioni/un_E.html#esercizio-riassuntivo",
    "href": "lezioni/un_E.html#esercizio-riassuntivo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo",
    "text": "Esercizio riassuntivo\nLa misura di asimmetria di uso più comune è il cosiddetto indice di asimmetria standardizzato di Pearson, definito come \\[\n    \\gamma = \\frac{1}{\\text{sqm}(x)^3} \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^3 = \\frac{1}{n} \\sum_{i=1}^n \\left(\\frac{x_i - \\bar{x}}{\\sigma}\\right)^3.\n\\]\n\nSi crei una funzione opportuna per il suo calcolo.\n\n\nSoluzione dell’esercizio riassuntivo\n\n# Prima possibile implementazione\nasym <- function(x) {\n  sqm <- sqrt(mean(x^2) - mean(x)^2)\n  mean((x - mean(x))^3) / sqm^3\n}\n\n# Implementazione (leggermente) alternativa\nasym <- function(x) {\n  sqm <- sqrt(mean(x^2) - mean(x)^2)\n  z <- (x - mean(x)) / sqm\n  mean(z^3)\n}\n\nasym(emo_A)\n\n[1] 0.09535216"
  },
  {
    "objectID": "lezioni/un_A.html",
    "href": "lezioni/un_A.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "A-B-C: il software R come calcolatrice scientifica\nOperazioni di routine: pulizia del workspace, simboli speciali\nFunzioni matematiche, grafico di una funzione, operazioni logiche\nOperazioni con vettori e matrici\n\n\n\n\n\n\n\nNota\n\n\n\nEsercizi R associati sono diponibili a questo link"
  },
  {
    "objectID": "lezioni/un_A.html#calcolatrice-scientifica",
    "href": "lezioni/un_A.html#calcolatrice-scientifica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Calcolatrice scientifica",
    "text": "Calcolatrice scientifica\nAnzitutto, R può essere usato come se fosse una calcolatrice scientifica:\n\n2 + 2\n\n[1] 4\n\n4 * (3 + 5) # La somma entro parentesi viene eseguita per prima\n\n[1] 32\n\npi / 4 # Pi greco quarti\n\n[1] 0.7853982\n\n\nPer calcolare la potenza \\(a^b\\) si usa:\n\n2^5 # Sintassi alternativa: 2**5\n\n[1] 32\n\n\nLe quantità \\(\\sqrt{2}\\) e \\(\\sin(\\pi/4)\\) si ottengono invece con i comandi:\n\nsqrt(2)\n\n[1] 1.414214\n\nsin(pi / 4)\n\n[1] 0.7071068\n\n\n\n\n\n\n\n\nNota\n\n\n\nTutto ciò che viene scritto dopo un cancelletto (#) è considerato un commento."
  },
  {
    "objectID": "lezioni/un_A.html#assegnazione-di-un-valore",
    "href": "lezioni/un_A.html#assegnazione-di-un-valore",
    "title": "R per l’analisi statistica multivariata",
    "section": "Assegnazione di un valore",
    "text": "Assegnazione di un valore\nÈ possibile salvare un valore assegnandolo ad un oggetto tramite il simbolo <-.\n\n# Assegna il valore 5 all'oggetto x\nx <- sqrt(5) # Sintassi alternativa (sconsigliata): x = sqrt(5)\n\nIl valore contenuto in x può essere successivamente richiamato, modificato e salvato in un nuovo oggetto, chiamato ad esempio y.\n\ny <- x + pi # ovvero pi greco + radice quadrata di 5\ny\n\n[1] 5.377661\n\n\nPer rimuovere un oggetto dalla memoria, si usa il comando rm, ovvero remove.\n\nrm(x) # x non è più presente nel \"workspace\"\n\n\n\n\n\n\n\nNota\n\n\n\nR è case sensitive, pertanto l’oggetto x è diverso dall’oggetto X."
  },
  {
    "objectID": "lezioni/un_A.html#pulizia-del-workspace",
    "href": "lezioni/un_A.html#pulizia-del-workspace",
    "title": "R per l’analisi statistica multivariata",
    "section": "Pulizia del workspace",
    "text": "Pulizia del workspace\nÈ buona norma mantenere pulito il workspace, ovvero l’ambiente di lavoro.\nSe un oggetto non è più necessario, è possibile eliminarlo tramite il comando rm.\nÈ possibile visualizzare la lista di oggetti salvati in memoria tramite il comando seguente:\n\nls() # Nel workspace è presente l'oggetto y\n\n[1] \"y\"\n\n\nPertanto, per eliminare tutti gli oggetti salvati, si può usare\n\nrm(list = ls())"
  },
  {
    "objectID": "lezioni/un_A.html#alcune-funzioni-matematiche-i",
    "href": "lezioni/un_A.html#alcune-funzioni-matematiche-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcune funzioni matematiche I",
    "text": "Alcune funzioni matematiche I\nSupponiamo che x sia un numero reale.\nCiò che seguono sono una lista di funzioni disponibili in R:\n\nx <- 1/2 # Esempio di numero reale\n\n\nexp(x) # Esponenziale e logaritmo naturale\n\n[1] 1.648721\n\nlog(x)\n\n[1] -0.6931472\n\n\n\nabs(x) # Valore assoluto\n\n[1] 0.5\n\nsign(x) # Funzione segno\n\n[1] 1"
  },
  {
    "objectID": "lezioni/un_A.html#alcune-funzioni-matematiche-ii",
    "href": "lezioni/un_A.html#alcune-funzioni-matematiche-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcune funzioni matematiche II",
    "text": "Alcune funzioni matematiche II\n\nsin(x) # Funzioni trigonometriche (seno, coseno, tangente)\n\n[1] 0.4794255\n\ncos(x)\n\n[1] 0.8775826\n\ntan(x)\n\n[1] 0.5463025\n\n\n\nasin(x) # Funzioni trigonometriche inverse\n\n[1] 0.5235988\n\nacos(x)\n\n[1] 1.047198\n\natan(x)\n\n[1] 0.4636476\n\n\n\n\n\n\n\n\nNota\n\n\n\nLe funzioni di R si possono combinare tra loro, ad esempio log(abs(x))."
  },
  {
    "objectID": "lezioni/un_A.html#ulteriori-funzioni-matematiche-i",
    "href": "lezioni/un_A.html#ulteriori-funzioni-matematiche-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ulteriori funzioni matematiche I",
    "text": "Ulteriori funzioni matematiche I\nSupponiamo che x e y siano due numeri reali. Inoltre, siano n e k due numeri naturali.\nSi noti l’uso del ; che può essere usato per separare due comandi nella stessa riga.\n\nx <- 1 / 2; y <- 1 / 3 # Numeri reali \nn <- 5; k <- 2 # Numeri naturali\n\n\nfactorial(n) # n!\n\n[1] 120\n\nchoose(n, k) # Coefficiente binomiale\n\n[1] 10\n\n\n\nround(x, digits = 2) # Arrotonda x usando 2 cifre decimali\n\n[1] 0.5\n\nfloor(x) # Arrotonda x all'intero più vicino, per difetto\n\n[1] 0\n\nceiling(x) # Arrotonda x all'intero più vicino, per eccesso\n\n[1] 1"
  },
  {
    "objectID": "lezioni/un_A.html#ulteriori-funzioni-matematiche-ii",
    "href": "lezioni/un_A.html#ulteriori-funzioni-matematiche-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ulteriori funzioni matematiche II",
    "text": "Ulteriori funzioni matematiche II\nLa funzione gamma \\(\\Gamma(x) = \\int_0^\\infty s^{x-1} e^{-s} d s\\) si calcola in R come segue:\n\ngamma(x) # Funzione gamma\n\n[1] 1.772454\n\n\nLa funzione beta \\(\\mathcal{B}(x,y) = \\int_0^1 s^{x-1}(1-s)^{y-1}ds\\) si calcola in R come segue:\n\nbeta(x, y) # Funzione beta\n\n[1] 4.206546"
  },
  {
    "objectID": "lezioni/un_A.html#grafico-di-una-funzione",
    "href": "lezioni/un_A.html#grafico-di-una-funzione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Grafico di una funzione",
    "text": "Grafico di una funzione\nIn R è possibile disegnare una qualsiasi funzione tramite il comando curve.\nSe ad esempio si considera la funzione \\[f(x) = \\frac{\\sin(x)}{x},\\] allora possiamo disegnare \\(f(x)\\) nell’intervallo \\((0,15)\\) come segue:\n\ncurve(sin(x) / x, from = 0, to = 15)"
  },
  {
    "objectID": "lezioni/un_A.html#la-documentazione-ufficiale",
    "href": "lezioni/un_A.html#la-documentazione-ufficiale",
    "title": "R per l’analisi statistica multivariata",
    "section": "La documentazione ufficiale",
    "text": "La documentazione ufficiale\nLa documentazione di R è la principale fonte di informazioni.\nA cosa serve una funzione? Qual è la definizione dei suoi argomenti? La risposta va sempre cercata nella documentazione ufficiale e non in queste slide.\nIl comando ? funzione apre una finestra in cui vengono descritta nel dettaglio una funzione. Esempio:\n\n? log # Documentazione della funzione log\n\n\n\n\n\n\n\nNota riguardante l’esame\n\n\n\nDurante la prova d’esame è legittimo (anzi, è caldamente consigliato) consultare la documentazione."
  },
  {
    "objectID": "lezioni/un_A.html#simboli-speciali",
    "href": "lezioni/un_A.html#simboli-speciali",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simboli speciali",
    "text": "Simboli speciali\nNumeri molto grandi, come \\(10^{15}\\), e molto piccoli, come \\(10^{-15}\\), in R vengono rappresentati come segue:\n\n10^15\n\n[1] 1e+15\n\n10^(-15)\n\n[1] 1e-15\n\n\nPer questioni di approssimazione numerica, quando un numero è troppo grande R riporta Inf, ovvero infinito. Per esempio:\n\n10^1000 # Numero molto grande, anche se finito\n\n[1] Inf\n\n\nIl simbolo NaN significa invece Not a Number e si ottiene quando qualche funzione matematica non è stata usata nel modo corretto. Ad esempio:\n\nlog(-1) # Questo comando genera inoltre un avviso\n\nWarning in log(-1): Si è prodotto un NaN\n\n\n[1] NaN"
  },
  {
    "objectID": "lezioni/un_A.html#errori-di-approssimazione-numerica",
    "href": "lezioni/un_A.html#errori-di-approssimazione-numerica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Errori di approssimazione numerica",
    "text": "Errori di approssimazione numerica\nÈ ben noto che \\(\\sin(\\pi) = 0\\). Tuttavia, in R si ottiene un numero molto vicino a \\(0\\), ma strettamente positivo. Infatti:\n\nsin(pi)\n\n[1] 1.224647e-16\n\n\nR è uno strumento di calcolo numerico e pertanto sono sempre presenti errori di approssimazione numerica.\nFortunatamente, nella maggior parte dei casi pratici la differenza tra \\(0\\) e \\(10^{-16}\\) è del tutto irrilevante.\nIn altre situazioni, errori di approssimazione numerica possono portare a conclusioni fuorvianti. Occorre quindi fare attenzione e valutare caso per caso.\nAd ogni modo, l’approssimazione numerica potrebbe anche migliorare. Ad esempio:\n\ncos(pi)\n\n[1] -1"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-logiche",
    "href": "lezioni/un_A.html#operazioni-logiche",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni logiche",
    "text": "Operazioni logiche\nIn R è spesso necessario verificare se una o più condizioni sono verificate o meno.\n\nx <- 5\nx < 0 # Il valore di x è minore di 0?\n\n[1] FALSE\n\na <- (x == -3) # Il valore di x è uguale a -3?\na\n\n[1] FALSE\n\n\nIl valore di a è un indicatore binario o booleano, ovvero può essere vero (TRUE) oppure falso (FALSE).\nAltre funzioni logiche disponibili (assumendo che y sia un numero e b un booleano) sono:\n\na <- TRUE; b <- FALSE; x <- 5; y <- 7\nx >= y # x è maggiore o uguale a y? (Si usa \"<=\" per minore uguale)\n\n[1] FALSE\n\nx != y # x è diverso da y?\n\n[1] TRUE\n\na & b # a AND b. I valori booleani a e b sono entrambi veri?\n\n[1] FALSE\n\na | b # a OR b. Almeno uno tra a ed b è vero?\n\n[1] TRUE"
  },
  {
    "objectID": "lezioni/un_A.html#vettori",
    "href": "lezioni/un_A.html#vettori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Vettori",
    "text": "Vettori\nUn vettore in R viene definito tramite la funzione c(), come nel seguente esempio:\n\nx <- c(4, 2, 2, 8, 10) \nx\n\n[1]  4  2  2  8 10\n\n\n\n\n\n\n\n\nNota\n\n\n\nCon il termine generico “vettore” in R non si fa riferimento alla nozione dell’algebra lineare ma semplicemente ad una stringa di valori ordinati.\n\n\nIl seguente oggetto è un vettore in R, nonostante l’oggetto x sia composto sia numeri che da lettere\n\nx <- c(\"A\", \"B\", 2, 8, 10)\nx\n\n[1] \"A\"  \"B\"  \"2\"  \"8\"  \"10\""
  },
  {
    "objectID": "lezioni/un_A.html#creazione-di-vettori",
    "href": "lezioni/un_A.html#creazione-di-vettori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Creazione di vettori",
    "text": "Creazione di vettori\nTalvolta è comodo creare dei vettori i cui elementi sono dei numeri consecutivi\n\nx <- 5:10 # Equivalente a: x <- c(5, 6, 7, 8, 9, 10)\nx\n\n[1]  5  6  7  8  9 10\n\n\nPer creare una successione di numeri reali si usa il comando seq:\n\nx <- seq(from = 0, to = 1, by = 0.1)\nx\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nPer creare un vettore di valori ripetuti si usa il comando rep:\n\nx <- rep(10, 7) # Vettore in cui il numero 10 è ripetuto 7 volte\nx\n\n[1] 10 10 10 10 10 10 10"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sui-vettori-i",
    "href": "lezioni/un_A.html#operazioni-sui-vettori-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori I",
    "text": "Operazioni sui vettori I\nLa maggior parte delle funzioni matematiche di R sono vettorizzate. In altri termini, le funzioni agiscono su tutti gli elementi di un vettore.\n\nexp(1:6) + (1:6) / 2 + 1 # Esempio 1\n\n[1]   4.218282   9.389056  22.585537  57.598150 151.913159 407.428793\n\n\n\nx <- c(10, 10^2, 10^3, 10^4, 10^5, 10^6) # Esempio 2\nlog(x, base = 10)\n\n[1] 1 2 3 4 5 6\n\n\n\n1:8 > 4 # Esempio 3\n\n[1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nAltre funzioni invece sono utili proprio nel caso in cui l’argomento sia un vettore:\n\nx <- c(2, 3, 1, 3, 10, 5)\nlength(x) # Lunghezza del vettore\n\n[1] 6\n\nsum(x) # Somma degli elementi del vettore\n\n[1] 24\n\ncumsum(x) # Somme cumulate\n\n[1]  2  5  6  9 19 24"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sui-vettori-ii",
    "href": "lezioni/un_A.html#operazioni-sui-vettori-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori II",
    "text": "Operazioni sui vettori II\nUlteriori semplici operazioni in cui l’argomento è un vettore sono elencate nel seguito:\n\nx <- c(2, 3, 1, 3, 10, 5)\nprod(x) # Prodotto degli elementi del vettore\n\n[1] 900\n\ncumprod(x) # Prodotti cumulati\n\n[1]   2   6   6  18 180 900\n\nsort(x, decreasing = FALSE) # Vettore ordinato in ordine crescente\n\n[1]  1  2  3  3  5 10\n\nmin(x) # Valore minimo\n\n[1] 1\n\nwhich.min(x) # Posizione del valore corrispondente al minimo\n\n[1] 3\n\n\nInfine, il funzionamento delle seguenti funzioni dovrebbero essere intuibile da quanto visto finora:\n\nmax(x) # Valore massimo\n\n[1] 10\n\nwhich.max(x) # Posizione del valore corrispondente al massimo\n\n[1] 5\n\nrange(x) # Equivalente a: c(min(x), max(x))\n\n[1]  1 10"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sui-vettori-iii",
    "href": "lezioni/un_A.html#operazioni-sui-vettori-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori III",
    "text": "Operazioni sui vettori III\nÈ possibile selezionare gli elementi di un vettore usando le parentesi quadrate, come nei seguenti esempi:\n\n# Concatenazione di vettori\nx <- c(rep(pi, 2), sqrt(2), c(10, 7))\nx[3] # Estrae il terzo elemento dal vettore x, ovvero sqrt(2)\n\n[1] 1.414214\n\nx[c(1, 3, 5)] # Estrae il primo, il terzo ed il quinto elemento\n\n[1] 3.141593 1.414214 7.000000\n\nx[-c(1, 3, 5)] # Elimina il primo, il terzo ed il quinto elemento\n\n[1]  3.141593 10.000000\n\nx[x > 3.5] # Estrae gli elementi maggiori di 3.5\n\n[1] 10  7\n\n\nL’ultimo comando suggerisce che gli elementi di un vettore possono essere selezionati tramite una condizione relativa al vettore stesso."
  },
  {
    "objectID": "lezioni/un_A.html#operazione-sui-vettori-avvertenze",
    "href": "lezioni/un_A.html#operazione-sui-vettori-avvertenze",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazione sui vettori: avvertenze",
    "text": "Operazione sui vettori: avvertenze\nCosa succede quando vengono sommati due vettori di dimensioni diverse?\n\n\n\n\n\n\nWarning\n\n\n\nLa maggior parte dei linguaggi di programmazione restituisce un errore. R invece esegue ugualmente l’operazione “allungando” il vettore più corto.\n\n\nIn questo primo esempio, quantomeno R restituisce un warning.\n\n# Concatenazione di vettori\nx <- 1:5\ny <- 1:6\nx + y # Equivalente a: c(x, x[1]) + y\n\nWarning in x + y: la lunghezza più lunga dell'oggetto non è un multiplo della\nlunghezza più corta dell'oggetto\n\n\n[1]  2  4  6  8 10  7\n\n\nIn questo secondo esempio, invece, R non restituisce alcun avviso, rendendo la cosa particolarmente pericolosa\n\nx <- 1:3\ny <- 1:6\nx + y # Equivalente a: c(x, x) + y\n\n[1] 2 4 6 5 7 9"
  },
  {
    "objectID": "lezioni/un_A.html#matrici",
    "href": "lezioni/un_A.html#matrici",
    "title": "R per l’analisi statistica multivariata",
    "section": "Matrici",
    "text": "Matrici\nUna matrice \\({\\bf A}\\) è una collezione di elementi \\((a)_{ij}\\) per \\(i=1,\\dots,n\\) e \\(j=1,\\dots,m\\).\nPer esempio, la matrice quadrata di dimensione \\(2 \\times 2\\)\n\\[{\\bf A} = \\begin{pmatrix}\n5 & 2\\\\\n1 & 4 \\\\\n\\end{pmatrix},\\] si può definire in R tramite il comando matrix come segue:\n\nA <- matrix(c(5, 1, 2, 4), nrow = 2, ncol = 2)\nA\n\n     [,1] [,2]\n[1,]    5    2\n[2,]    1    4\n\n\nÈ inoltre possibile elencare gli elementi riga per riga\n\n# Definizione equivalente\nA <- matrix(c(5, 2, 1, 4), nrow = 2, ncol = 2, byrow = TRUE)"
  },
  {
    "objectID": "lezioni/un_A.html#vettori-riga-e-vettori-colonna",
    "href": "lezioni/un_A.html#vettori-riga-e-vettori-colonna",
    "title": "R per l’analisi statistica multivariata",
    "section": "Vettori riga e vettori colonna",
    "text": "Vettori riga e vettori colonna\nUna matrice con una sola colonna è un vettore colonna:\n\nx_col <- matrix(c(1, 10, 3, 5), ncol = 1)\nx_col\n\n     [,1]\n[1,]    1\n[2,]   10\n[3,]    3\n[4,]    5\n\n\nUna matrice con una sola colonna è un vettore riga:\n\nx_row <- matrix(c(1, 10, 3, 5), nrow = 1)\nx_row\n\n     [,1] [,2] [,3] [,4]\n[1,]    1   10    3    5"
  },
  {
    "objectID": "lezioni/un_A.html#vettori-riga-e-vettori-di-r",
    "href": "lezioni/un_A.html#vettori-riga-e-vettori-di-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Vettori riga e vettori di R",
    "text": "Vettori riga e vettori di R\nNella maggior parte dei casi, il {vettore riga x_row è intercambiabile col vettore x.\n\nx_row <- matrix(c(1, 10, 3, 5), nrow = 1)\nx <- c(1, 10, 3, 5) # Simile, ma non identico, a x_row\n\nAd esempio, le funzioni sum(x_row) e sum(x) forniscono lo stesso risultato.\nCi sono tuttavia alcune lievi distinzioni. Ad esempio:\n\ndim(x_row)\n\n[1] 1 4\n\ndim(x)\n\nNULL\n\n\nIl simbolo NULL significa non definito, perché non esiste la nozione di dimensione per un generico vettore R."
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-i",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici I",
    "text": "Operazioni sulle matrici I\nÈ possibile selezionare gli elementi di una matrice in maniera analoga a quanto fatto con i vettori.\n\nA[1, 2] # Estrazione di elemento in posizione (1,2)\n\n[1] 2\n\nA[, 2] # Estrazione seconda colonna\n\n[1] 2 4\n\nA[1, ] # Estrazione prima riga\n\n[1] 5 2\n\n\nAlcuni comandi di base per manipolare le matrici sono i seguenti\n\ndim(A) # Restituisce la dimensione della matrice\n\n[1] 2 2\n\na <- c(A) # Converte la matrice in un vettore\na\n\n[1] 5 1 2 4\n\n\n\ndiag(A) # Restituisce la diagonale della matrice\n\n[1] 5 4\n\nt(A) # Calcola la matrice trasposta A'\n\n     [,1] [,2]\n[1,]    5    1\n[2,]    2    4\n\nsum(A) # Somma di tutti gli elementi di A\n\n[1] 12"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-ii",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici II",
    "text": "Operazioni sulle matrici II\nCome per i vettori, le operazioni elementari (somma, prodotto, log, exp, etc.) vengono eseguite elemento per elemento.\n\nexp(A)\n\n           [,1]      [,2]\n[1,] 148.413159  7.389056\n[2,]   2.718282 54.598150\n\n\nSiano \\({\\bf A}\\) e \\({\\bf B}\\) due matrici aventi lo stesso numero di colonne e definiamo\n\\[\n{\\bf C} = \\begin{pmatrix}{\\bf A} \\\\ {\\bf B} \\end{pmatrix}.\n\\]\n\nB <- A # Creo una matrice B identica ad A, per semplicità\nC <- rbind(A, B)\nC\n\n     [,1] [,2]\n[1,]    5    2\n[2,]    1    4\n[3,]    5    2\n[4,]    1    4\n\n\nIn maniera analoga, siano \\({\\bf A}\\) e \\({\\bf B}\\) due matrici aventi lo stesso numero di righe e definiamo \\({\\bf C} = \\begin{pmatrix}{\\bf A} & {\\bf B} \\end{pmatrix}\\).\n\nC <- cbind(A, B)\nC\n\n     [,1] [,2] [,3] [,4]\n[1,]    5    2    5    2\n[2,]    1    4    1    4"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-iii",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici III",
    "text": "Operazioni sulle matrici III\nSiano \\({\\bf x}\\) e \\({\\bf y}\\) due vettori colonna in \\(\\mathbb{R}^p\\). Allora, il loro è pari a\n\\[\n{\\bf x}^\\intercal {\\bf y} = \\sum_{i=1}^p x_i y_i.\n\\]\nIn R possiamo usare il comando crossprod\n\nx <- matrix(c(-4, 2, 6, 10, 22), ncol = 1)\ny <- matrix(c(3, 2, 2, 7, 9), ncol = 1)\ncrossprod(x, y) # Equivalente a: sum(x * y)\n\n     [,1]\n[1,]  272\n\n\nIl comando crossprod funziona correttamente anche con “vettori” R.\nIl comando crossprod può essere usato anche per calcolare il seguente prodotto tra matrici \\[\n{\\bf A}^\\intercal {\\bf B},\n\\] dove \\({\\bf A}\\) e \\({\\bf B}\\) sono due matrici di dimensioni compatibili."
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-iv",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-iv",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici IV",
    "text": "Operazioni sulle matrici IV\nIn algebra lineare il prodotto tra matrici compatibili \\({\\bf A} {\\bf B}\\) è chiamato prodotto righe per colonne. In R si usa il comando seguente\n\nA <- rbind(c(1, 2, 3), c(4, 9, 2), c(2, 2, 2))\nB <- rbind(c(5, 2, 5), c(3, 3, 7), c(-2, -8, 10))\n\nA %*% B # Prodotto righe per colonne AB\n\n     [,1] [,2] [,3]\n[1,]    5  -16   49\n[2,]   43   19  103\n[3,]   12   -6   44\n\n\nNota. Il comando A * B indica il prodotto elemento per elemento e non il prodotto righe per colonne.\nSe le matrici non sono compatibili R produce un errore (provateci per esercizio!)"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-v",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-v",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici V",
    "text": "Operazioni sulle matrici V\nSia \\({\\bf A}\\) una matrice quadrata \\(n \\times n\\) a valori reali. La sua matrice inversa \\({\\bf A}^{-1}\\), quando esiste, è l’unica matrice tale per cui\n\\[\n{\\bf A} {\\bf A}^{-1} = {\\bf A}^{-1} {\\bf A} =  I_n.\n\\]\nPer ottenere \\({\\bf A}^{-1}\\) si usa il comando solve.\n\nA <- rbind(c(1, 2, 3), c(4, 9, 2), c(2, 2, 2))\nA1 <- solve(A) # Matrice inversa di A\nA1\n\n           [,1]        [,2]        [,3]\n[1,] -0.5833333 -0.08333333  0.95833333\n[2,]  0.1666667  0.16666667 -0.41666667\n[3,]  0.4166667 -0.08333333 -0.04166667\n\n\n\nround(A %*% A1, digits = 5) # Operazione di controllo\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n\n\ndet(A) # Calcola il determinante della matrice A\n\n[1] -24"
  },
  {
    "objectID": "lezioni/un_A.html#operazioni-sulle-matrici-vi",
    "href": "lezioni/un_A.html#operazioni-sulle-matrici-vi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici VI",
    "text": "Operazioni sulle matrici VI\nNel caso una matrice non sia invertibile, il determinante è pari a \\(0\\). Il comando solve in quel caso produce un errore.\n\n# Esempio di matrice NON invertibile\nA <- rbind(c(1, 2, 3), c(2, 4, 6), c(2, 2, 2))\ndet(A) # Deteminante pari a 0, solve(A) produce un errore\n\n[1] 0\n\n\nCi sono numerose funzioni per la scomposizione di matrici, il cui output è a volte una lista.\n\nA <- matrix(c(4, 1, 1, 8), ncol = 2)\nchol(A) # Scomposizione di Cholesky\n\n     [,1]     [,2]\n[1,]    2 0.500000\n[2,]    0 2.783882\n\nqr(A) # Scomposizione QR\n\n$qr\n           [,1]      [,2]\n[1,] -4.1231056 -2.910428\n[2,]  0.2425356  7.518604\n\n$rank\n[1] 2\n\n$qraux\n[1] 1.970143 7.518604\n\n$pivot\n[1] 1 2\n\nattr(,\"class\")\n[1] \"qr\"\n\neigen(A) # Scomposizione spettrale\n\neigen() decomposition\n$values\n[1] 8.236068 3.763932\n\n$vectors\n          [,1]       [,2]\n[1,] 0.2297529 -0.9732490\n[2,] 0.9732490  0.2297529"
  },
  {
    "objectID": "lezioni/un_A.html#liste",
    "href": "lezioni/un_A.html#liste",
    "title": "R per l’analisi statistica multivariata",
    "section": "Liste",
    "text": "Liste\nUna lista è una collezione di oggetti (numeri, vettori, matrici, etc).\nPer salvare o per estrarre un oggetto da una lista si usa il simbolo del dollaro $.\n\n# Creazione di una lista\nnew_list <- list(\n  A = matrix(c(4, 1, 1, 8), ncol = 2),\n  x = c(1, 2, 6, 6, 9)\n)\n\nnew_list\n\n$A\n     [,1] [,2]\n[1,]    4    1\n[2,]    1    8\n\n$x\n[1] 1 2 6 6 9"
  },
  {
    "objectID": "lezioni/un_A.html#esempio-la-scomposizione-spettrale",
    "href": "lezioni/un_A.html#esempio-la-scomposizione-spettrale",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esempio: la scomposizione spettrale",
    "text": "Esempio: la scomposizione spettrale\nGli autovalori ed autovettori di una matrice \\(\\textbf{A}\\) si ottengono tramite il comando eigen.\nIl risultato è una lista, contenente gli autovettori (vectors) e autovalori (values).\n\nSpec_A <- eigen(A) # Scomposizione spettrale della matrice A\nSpec_A\n\neigen() decomposition\n$values\n[1] 8.236068 3.763932\n\n$vectors\n          [,1]       [,2]\n[1,] 0.2297529 -0.9732490\n[2,] 0.9732490  0.2297529\n\n\n\nSpec_A$values # Estrazione degli autovalori\n\n[1] 8.236068 3.763932"
  },
  {
    "objectID": "lezioni/un_B.html",
    "href": "lezioni/un_B.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Definizione di una nuova funzione\nIstruzioni di controllo: if, else\nCicli for, cicli while\nCenni alle funzioni *apply\nI pacchetti R\n\n\n\n\n\n\n\nNota\n\n\n\nEsercizi R associati disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_B.html#funzioni-i",
    "href": "lezioni/un_B.html#funzioni-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Funzioni I",
    "text": "Funzioni I\nOltre ad essere un software statistico, R è un linguaggio di programmazione.\nLa maggior parte degli oggetti R è una funzione. Infatti:\n\nclass(sum) # Identifica la tipologia di oggetto\n\n[1] \"function\"\n\n\n\n\nclass(log) # Secondo esempio\n\n[1] \"function\"\n\n\n\n\nÈ possibile quindi definire nuove funzioni, in aggiunta a quelle già esistenti.\nUna volta create, le funzioni possono essere usate proprio come tutte le altre."
  },
  {
    "objectID": "lezioni/un_B.html#funzioni-ii",
    "href": "lezioni/un_B.html#funzioni-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Funzioni II",
    "text": "Funzioni II\nPer creare una nuova funzione, si utilizza comando function.\nLa nuova funzione cube calcola il cubo del numero ricevuto come input:\n\ncube <- function(x) {\n  out <- x^3\n  out\n}\n\n\nL’ultimo oggetto (in questo caso chiamato out) viene restituito come risultato:\n\ncube(4) # Calcola il cubo del valore 4\n\n[1] 64\n\n\n\n\nPossiamo alternativamente utilizzare anche il comando return per restituire il risultato:\n\ncube <- function(x) {\n  out <- x^3\n  return(out) # Esplicita che il valore da dover restituire è out\n}\ncube(8) # Calcola il cubo del valore 8\n\n[1] 512"
  },
  {
    "objectID": "lezioni/un_B.html#funzioni-iii",
    "href": "lezioni/un_B.html#funzioni-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Funzioni III",
    "text": "Funzioni III\nÈ possibile definire nuove funzioni con molteplici argomenti, scegliendo anche i loro eventuali valori predefiniti\n\npower <- function(x, p = 2) {\n  out <- x^p\n  out\n}\n\n\nIl valore predefinito per l’argomento p è il quadrato (p = 2), infatti:\n\npower(x = 4) # Calcola il quadrato del valore 4\n\n[1] 16\n\n\n\n\n\npower(4) # Sintassi alternativa: non è necessario specificare i nomi degli argomenti\n\n[1] 16\n\n\n\n\nTuttavia, possiamo selezionare una potenza diversa nel modo seguente:\n\npower(x = 4, p = 3) # Calcola il cubo del valore 4\n\n[1] 64\n\npower(4, 3) # Sintassi alternativa: non è necessario specificare i nomi degli argomenti\n\n[1] 64"
  },
  {
    "objectID": "lezioni/un_B.html#istruzioni-di-controllo-i",
    "href": "lezioni/un_B.html#istruzioni-di-controllo-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Istruzioni di controllo I",
    "text": "Istruzioni di controllo I\nL’istruzione di controllo if consente di svolgere una determinata operazione solamente se una certa condizione è verificata (TRUE oppure FALSE).\nL’istruzione di controllo (facoltativa) else consente di svolgere un’operazione alternativa se la precedente condizione non è verificata.\n\nAd esempio, il seguente codice mostra a schermo (funzione print) una frase diversa a seconda che la condizione sia vera o falsa:\n\ncondizione <- pi^2 < 10 # Valore booleano (in questo caso la condizione è TRUE)\n\nif (condizione) {\n  print(\"La condizione è vera\")\n  # Alcuni comandi da eseguire\n  # ...\n} else {\n  print(\"La condizione è falsa\")\n  # Altri comandi da eseguire\n  # ...\n}\n\n[1] \"La condizione è vera\""
  },
  {
    "objectID": "lezioni/un_B.html#istruzioni-di-controllo-ii",
    "href": "lezioni/un_B.html#istruzioni-di-controllo-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Istruzioni di controllo II",
    "text": "Istruzioni di controllo II\nLa seguente funzione square_root è un esempio più concreto relativo ad if ed else.\nSe il numero fornito come input è negativo, viene restituito un NaN:\n\nsquare_root <- function(x) {\n  if (x < 0) {\n    # Messaggio di avvertimento; in realtà sarebbe più appropriato usare il comando \"warning\"\n    print(\"Il valore di x deve essere positivo\")\n    out <- NaN # Restituisco Not A Number\n  } else {\n    out <- sqrt(x)\n  }\n  out\n}\n\nsquare_root(-2) # La condizione x < 0 è verificata\n\n[1] \"Il valore di x deve essere positivo\"\n\n\n[1] NaN\n\nsquare_root(36) # La condizione x < 0 NON è verificata\n\n[1] 6"
  },
  {
    "objectID": "lezioni/un_B.html#cicli-while-e-for-i",
    "href": "lezioni/un_B.html#cicli-while-e-for-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Cicli while e for I",
    "text": "Cicli while e for I\nI cicli for ed i cicli while ripetono l’operazione contenuta tra le parentesi graffe { } fintanto che una determinata condizione non si è verificata.\n\nCominciamo con un semplice esempio relativo alla funzione while:\n\ni <- 5 # Partiamo con i = 5\n\nwhile (i <= 25) { # Ripete l'operazione fintanto che i non è minore o uguale di 25\n  print(i) # Mostra a schermo il valore di i\n  i <- i + 5 # Incrementa il valore di i\n\n  # In contesti reali, qui ovviamente ci sono altre operazioni da eseguire\n  # ...\n}\n\n[1] 5\n[1] 10\n[1] 15\n[1] 20\n[1] 25"
  },
  {
    "objectID": "lezioni/un_B.html#cicli-while-e-for-ii",
    "href": "lezioni/un_B.html#cicli-while-e-for-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Cicli while e for II",
    "text": "Cicli while e for II\n\n\n\n\n\n\nWarning\n\n\n\nAttenzione a non creare dei loop senza fine!\n\n\n\nIl codice seguente richiede l’interruzione forzata della sessione di R oppure, nella peggiore delle ipotesi, il riavvio del computer:\n\n# NON ESEGUIRE IL SEGUENTE CODICE!\n#\n# La condizione i <= 25 è sempre vera perché i non viene aggiornato\ni <- 5\nwhile (i <= 25) {\n  print(i)\n\n  # Altre operazioni da eseguire\n  # ...\n}"
  },
  {
    "objectID": "lezioni/un_B.html#cicli-while-e-for-ii-1",
    "href": "lezioni/un_B.html#cicli-while-e-for-ii-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Cicli while e for II",
    "text": "Cicli while e for II\nIn alternativa ai cicli while, si può usare la sintassi più esplicita dei cicli for.\nIl ciclo esegue il contenuto delle parantesi graffe considerando di volta in volta i valori contenuti ad esempio in un vettore:\n\nvalues <- seq(from = 5, to = 25, by = 5)\nvalues\n\n[1]  5 10 15 20 25\n\nfor (i in values) {\n  print(i + 2) # Mostra a schermo il valore di i + 2\n\n  # Altre operazioni da eseguire\n  # ...\n}\n\n[1] 7\n[1] 12\n[1] 17\n[1] 22\n[1] 27"
  },
  {
    "objectID": "lezioni/un_B.html#esercizio-riassuntivo-i",
    "href": "lezioni/un_B.html#esercizio-riassuntivo-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo I",
    "text": "Esercizio riassuntivo I\nSi calcolino gli elementi di una matrice quadrata \\({\\bf D}\\) di dimensione \\(n \\times n\\), i cui elementi sono pari \\[\nd_{ij} = (x_i - x_j)^2, \\qquad  i,j \\in \\{1,\\dots,n\\},\n\\] dove \\({\\bf x} = (x_1,\\dots,x_n)^\\intercal\\) è un generico vettore in \\(\\mathbb{R}^n\\).\nIn altri termini, si definisca una funzione distances(x) che a partire da un generico vettore x restituisca una matrice D.\n\n\n\n\n\n\n\nTraccia dello svolgimento\n\n\n\nSi crei innanzitutto una matrice D i cui elementi sono tutti pari a 0, usando il comando matrix.\nQuindi, si usino due cicli for “annidati”, ovvero uno all’interno dell’altro, per calcolare ciascuno dei valori D[i, j].\n\n\n\nSoluzione esercizio riassuntivo I\n\ndistances <- function(x) {\n  n <- length(x) # Ottengo la lunghezza del vettore x\n  D <- matrix(0, nrow = n, ncol = n) # Creazione matrice vuota\n\n  for (i in 1:n) {\n    for (j in 1:n) {\n      D[i, j] <- (x[i] - x[j])^2\n    }\n  }\n  D # Valore da restituire\n}\n\nx <- c(5, 2, 1, 24) # Esempio per verificare che sia corretto\ndistances(x)\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    9   16  361\n[2,]    9    0    1  484\n[3,]   16    1    0  529\n[4,]  361  484  529    0\n\n\n\n\n\n\n\n\nNota\n\n\n\nEsistono molti modi diversi (ma corretti) di implementare questa funzione. Per inciso, questa soluzione non è affatto il modo più efficiente."
  },
  {
    "objectID": "lezioni/un_B.html#esercizio-riassuntivo-ii",
    "href": "lezioni/un_B.html#esercizio-riassuntivo-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo II",
    "text": "Esercizio riassuntivo II\nFizzbuzz è un semplice esercizio di programmazione spesso usato nei colloqui di lavoro per verificare le conoscenze di programmazione di base.\nIl compito è il seguente: per tutti i numeri da \\(1\\) a \\(100\\) si stampi a schermo:\n\nla parola fizz se il numero è un multiplo di \\(3\\),\nla parola buzz se è multiplo di \\(5\\),\nla parola fizzbuzz se il numero è un multiplo sia di \\(3\\) che di \\(5\\),\nil numero stesso altrimenti.\n\n\n\n\n\n\n\n\nSuggerimento\n\n\n\nSi usi la funzione print e la funzione resto % di R. Inoltre, per rendere il codice più snello è possibile usare l’istruzione di controllo chiamata else if.\n\n\n\nSoluzione esercizio riassuntivo II\nLa soluzione riportata fa uso del costrutto else if.\n\nfor (i in 1:100) {\n  condA <- (i %% 3) == 0 # Il numero è un multiplo di 3?\n  condB <- (i %% 5) == 0 # Il numero è un multiplo di 5?\n\n  if (condA & condB) {\n    print(\"fizzbuzz\")\n  } else if (condA) {\n    print(\"fizz\")\n  } else if (condB) {\n    print(\"buzz\")\n  } else {\n    print(i)\n  }\n}"
  },
  {
    "objectID": "lezioni/un_B.html#la-famiglia-di-funzioni-apply",
    "href": "lezioni/un_B.html#la-famiglia-di-funzioni-apply",
    "title": "R per l’analisi statistica multivariata",
    "section": "La famiglia di funzioni *apply",
    "text": "La famiglia di funzioni *apply\nQuando possibile, sarebbe meglio evitare l’utilizzo dei cicli for, perché questi tendono ad essere lenti in R (a differenza di altri linguaggi, come C++).\nUn’alternativa più elegante, anche se non necessariamente più efficiente, è la famiglia di funzioni *apply, ovvero: apply, tapply, sapply, mapply, lapply.\nLa più semplice, ovvero apply, esegue una determinata funzione per ciascuna riga / colonna di una matrice.\n\n\n\n\n\n\nEsercizio\n\n\n\nSi consulti la documentazione delle funzioni *apply per avere una prima idea del loro funzionamento."
  },
  {
    "objectID": "lezioni/un_B.html#i-pacchetti-r",
    "href": "lezioni/un_B.html#i-pacchetti-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "I pacchetti R",
    "text": "I pacchetti R\nCome menzionato nella lezione introduttiva, R è organizzato in pacchetti.\nSe vogliamo utilizzare le funzioni di un pacchetto, questo può essere richiamato usando la funzione library, ovvero:\n\nlibrary(MASS) # Carica in memoria il pacchetto MASS\nlibrary(knitr) # Carica in memoria il pacchetto knitr\n\n\nSe un pacchetto non è presente nel computer è necessario installarlo.\nSi può usare il comando seguente oppure usare la finestra “Packages” presente in RStudio.\n\ninstall.packages(\"knitr\") # Installa il pacchetto knitr"
  },
  {
    "objectID": "lezioni/un_C.html",
    "href": "lezioni/un_C.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "L’oggetto data.frame\nImportazione di un dataset in memoria\nEsplorazione e manipolazione di un dataset\nTipologia di variabili\nI valori mancanti\n\n\n\n\n\n\n\nNota\n\n\n\nEsercizi R associati disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_C.html#gli-oggetti-di-tipo-data.frame",
    "href": "lezioni/un_C.html#gli-oggetti-di-tipo-data.frame",
    "title": "R per l’analisi statistica multivariata",
    "section": "Gli oggetti di tipo data.frame",
    "text": "Gli oggetti di tipo data.frame\nUn oggetto R chiamato data.frame corrisponde alla matrice dei dati.\nCiascuna riga rappresenta quindi un’unità statistica, mentre ciascuna colonna rappresenta invece una variabile.\n\nUn data.frame assomiglia ad una matrice (matrix), ma è pensato per l’analisi dei dati.\nAd esempio, un data.frame può contenere anche valori non numerici, come per esempio le variabili qualitative o valori mancanti.\nCome vedremo, il data.frame viene generalmente caricato all’interno di R utilizzando ad esempio la funzione read.table."
  },
  {
    "objectID": "lezioni/un_C.html#importazione-di-un-dataset",
    "href": "lezioni/un_C.html#importazione-di-un-dataset",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione di un dataset",
    "text": "Importazione di un dataset\nIl modo più frequente di caricare un dataset in memoria è importarlo da un file esterno.\nSe i dati hanno dimensioni piccole / medie (dimensione file \\(<\\) 3-4 Gb), sono spesso salvati in formato .csv oppure .txt.\nIn contesti reali e più complessi, è possibile importare i dati a partire direttamente da database relazionali come SQL.\n\nÈ sconsigliabile importare i dati in R a partire da un file Excel. Più in generale, ci sono svariate ragioni per evitare Excel se l’obiettivo è condurre una rigorosa analisi dei dati.\n\n\n\n\n\n\n\n\nNota\n\n\n\nPer poter procedere con i prossimi comandi, è necessario scaricare il file calcio.csv e salvarlo nel proprio computer. Link al file."
  },
  {
    "objectID": "lezioni/un_C.html#i-dati-grezzi-editor-di-testo",
    "href": "lezioni/un_C.html#i-dati-grezzi-editor-di-testo",
    "title": "R per l’analisi statistica multivariata",
    "section": "I dati grezzi (editor di testo)",
    "text": "I dati grezzi (editor di testo)"
  },
  {
    "objectID": "lezioni/un_C.html#la-cartella-di-lavoro",
    "href": "lezioni/un_C.html#la-cartella-di-lavoro",
    "title": "R per l’analisi statistica multivariata",
    "section": "La cartella di lavoro",
    "text": "La cartella di lavoro\nLa sessione di R attiva è aperta in una specifica cartella di lavoro, identificata dal comando getwd.\nAd esempio, la cartella in cui il codice è stato eseguito è la seguente\n\ngetwd() # Identifica la cartella di lavoro (get working directory)\n\n[1] \"/Users/tommaso/Library/Mobile Documents/com~apple~CloudDocs/University/Bicocca/Didattica/Laboratorio Statistica/introR/lezioni\"\n\n\n\nPer aprire il file calcio.csv, bisogna fornire ad R il percorso del file, che dipende da dove questo è stato salvato (sul Desktop, cartella downloads, etc).\n\n# LA VARIABILE PATH VA CAMBIATA A SECONDA DI DOVE SIA SALVATO IL FILE .csv NEL PROPRIO PC\npath <- \"../dataset/calcio.csv\" # Questo è il percorso del file, relativo a getwd()\n\n\n\nIl percorso del file può anche essere un link, come in questo caso:\n\npath <- \"https://tommasorigon.github.io/introR/dataset/calcio.csv\""
  },
  {
    "objectID": "lezioni/un_C.html#importazione-del-dataset",
    "href": "lezioni/un_C.html#importazione-del-dataset",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione del dataset",
    "text": "Importazione del dataset\nÈ anche possibile cambiare la cartella di lavoro tramite il comando setwd.\nIn Rstudio, si può usare l’opzione More -> Set as working directory nella finestra Files, selezionando la cartella di interesse.\nUna volta identificato il corretto path del file, per importare il dataset in memoria si usa ad esempio il comando read.table. Pertanto:\n\ncalcio <- read.table(path, header = TRUE, sep = \",\")\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nL’opzione header = TRUE significa che la prima riga contiene i nomi delle variabili.\nL’opzione sep = \",\" indica che i vari valori di ciascuna variabile sono separati da una virgola.\n\n\n\n\n\nInfine, si noti che nel caso in cui il file sia contenuto nella cartella di lavoro, è quindi sufficiente usare:\n\ncalcio <- read.table(\"calcio.csv\", header = TRUE, sep = \",\")"
  },
  {
    "objectID": "lezioni/un_C.html#esplorazione-di-un-data.frame",
    "href": "lezioni/un_C.html#esplorazione-di-un-data.frame",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esplorazione di un data.frame",
    "text": "Esplorazione di un data.frame\nIn primo luogo, siamo interessati a capire quante variabili e quante osservazioni sono contenute nel dataset data.frame:\n\ndim(calcio) # Equivalente a c(nrow(calcio), ncol(calcio))\n\n[1] 1900    7\n\n\n\nPer verificare di non aver commesso errori grossolani nell’importazione del data.frame, possiamo visualizzare le prime \\(6\\) osservazioni con il comando head:\n\nhead(calcio) # Comando equivalente: calcio[1:6, ]\n\n        Date HomeTeam   AwayTeam FTR B365H B365D B365A\n1 2014-08-30   Chievo   Juventus   A  7.00   4.0  1.50\n2 2014-08-30     Roma Fiorentina   H  1.67   3.8  5.00\n3 2014-08-31 Atalanta     Verona   D  2.05   3.4  3.60\n4 2014-08-31   Cesena      Parma   H  3.10   3.2  2.35\n5 2014-08-31    Genoa     Napoli   A  3.90   3.4  1.95\n6 2014-08-31    Milan      Lazio   H  2.00   3.4  3.75\n\n\n\n\nIl comando tail può essere usato per mostrare le ultime \\(6\\) osservazioni:\n\ntail(calcio) # Comando equivalente: calcio[1895:1900, ]\n\n           Date HomeTeam  AwayTeam FTR B365H B365D B365A\n1895 2011-05-22    Inter   Catania   H  1.53  3.75  7.00\n1896 2011-05-22 Juventus    Napoli   D  1.90  3.60  3.80\n1897 2011-05-22    Lecce     Lazio   A  6.00  3.60  1.60\n1898 2011-05-22  Palermo    Chievo   A  1.75  3.50  4.75\n1899 2011-05-22     Roma Sampdoria   H  1.29  5.00 11.00\n1900 2011-05-22  Udinese     Milan   D  3.50  1.53  6.50"
  },
  {
    "objectID": "lezioni/un_C.html#il-dataset-calcio",
    "href": "lezioni/un_C.html#il-dataset-calcio",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il dataset calcio",
    "text": "Il dataset calcio\nIl dataset calcio contiene quindi un totale di \\(7\\) variabili. Ciascuna osservazione è una partita di calcio avvenuta nel campionato di serie A dal 2008 al 2015.\n\n\nLa variabile Date indica la data della partita.\nLe variabili HomeTeam, AwayTeam indicano la squadra che ha giocato in casa ed in trasferta, rispettivamente.\nLa variabile FTR (“Full Time Result”) indica se la partita è stata vinta dalla squadra di casa (H), dalla squadra in trasferta (A), o si è conclusa con un pareggio (D).\nLe variabili B365H, B365D e B365A, indicano le quote della compagnia di scommesse Bet365 Group Ltd relative ai 3 eventi, prima dell’inizio della partita.\n\n\n\nPer accedere e modificare i nomi delle variabili, si utilizza il comando colnames.\n\ncolnames(calcio) # Per accedere ai nomi delle variabili\n\n[1] \"Date\"     \"HomeTeam\" \"AwayTeam\" \"FTR\"      \"B365H\"    \"B365D\"    \"B365A\""
  },
  {
    "objectID": "lezioni/un_C.html#tipologia-di-variabili",
    "href": "lezioni/un_C.html#tipologia-di-variabili",
    "title": "R per l’analisi statistica multivariata",
    "section": "Tipologia di variabili",
    "text": "Tipologia di variabili\nIn un dataset sono presenti diverse tipologie di variabili.\n\nLe variabili quantitative discrete e continue in R sono codificate come oggetti di tipo integer e numeric, rispettivamente.\n\n\nLe variabili qualitative in R sono codificate come oggetti di tipo character oppure di tipo factor; la differenza tra queste tipologie verrà chiarita nelle prossime slides.\nInfine, le date in R si codificano con la tipologia Date.\n\n\n\n\n\n\n\n\nNota\n\n\n\nR non sempre riconosce correttamente la tipologia di variabili, come evidenziato dal comando str, che fornisce un sommario del data.frame.\n\nstr(calcio)\n\n'data.frame':   1900 obs. of  7 variables:\n $ Date    : chr  \"2014-08-30\" \"2014-08-30\" \"2014-08-31\" \"2014-08-31\" ...\n $ HomeTeam: chr  \"Chievo\" \"Roma\" \"Atalanta\" \"Cesena\" ...\n $ AwayTeam: chr  \"Juventus\" \"Fiorentina\" \"Verona\" \"Parma\" ...\n $ FTR     : chr  \"A\" \"H\" \"D\" \"H\" ...\n $ B365H   : num  7 1.67 2.05 3.1 3.9 2 2.2 2.3 3.1 1.8 ...\n $ B365D   : num  4 3.8 3.4 3.2 3.4 3.4 3.25 3.4 3.3 3.5 ...\n $ B365A   : num  1.5 5 3.6 2.35 1.95 3.75 3.3 3 2.3 4.5 ..."
  },
  {
    "objectID": "lezioni/un_C.html#variabili-quantitative",
    "href": "lezioni/un_C.html#variabili-quantitative",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili quantitative",
    "text": "Variabili quantitative\nPer estrarre una variabile da un data.frame si procede come nel caso delle liste, ovvero tramite il simbolo $. Le variabili possono essere salvate con un nome a piacere.\n\nUna variabile numerica è un vettore R a tutti gli effetti, pertanto possiamo applicare le funzioni che abbiamo già incontrato finora\n\nis.numeric(calcio$B365H) # Verifico che si tratta di una variabile di tipo numeric\n\n[1] TRUE\n\nclass(calcio$B365H)\n\n[1] \"numeric\"\n\ncalcio$B365H[1:10] # Primi 10 elementi di un vettore R\n\n [1] 7.00 1.67 2.05 3.10 3.90 2.00 2.20 2.30 3.10 1.80\n\n\n\n\nLe analisi descrittive di una variabile numerica verranno affrontate nelle unità successive, per ora ci limitiamo alla manipolazione del data.frame."
  },
  {
    "objectID": "lezioni/un_C.html#variabili-qualitative-i",
    "href": "lezioni/un_C.html#variabili-qualitative-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili qualitative I",
    "text": "Variabili qualitative I\nLe variabili di tipo character sono appropriate per le stringhe di testo, ovvero se ciascun campo corrisponde ad un breve testo, come ad esempio un Tweet.\nLe variabili qualitative con valori ripetuti vanno invece codificate come factor.\nDobbiamo quindi convertire le \\(3\\) variabili HomeTeam, AwayTeam e FTR come segue:\n\ncalcio$HomeTeam <- factor(calcio$HomeTeam)\ncalcio$AwayTeam <- factor(calcio$AwayTeam)\ncalcio$FTR <- factor(calcio$FTR)\n\n\nIn alternativa, possiamo fare questa operazione in fase di lettura di dati, tramite l’opzione stringsAsFactors. Quindi:\n\ncalcio <- read.table(path, header = TRUE, sep = \",\", stringsAsFactors = TRUE)"
  },
  {
    "objectID": "lezioni/un_C.html#variabili-qualitative-ii",
    "href": "lezioni/un_C.html#variabili-qualitative-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili qualitative II",
    "text": "Variabili qualitative II\nIn primo luogo, verifichiamo che la conversione sia avvenuta correttamente ed esploriamone il contenuto della variabile HomeTeam:\n\nNelle variabili di tipo factor sono pertanto elencate le varie modalità, chiamati levels in R.\n\n\nPer accedere alle modalità si usa il comando levels, che elenca le modalità della variabile considerata in ordine alfabetico:\n\nlevels(calcio$HomeTeam)\n\n [1] \"Atalanta\"   \"Bari\"       \"Bologna\"    \"Brescia\"    \"Cagliari\"  \n [6] \"Catania\"    \"Cesena\"     \"Chievo\"     \"Empoli\"     \"Fiorentina\"\n[11] \"Genoa\"      \"Inter\"      \"Juventus\"   \"Lazio\"      \"Lecce\"     \n[16] \"Livorno\"    \"Milan\"      \"Napoli\"     \"Palermo\"    \"Parma\"     \n[21] \"Reggina\"    \"Roma\"       \"Sampdoria\"  \"Sassuolo\"   \"Siena\"     \n[26] \"Torino\"     \"Udinese\"    \"Verona\""
  },
  {
    "objectID": "lezioni/un_C.html#variabili-qualitative-iii",
    "href": "lezioni/un_C.html#variabili-qualitative-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili qualitative III",
    "text": "Variabili qualitative III\nIl comando levels permette di rinominare le modalità, ad esempio:\n\ncalcio$FTR[1:10]\n\n [1] A H D H A H D D D H\nLevels: A D H\n\nlevels(calcio$FTR) <- c(\"Away\", \"Draw\", \"Home\") # Rinomino le modalità\ncalcio$FTR[1:10]\n\n [1] Away Home Draw Home Away Home Draw Draw Draw Home\nLevels: Away Draw Home\n\n\n\nIl comando levels consente inoltre di accorpare le modalità di una variabile qualitativa:\n\ncalcio$Draw <- calcio$FTR # Creo una copia della variabile FTR chiamata Draw\nlevels(calcio$Draw) <- c(\"Not_Draw\", \"Draw\", \"Not_Draw\") # Accorpamento delle modalità\n\ncalcio$Draw[1:10]\n\n [1] Not_Draw Not_Draw Draw     Not_Draw Not_Draw Not_Draw Draw     Draw    \n [9] Draw     Not_Draw\nLevels: Not_Draw Draw"
  },
  {
    "objectID": "lezioni/un_C.html#le-variabili-di-tipo-date",
    "href": "lezioni/un_C.html#le-variabili-di-tipo-date",
    "title": "R per l’analisi statistica multivariata",
    "section": "Le variabili di tipo date",
    "text": "Le variabili di tipo date\nLa variabile Date del dataset calcio rappresenta una data e pertanto va codificata come tale.\n\nIn R la conversione viene eseguita dal comando as.Date, seguita dal formato in cui è espressa la data:\n\ncalcio$Date <- as.Date(calcio$Date, format = \"%Y-%m-%d\")\nclass(calcio$Date)\n\n[1] \"Date\"\n\ncalcio$Date[1:10]\n\n [1] \"2014-08-30\" \"2014-08-30\" \"2014-08-31\" \"2014-08-31\" \"2014-08-31\"\n [6] \"2014-08-31\" \"2014-08-31\" \"2014-08-31\" \"2014-08-31\" \"2014-08-31\"\n\n\n\n\nUna volta convertito in formata Date, è possibile svolgere alcune operazioni aggiuntive. Ad esempio:\n\nmin(calcio$Date) # Prima partita giocata\n\n[1] \"2008-08-30\"\n\nmax(calcio$Date) # Ultima partita giocata\n\n[1] \"2015-05-31\""
  },
  {
    "objectID": "lezioni/un_C.html#manipolazione-di-un-dataset",
    "href": "lezioni/un_C.html#manipolazione-di-un-dataset",
    "title": "R per l’analisi statistica multivariata",
    "section": "Manipolazione di un dataset",
    "text": "Manipolazione di un dataset\nPer selezionare le righe di un dataset si procede come nel caso delle matrici:\n\ncalcio[c(1806, 501, 109), ]\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw\n1806 2011-03-13    Genoa  Palermo Home  1.91  3.25   4.2 Not_Draw\n501  2013-11-23    Milan    Genoa Draw  1.44  4.20   7.5     Draw\n109  2014-11-09  Palermo  Udinese Draw  2.15  3.30   3.4     Draw\n\n\n\nÈ ovviamente possibile (e tipicamente molto più utile) selezionare le osservazioni che soddisfino una determinata condizione.\n\n\nSupponiamo ad esempio di voler identificare le partite terminate con un pareggio:\n\ncalcio_draw <- calcio[calcio$FTR == \"Draw\", ]\nhead(calcio_draw)\n\n         Date   HomeTeam  AwayTeam  FTR B365H B365D B365A Draw\n3  2014-08-31   Atalanta    Verona Draw  2.05  3.40   3.6 Draw\n7  2014-08-31    Palermo Sampdoria Draw  2.20  3.25   3.3 Draw\n8  2014-08-31   Sassuolo  Cagliari Draw  2.30  3.40   3.0 Draw\n9  2014-08-31     Torino     Inter Draw  3.10  3.30   2.3 Draw\n14 2014-09-14 Fiorentina     Genoa Draw  1.57  3.80   6.0 Draw\n21 2014-09-20     Cesena    Empoli Draw  2.80  3.00   2.7 Draw"
  },
  {
    "objectID": "lezioni/un_C.html#i-valori-mancanti",
    "href": "lezioni/un_C.html#i-valori-mancanti",
    "title": "R per l’analisi statistica multivariata",
    "section": "I valori mancanti",
    "text": "I valori mancanti\nSupponiamo di voler identificare le partite in cui la squadra di casa ha una bassa probabilità di vittoria secondo Bet365:\n\ncalcio_home <- calcio[calcio$B365H > 9, ]\ncalcio_home\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw\n162  2015-01-06   Cesena   Napoli Away   9.5  4.75  1.36 Not_Draw\n224  2015-02-15   Cesena Juventus Draw  15.0  6.00  1.22     Draw\nNA         <NA>     <NA>     <NA> <NA>    NA    NA    NA     <NA>\n1520 2010-05-16    Siena    Inter Away  21.0  9.00  1.10 Not_Draw\nNA.1       <NA>     <NA>     <NA> <NA>    NA    NA    NA     <NA>\nNA.2       <NA>     <NA>     <NA> <NA>    NA    NA    NA     <NA>\n\n\n\n\n\n\n\n\nImportant\n\n\n\nQualcosa è andato storto: ci sono dei simboli (NA) che non avevamo incontrato finora.\n\n\nLa ragione per cui il comando produce dei risultati apparentemente strani è dovuto alla presenza di alcuni dati mancanti, codificati come NA (Not Available).\nIn particolare, ci sono \\(3\\) osservazioni (la \\(1501\\), \\(1846\\) e la \\(1848\\)) i cui valori relativi a Bet365 non sono disponibili.\n\ncalcio[rowSums(is.na(calcio)) > 0, ] # Identifica le righe con valori mancanti\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw\n1501 2010-05-09  Bologna  Catania Draw    NA    NA    NA     Draw\n1846 2011-04-17   Chievo  Bologna Home    NA    NA    NA Not_Draw\n1848 2011-04-17    Genoa  Brescia Home    NA    NA    NA Not_Draw\n\n\n\nLa funzione is.na produce una matrice logica della stessa dimensione di calcio, contenente TRUE se il valore è mancante e FALSE altrimenti.\n\n\nLa funzione rowSums(matrice) produce un vettore i cui valori alla somma degli elementi di ciascuna riga della matrice.\nDi conseguenza, rowSums(is.na(calcio)) indica quanti valori mancanti sono presenti in ciascuna riga."
  },
  {
    "objectID": "lezioni/un_C.html#gestire-i-dati-mancanti",
    "href": "lezioni/un_C.html#gestire-i-dati-mancanti",
    "title": "R per l’analisi statistica multivariata",
    "section": "Gestire i dati mancanti",
    "text": "Gestire i dati mancanti\nLa gestione statistica dei dati mancanti non è tra gli obiettivi di questo corso.\nLa soluzione più facile, sebbene potenzialmente molto pericolosa, consistente semplicemente nel rimuovere le righe incomplete tramite il comando na.omit:\n\ncalcio_no_na <- na.omit(calcio)\ndim(calcio_no_na)\n\n[1] 1897    8\n\n\n\nPer risolvere il problema originario, ovvero identificare le partite in cui la squadra di casa ha bassa probabilità di vittoria, si può usare subset:\n\ncalcio_home <- subset(calcio, subset = B365H > 9)\ncalcio_home\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw\n162  2015-01-06   Cesena   Napoli Away   9.5  4.75  1.36 Not_Draw\n224  2015-02-15   Cesena Juventus Draw  15.0  6.00  1.22     Draw\n1520 2010-05-16    Siena    Inter Away  21.0  9.00  1.10 Not_Draw"
  },
  {
    "objectID": "lezioni/un_C.html#selezione-delle-variabili",
    "href": "lezioni/un_C.html#selezione-delle-variabili",
    "title": "R per l’analisi statistica multivariata",
    "section": "Selezione delle variabili",
    "text": "Selezione delle variabili\nIl comando subset può essere usato sia per selezionare le righe (osservazioni) che per selezionare le colonne (variabili).\n\nNel secondo caso, si può procedere tramite l’opzione select:\n\ncalcio_B365 <- subset(calcio, select = c(B365H, B365D, B365A))\nhead(calcio_B365)\n\n  B365H B365D B365A\n1  7.00   4.0  1.50\n2  1.67   3.8  5.00\n3  2.05   3.4  3.60\n4  3.10   3.2  2.35\n5  3.90   3.4  1.95\n6  2.00   3.4  3.75\n\n\nOvviamente è possibile anche selezionare sia le righe che le colonne."
  },
  {
    "objectID": "lezioni/un_C.html#il-comando-attach",
    "href": "lezioni/un_C.html#il-comando-attach",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il comando attach",
    "text": "Il comando attach\nIn R esiste un comando chiamato attach. Sebbene usato da molti, questo comando è diabolico e sarebbe meglio evitare di utilizzarlo.\n\nIl comando attach(dataframe) consente di utilizzare le variabili di un data.frame come se queste fossero presenti nel workspace.\nQuesta pratica tuttavia rende il codice molto meno leggibile e spesso conduce ad errori di varia natura.\n\n\nNonostante le varie proteste a favore della rimozione di attach da parte di alcuni, questo comando continua a (r)esistere e viene tuttora usato da molti.\nIn questo corso non verranno forniti esempi di utilizzo di attach per evitare di indurre lo studente in tentazione."
  },
  {
    "objectID": "lezioni/un_C.html#sommario",
    "href": "lezioni/un_C.html#sommario",
    "title": "R per l’analisi statistica multivariata",
    "section": "Sommario",
    "text": "Sommario\nA seguito di tutte queste operazioni, il dataset risulta molto modificato rispetto alla sua versione iniziale.\nRi-eseguendo il comando str otteniamo infatti che\n\nstr(calcio)\n\n'data.frame':   1900 obs. of  8 variables:\n $ Date    : Date, format: \"2014-08-30\" \"2014-08-30\" ...\n $ HomeTeam: Factor w/ 28 levels \"Atalanta\",\"Bari\",..: 8 22 1 7 11 17 19 24 26 27 ...\n $ AwayTeam: Factor w/ 28 levels \"Atalanta\",\"Bari\",..: 13 10 28 20 18 14 23 5 12 9 ...\n $ FTR     : Factor w/ 3 levels \"Away\",\"Draw\",..: 1 3 2 3 1 3 2 2 2 3 ...\n $ B365H   : num  7 1.67 2.05 3.1 3.9 2 2.2 2.3 3.1 1.8 ...\n $ B365D   : num  4 3.8 3.4 3.2 3.4 3.4 3.25 3.4 3.3 3.5 ...\n $ B365A   : num  1.5 5 3.6 2.35 1.95 3.75 3.3 3 2.3 4.5 ...\n $ Draw    : Factor w/ 2 levels \"Not_Draw\",\"Draw\": 1 1 2 1 1 1 2 2 2 1 ..."
  },
  {
    "objectID": "lezioni/un_C.html#il-banco-vince-sempre",
    "href": "lezioni/un_C.html#il-banco-vince-sempre",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il banco vince sempre",
    "text": "Il banco vince sempre\nNelle scommesse calcistiche le quote rappresentano l’inverso della probabilità di un evento, per cui \\[\n    (\\text{Probabilità dell'evento}) = \\frac{1}{(\\text{Quota dell'evento})}\n    \\]\n\nLa quota rappresenta inoltre l’ammontare in € che il vincitore riceve a fronte del pagamento dell’importo unitario di \\(1\\)€.\n\n\nAd esempio, scommettendo \\(10\\)€ sulla vittoria della Juventus nella partita contro il Chievo del 30 Agosto 2014, si sarebbero ottenuti \\(15\\)€, dato che la quota era di \\(1.50\\).\n\n\nSe la scommessa fosse equa, le probabilità di vittoria, pareggio e sconfitta dovrebbero sommare ad \\(1\\).\nTuttavia, questo non accade: le probabilità ottenute sommano ad un valore \\(>1\\). Tale discrepanza si chiama allibramento o aggio e garantisce al banco un guadagno."
  },
  {
    "objectID": "lezioni/un_C.html#esercizio-riassuntivo",
    "href": "lezioni/un_C.html#esercizio-riassuntivo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo",
    "text": "Esercizio riassuntivo\n\nSi ottenga la variabile aggio, ottenuta come la differenza tra la somma delle “probabilità” dei \\(3\\) eventi (vittoria, pareggio, sconfitta) ed \\(1\\), ovvero il caso equo.\nSi dica qual è l’aggio associato alla partita Udinese-Parma del 1 Settembre 2013.\nSi dica in quali partite è stato applicato il più basso ed il più alto aggio e si identifichino tali valori.\nIn quale partita è stato applicato l’aggio più alto nel campionato di Serie A del 2009/2010?\n\n\n\n\n\n\n\nSuggerimento\n\n\n\nSi usino i comandi which.min e which.max. Si consulti la documentazione per capirne il funzionamento.\n\n\n\nSoluzione\n\n# Calcolo dell'aggio\ncalcio$aggio <- 1 / calcio$B365H + 1 / calcio$B365D + 1 / calcio$B365A - 1\n\n# Aggio associato a Udinese-Parma del 1 Settembre 2013\nsubset(calcio, Date == \"2013-09-01\" & HomeTeam == \"Udinese\")\n\n          Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw      aggio\n400 2013-09-01  Udinese    Parma Home   2.1  3.25   3.6 Not_Draw 0.06166056\n\n# Minimo e massimo aggio\ncalcio[which.min(calcio$aggio), ]\n\n          Date HomeTeam AwayTeam  FTR B365H B365D B365A     Draw      aggio\n301 2015-04-18 Juventus    Lazio Home  1.95   3.4  4.33 Not_Draw 0.03788504\n\ncalcio[which.max(calcio$aggio), ]\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A Draw     aggio\n1839 2011-04-10  Palermo   Cesena Draw   2.1   2.1     6 Draw 0.1190476\n\n# Il campionato di Serie A inizia a fine Agosto e finisce a fine Maggio\ncalcio2009_2010 <- subset(calcio, Date <= \"2009-08-15\" & Date <= \"2010-06-15\")\ncalcio2009_2010[which.max(calcio2009_2010$aggio), ]\n\n           Date HomeTeam AwayTeam  FTR B365H B365D B365A Draw     aggio\n1125 2009-05-24   Chievo  Bologna Draw   3.2  1.57     6 Draw 0.1161093"
  },
  {
    "objectID": "lezioni/un_intro.html",
    "href": "lezioni/un_intro.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "L’analisi statistica multivariata riguarda l’analisi congiunta di più variabili misurate sul medesimo insieme di unità statistiche.\nNei corsi precedenti (ad es. Statistica I), ci si è concentrati su una o due variabili alla volta. In contesti reali le variabili coinvolte sono quasi sempre ben più di 2.\nIl modulo AE è la naturale prosecuzione di un corso di statistica descrittiva, applicato al caso in cui le variabili sono più di 2.\nIl modulo MS estende e analizza nel dettaglio il modello lineare, nel caso in cui le variabili esplicative sono molte.\nLe tecniche per l’analisi di dati multivariati possono avere una natura descrittiva / esplorativa (AE) oppure inferenziale (MS)."
  },
  {
    "objectID": "lezioni/un_intro.html#organizzazione-del-corso",
    "href": "lezioni/un_intro.html#organizzazione-del-corso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Organizzazione del corso",
    "text": "Organizzazione del corso\nPagina e-learning: https://elearning.unimib.it/enrol/index.php?id=37030\nPagina web di ASM-R: https://tommasorigon.github.io/introR/\nNella pagina web del corso potete trovare:\n\nUltimi avvisi\nMateriale didattico da scaricare (slide, esercizi, etc.)\nModalità d’esame\nPropedeuticità, regole del salto d’appello\nAltro\n\nTutor: Luca Danese (l.danese1@campus.unimib.it)."
  },
  {
    "objectID": "lezioni/un_intro.html#propedeuticità",
    "href": "lezioni/un_intro.html#propedeuticità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Propedeuticità",
    "text": "Propedeuticità\nQuesta attività formativa deve essere preceduta dal superamento e registrazione dei seguenti esami:\n\nAlgebra lineare;\nAnalisi Matematica I;\nCalcolo delle Probabilità;\nStatistica I.\n\nNon è possibile iscriversi alla prove parziali di R, AE, MS, senza aver prima registrato le attività formative sopra elencate.\nÈ tuttavia sempre possibile frequentare le lezioni."
  },
  {
    "objectID": "lezioni/un_intro.html#registrazione-del-voto",
    "href": "lezioni/un_intro.html#registrazione-del-voto",
    "title": "R per l’analisi statistica multivariata",
    "section": "Registrazione del voto",
    "text": "Registrazione del voto\nIl voto finale di ASM è determinato dalla media (ponderata con i rispettivi CFU) dei voti conseguiti nelle tre parti R, AE e MS (arrotondato all’intero più vicino).\nPer poter registrare il voto di ASM, è necessario aver conseguito un voto sufficiente (\\(\\ge 18\\)) nelle prove di R, AE e MS ma anche iscriversi all’appello di ASM.\nQuindi per registrare l’esame è necessario iscriversi all’appello di ASM (15 CFU) ai fini della verbalizzazione."
  },
  {
    "objectID": "lezioni/un_intro.html#salto-dappello",
    "href": "lezioni/un_intro.html#salto-dappello",
    "title": "R per l’analisi statistica multivariata",
    "section": "Salto d’appello",
    "text": "Salto d’appello\nIn ottemperanza al Regolamento Didattico di Ateneo, per l’insegnamento ASM è previsto il salto d’appello.\nPer motivi didattici, agli studenti i quali nel primo appello della sessione Invernale ed Estiva consegnano un compito scritto, chiedendone la correzione, che palesa lacune tali da essere considerate non colmabili nel tempo che intercorre tra l’appello in questione ed il successivo, ovvero una votazione inferiore a 9/30.\nPer motivi disciplinari, agli studenti che durante gli esami scritti vengano sorpresi a copiare, a scambiare informazioni coi compagni, a riversare sull’elaborato informazioni provenienti da qualsiasi supporto di cui non è permesso l’utilizzo.\nPer motivi organizzativi, agli studenti che si iscrivono ripetutamente (3 volte consecutive) agli appelli senza presentarsi, senza effettuare la disiscrizione o avvisare per mail con adeguata motivazione per l’assenza."
  },
  {
    "objectID": "lezioni/un_intro.html#docente-del-modulo-asm-r",
    "href": "lezioni/un_intro.html#docente-del-modulo-asm-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Docente del modulo ASM-R",
    "text": "Docente del modulo ASM-R\n\nNome: Tommaso Rigon\nEmail: tommaso.rigon@unimib.it\nPagina personale: https://tommasorigon.github.io\nRicevimento: Martedì alle 17.30. Si prega di contattare il docente in anticipo."
  },
  {
    "objectID": "lezioni/un_intro.html#materiale-didattico-del-modulo-asm-r",
    "href": "lezioni/un_intro.html#materiale-didattico-del-modulo-asm-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Materiale didattico del modulo ASM-R",
    "text": "Materiale didattico del modulo ASM-R\n\nTesti di riferimento\n\nAlbert, J. & M. Rizzo (2012). R by Example. Springer. Link: https://link.springer.com/content/pdf/10.1007%2F978-1-4614-1365-3.pdf\nRobert, C. & G. Casella (2010). Introducing Monte Carlo Methods with R. Springer. Link: https://link.springer.com/content/pdf/10.1007%2F978-1-4419-1576-4.pdf\n\n\n\nTesti di consultazione\nIl materiale didattico fornito sulla pagina web.\n\nAdler, J. (2012). R in a nutshell. O’Reilly.\nGrolemund, G. & Wickham, H. (2016). R for Data Science. O’Reilly.\nVenables, W. N., Smith D. M. & the R Core Team (2021). An Introduction to R. https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf"
  },
  {
    "objectID": "lezioni/un_intro.html#analisi-statistica-multivariata",
    "href": "lezioni/un_intro.html#analisi-statistica-multivariata",
    "title": "R per l’analisi statistica multivariata",
    "section": "Analisi statistica multivariata",
    "text": "Analisi statistica multivariata\nL’analisi statistica multivariata riguarda l’analisi congiunta di più variabili misurate sul medesimo insieme di unità statistiche.\nNei corsi precedenti (ad es. Statistica I), ci si è concentrati su una o due variabili alla volta. In contesti reali le variabili coinvolte sono quasi sempre ben più di 2.\nIl modulo AE è la naturale prosecuzione di un corso di statistica descrittiva, applicato al caso in cui le variabili sono più di 2.\nIl modulo MS estende e analizza nel dettaglio il modello lineare, nel caso in cui le variabili esplicative sono molte.\nLe tecniche per l’analisi di dati multivariati possono avere una natura descrittiva / esplorativa (AE) oppure inferenziale (MS)."
  },
  {
    "objectID": "lezioni/un_intro.html#statistica-e-data-science",
    "href": "lezioni/un_intro.html#statistica-e-data-science",
    "title": "R per l’analisi statistica multivariata",
    "section": "Statistica e data science",
    "text": "Statistica e data science\n\nASA Statement on the Role of Statistics in Data Science (2015)\nWhile there is not yet a consensus on what precisely constitutes data science, three professional communities, all within computer science and/or statistics, are emerging as foundational to data science:\n\nDatabase Management enables transformation, conglomeration, and organization of data resources;\nStatistics and Machine Learning convert data into knowledge;\nDistributed and Parallel Systems provide the computational infrastructure to carry out data analysis.\n\nÈ quindi chiaro che la statistica moderna non può prescindere dall’uso di software.\nASA statement: https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/"
  },
  {
    "objectID": "lezioni/un_intro.html#competenze-mercato-del-lavoro",
    "href": "lezioni/un_intro.html#competenze-mercato-del-lavoro",
    "title": "R per l’analisi statistica multivariata",
    "section": "Competenze & mercato del lavoro",
    "text": "Competenze & mercato del lavoro\nUn laureato/a in statistica che ambisce a fare carriera come statistico/a, non deve sottovalutare l’importanza degli aspetti informatici e computazionali.\nÈ sufficiente visitare LinkedIn o altri siti web simili, per verificare che la conoscenza di almeno un software di programmazione (R, Python, Julia, etc) è un requisito essenziale.\nIl ruolo dello statistico non è quello del programmatore. Lo statistico interviene principalmente per decidere cosa fare (analisi statistica) più che sul come fare (implementazione informatica).\nIl “cosa” ed il “come” sono concetti legati a doppio filo: lo statistico deve sapersi interfacciare con i programmatori, o perfino svolgere l’intero lavoro in autonomia."
  },
  {
    "objectID": "lezioni/un_intro.html#annuncio-di-lavoro-i",
    "href": "lezioni/un_intro.html#annuncio-di-lavoro-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Annuncio di lavoro I",
    "text": "Annuncio di lavoro I"
  },
  {
    "objectID": "lezioni/un_intro.html#annuncio-di-lavoro-ii",
    "href": "lezioni/un_intro.html#annuncio-di-lavoro-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Annuncio di lavoro II",
    "text": "Annuncio di lavoro II"
  },
  {
    "objectID": "lezioni/un_intro.html#r-software",
    "href": "lezioni/un_intro.html#r-software",
    "title": "R per l’analisi statistica multivariata",
    "section": "R software",
    "text": "R software\nIl software R è contemporaneamente un linguaggio di programmazione ed un software per l’analisi dei dati.\nÈ distribuito gratuitamente dal gruppo The R Project for Statistical Computing (http://www.r-project.org).\nUn gruppo di ricercatori, l’R Core Team, costituito oggi da circa 20 membri, si occupa dei codici sorgente.\nIl software R è in continua evoluzione: dalla versione 0.64 si è giunti ad oggi (Novembre 2022) allo sviluppo della versione 4.2.2 (Innocent and Trusting).\nÈ previsto un aggiornamento semestrale in quanto il gruppo di sviluppatori rilascia una major release all’anno e una sua patch ogni 6 mesi."
  },
  {
    "objectID": "lezioni/un_intro.html#perché-proprio-r",
    "href": "lezioni/un_intro.html#perché-proprio-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Perché proprio R?",
    "text": "Perché proprio R?\nPerché si è deciso di usare R e non altri strumenti informatici, tra cui i linguaggi Python, Julia da un lato e i costosissimi software STATA, SAS, SPSS dall’altro?\nR è probabilmente il più popolare linguaggio di programmazione tra i statistici e data scientist. Esiste da più di \\(20\\) anni e può quindi contare su un ampia base di supporto.\nR è open-source e gratuito.\nR è sviluppato da statistici per gli statistici. Non è quindi un software generalista riadattato per l’analisi dei dati, ma uno strumento con delle precise finalità statistiche.\nR è lo strumento primario per la ricerca statistica: tutte le volte che un nuovo metodo viene studiato, tendenzialmente viene pubblicato anche il corrispondente pacchetto R."
  },
  {
    "objectID": "lezioni/un_intro.html#numero-di-pacchetti-r-pubblicati-sul-cran",
    "href": "lezioni/un_intro.html#numero-di-pacchetti-r-pubblicati-sul-cran",
    "title": "R per l’analisi statistica multivariata",
    "section": "Numero di pacchetti R pubblicati sul CRAN",
    "text": "Numero di pacchetti R pubblicati sul CRAN\n\nIl numero di pacchetti R disponibili sul CRAN (Comprehensive R Archive Network) continua a crescere esponenzialmente."
  },
  {
    "objectID": "lezioni/un_intro.html#scaricare-ed-installare-r",
    "href": "lezioni/un_intro.html#scaricare-ed-installare-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Scaricare ed installare R",
    "text": "Scaricare ed installare R\nCome menzionato, R è un software libero e viene distribuito con la licenza GNU GPL.\nPertanto, per il download di R è sufficiente visitare il Comprehensive R Archive Network (http://cran.r-project.org), spesso abbreviato in CRAN.\nR è multi-piattaforma, ovvero disponibile per Windows, Mac e Linux:\n\nMicrosoft Windows: http://cran.r-project.org/bin/windows/base/\nMacOS: http://cran.r-project.org/bin/macosx/\nLinux: http://cran.r-project.org/bin/linux/\n\n\nNota\nOvviamente, è fondamentale che installiate R sul vostro laptop personale, sia ai fini di questo corso che per gli esami successivi (non solo ASM!)"
  },
  {
    "objectID": "lezioni/un_intro.html#rstudio",
    "href": "lezioni/un_intro.html#rstudio",
    "title": "R per l’analisi statistica multivariata",
    "section": "Rstudio",
    "text": "Rstudio\nR può essere utilizzato tramite linea di comando (R Console).\nRStudio (http://www.rstudio.org) è un software open-source separato da R, ma che grazie alla sua interfaccia intuitiva ne rende più agevole l’uso.\nRStudio è infatti un IDE (Integrated Development Environment).\nAnche RStudio è disponibile per differenti piattaforme (Windows, Mac, Linux).\nPer il download: http://www.rstudio.com/products/rstudio/download/\nL’uso di Rstudio è facoltativo, ma altamente raccomandato."
  },
  {
    "objectID": "lezioni/un_intro.html#il-corso-asm-r",
    "href": "lezioni/un_intro.html#il-corso-asm-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il corso ASM-R",
    "text": "Il corso ASM-R\nIl modulo R è in larga misura una revisione di argomenti che dovreste già conoscere bene. Nello specifico, ci occuperemo di\n\nStatistica descrittiva (Statistica I);\nCalcolo delle probabilità;\nInferenza statistica (Statistica II).\n\nAl tempo stesso, il modulo R è un esame di programmazione in R.\n\nNota\nASM-R non è una “introduzione” al software R. Lo scopo del corso è mostrare come risolvere problemi statistici reali disponendo di un computer.\nIn altre parole, all’esame verranno valutati sia la forma (programmazione) che il contenuto (analisi statistica)."
  },
  {
    "objectID": "lezioni/un_intro.html#programma-dettagliato",
    "href": "lezioni/un_intro.html#programma-dettagliato",
    "title": "R per l’analisi statistica multivariata",
    "section": "Programma dettagliato",
    "text": "Programma dettagliato\nIl corso ASM-R è costituito da \\(4\\) macro-argomenti.\n\nIntroduzione ad R\nConcetti di base, elementi di programmazione, vettori, matrici, dataframes, funzioni.\n\n\nStatistica descrittiva\nRevisione degli argomenti di Statistica I usando R. Analisi descrittiva di un dataset.\n\n\nCalcolo delle probabilità\nVariabili aleatorie, numeri pseudo-casuali, applicazioni del metodo Monte Carlo.\n\n\nInferenza statistica\n\nMetodi numerici per l’analisi di verosimiglianza.\nMetodi Monte Carlo per il calcolo delle proprietà di uno stimatore (distorsione, varianza, consistenza)."
  },
  {
    "objectID": "lezioni/un_intro.html#affrontare-il-corso",
    "href": "lezioni/un_intro.html#affrontare-il-corso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Affrontare il corso",
    "text": "Affrontare il corso\nNon è possibile imparare ad usare R semplicemente leggendo un libro o (peggio ancora) “studiando” dalle slides.\nAl contrario, la pratica è probabilmente ciò che determina la buona preparazione di uno studente.\nUn pessimo modo di impiegare il proprio tempo è tentare di memorizzare i comandi R.\nViceversa, è importante svolgere il maggior numero possibile di esercizi sforzandosi di non guardare le soluzioni se non dopo aver provato a risolverlo.\nNel caso aveste finito gli esercizi e aveste già risolto autonomamente la lista di esami precedenti, potete provare a risolvere in R gli esami degli altri corsi.\n\nNota\nAll’esame è possibile consultare sia il codice utilizzato a lezione che la documentazione di R https://github.com/tommasorigon/introR/tree/master/docs/lezioni/script"
  },
  {
    "objectID": "lezioni/un_intro.html#verso-un-uso-di-r-moderno",
    "href": "lezioni/un_intro.html#verso-un-uso-di-r-moderno",
    "title": "R per l’analisi statistica multivariata",
    "section": "Verso un uso di R moderno…",
    "text": "Verso un uso di R moderno…\nPurtroppo, per ragioni di tempo, non affronteremo gli aspetti più moderni e recenti del software R. Alcuni importanti pacchetti sono menzionati nel seguito.\nPacchetti dplyr, tidyr, readr facenti parte del cosiddetto tidyverse. Si tratta di strumenti estremamente efficienti per la manipolazioni di dataset.\nPacchetto ggplot2. Rappresentazioni grafiche avanzate e di alta qualità, basate sul concetto di grammar of graphics.\nPacchetto shiny. Strumenti per la creazione di siti web interattivi, in cui R rimane nel back-end.\nUn caso studio di Shiny: http://bicocca-datalab.shinyapps.io/covid19/"
  },
  {
    "objectID": "lezioni/un_M.html",
    "href": "lezioni/un_M.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Distribuzione di uno stimatore\nDistorsione, varianza ed errore quadratico medio\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_M.html#ripasso-e-notazione-i",
    "href": "lezioni/un_M.html#ripasso-e-notazione-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione I",
    "text": "Ripasso e notazione I\nIn questa unità discuteremo di stimatori e delle loro proprietà.\nRicordiamo che, nel caso assolutamente continuo, un modello statistico è una collezione di funzioni di densità \\[\n\\mathcal{F} = \\{f(\\cdot; \\theta) : \\theta \\in \\Theta\\},\n\\] indicizzata da un vettori di parametri \\(\\theta \\in \\Theta\\), dove \\(\\Theta \\subseteq \\mathbb{R}^p\\) è lo spazio parametrico.\nAssumiamo inoltre che i dati \\(y_1,\\dots,y_n\\) siano realizzazioni iid di variabili aleatorie \\(Y_1,\\dots,Y_n\\) con legge \\(f(y; \\theta)\\), per un qualche ignoto valore del parametro \\(\\theta\\).\nIl nostro scopo è stimare l’ignoto valore di \\(\\theta\\) nel miglior modo possibile usando i dati osservati \\(y = (y_1,\\dots,y_n)\\)."
  },
  {
    "objectID": "lezioni/un_M.html#ripasso-e-notazione-ii",
    "href": "lezioni/un_M.html#ripasso-e-notazione-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione II",
    "text": "Ripasso e notazione II\nUno stimatore \\(\\hat{\\theta}(Y)\\) è una qualsiasi funzione delle variabili aleatorie \\(Y = (Y_1,\\dots, Y_n)\\) che “si avvicina” al vero valore di \\(\\theta\\). Lo stimatore è una variabile aleatoria.\nUna stima \\(\\hat{\\theta} = \\hat{\\theta}(y)\\) è una qualsiasi funzione dei dati \\(y = (y_1,\\dots,y_n)\\) che ``si avvicina’’ al vero valore di~\\(\\theta\\). La stima è la realizzazione di \\(\\hat{\\theta}(Y)\\), perciò è un numero.\nAbbiamo bisogno di criterio per stabilire se uno stimatore “funziona” o meno. Il sostegno logico e filosofico proviene dal seguente principio (frequentista)."
  },
  {
    "objectID": "lezioni/un_M.html#il-principio-del-campionamento-ripetuto-i-ripasso",
    "href": "lezioni/un_M.html#il-principio-del-campionamento-ripetuto-i-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il principio del campionamento ripetuto I (ripasso)",
    "text": "Il principio del campionamento ripetuto I (ripasso)\nImmaginiamo che sia possibile, almeno ipoteticamente, ripetere l’esperimento varie volte, ottenendo ogni volta un nuovo campione \\(y\\) e quindi una nuova stima \\(\\hat{\\theta}\\).\nDi conseguenza, lo stimatore \\(\\hat{\\theta}(Y)\\) è una variabile aleatoria, per la quale possiamo parlare di distribuzione, valore atteso e così via."
  },
  {
    "objectID": "lezioni/un_M.html#il-principio-del-campionamento-ripetuto-ii-ripasso",
    "href": "lezioni/un_M.html#il-principio-del-campionamento-ripetuto-ii-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il principio del campionamento ripetuto II (ripasso)",
    "text": "Il principio del campionamento ripetuto II (ripasso)\nSe accettiamo il principio del campionamento ripetuto, valuteremo le bontà della singola stima \\(\\hat{\\theta}\\) sulla base delle proprietà dello stimatore \\(\\hat{\\theta}(Y)\\).\nIn altri termini, ci chiediamo come si comporterebbero le varie stime \\(\\hat{\\theta}\\) se potessimo osservare tanti campioni, non solo quello che abbiamo a disposizione.\nCi aspettiamo che mediamente la distribuzione di \\(\\hat{\\theta}(Y)\\) sia concentrata attorno al vero ed ignoto valore \\(\\theta\\). Ovviamente, questo non è assicurato campione per campione.\nUna proprietà tipicamente richiesta è che all’aumentare della dimensione del campione \\(n\\), la distribuzione di \\(\\hat{\\theta}(Y)\\) sia concentrata attorno a \\(\\theta\\)."
  },
  {
    "objectID": "lezioni/un_M.html#ripasso-e-notazione-iii",
    "href": "lezioni/un_M.html#ripasso-e-notazione-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione III",
    "text": "Ripasso e notazione III\nUna prima semplice aspettativa rispetto allo stimatore è che mediamente esso sia corretto o non distorto, ovvero \\[\n    \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\qquad \\theta \\in \\Theta.\n    \\]\nLa **distorsione è infatti definita come la differenza semplice \\[\n    \\text{bias}\\{\\hat{\\theta}(Y)\\}:= \\mathbb{E}\\{\\hat{\\theta}(Y)\\} - \\theta, \\qquad \\theta \\in \\Theta.\n    \\]\nSe uno stimatore è non distorto allora ovviamente \\(\\text{bias}\\{\\hat{\\theta}(Y)\\} = 0\\).\nUn requisito un po’ meno stringente è che lo stimatore sia asintoticamente non distorto, come è tipicamente la stima di massima verosimiglianza, ovvero \\[\n\\lim_{n \\rightarrow \\infty} \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\qquad \\theta \\in \\Theta,\n\\] dove \\(n\\) è la dimensione campionaria."
  },
  {
    "objectID": "lezioni/un_M.html#ripasso-e-notazione-iv",
    "href": "lezioni/un_M.html#ripasso-e-notazione-iv",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione IV",
    "text": "Ripasso e notazione IV\nLa non-distorsione (asintotica) è una proprietà auspicabile, ma spesso meno importante dello errore o scarto quadratico medio.\nLo scarto quadratico medio (mean squared error) misura la distanza media tra stimatore e vero valore del parametro, ovvero \\[\n    \\text{MSE}\\{\\hat{\\theta}(Y)\\} = \\mathbb{E}\\left\\{\\left[\\hat{\\theta}(Y) - \\theta\\right]^2\\right\\}, \\qquad \\theta \\in \\Theta.\n\\]\n\n\n\n\n\n\nEsercizio - proprietà\n\n\n\nDimostrare che vale la seguente scomposizione: \\[\n\\text{MSE}\\{\\theta(Y)\\} = \\text{var}\\left\\{\\hat{\\theta}(Y)\\right\\} + \\text{bias}\\left\\{\\hat{\\theta}(Y)\\right\\}^2, \\qquad \\theta \\in \\Theta.\n\\] Dedurre che se una stimatore è non-distorto, allora il suo scarto quadratico medio coincide con la varianza dello stimatore."
  },
  {
    "objectID": "lezioni/un_M.html#ripasso-e-notazione-v",
    "href": "lezioni/un_M.html#ripasso-e-notazione-v",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione V",
    "text": "Ripasso e notazione V\nUno stimatore si dice consistente in media quadratica se \\[\n\\lim_{n \\rightarrow \\infty} \\text{MSE}\\{\\hat{\\theta}(Y)\\} = 0, \\qquad \\theta \\in \\Theta.\n\\] oppure equivalentemente se \\[\n\\lim_{n \\rightarrow \\infty} \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\quad             \\lim_{n \\rightarrow \\infty} \\text{var}\\{\\hat{\\theta}(Y)\\} = 0, \\qquad \\theta \\in \\Theta.\n\\]\nLa consistenza in media quadratica implica la convergenza in probabilità, per cui scriveremo che \\[\n    \\hat{\\theta}(Y) \\overset{p}{\\longrightarrow} \\theta, \\qquad n \\rightarrow \\infty, \\qquad \\theta \\in \\Theta.\n\\]\n\nEsercizio\nLo studente è invitato a rivedersi la definizione di convergenza in probabilità, le sue proprietà e la sua relazione con la consistenza in media quadratica (in \\(L^2\\)).\n\n\n\n\n\n\nNota linguistica\n\n\n\nIl termine “consistente” deriva da un’errata traduzione del termine inglese consistent. Purtroppo, l’uso del termine è ormai troppo consolidato per porvi rimedio e non resta che subirlo. Lo stesso può dirsi del termine “stima puntuale”."
  },
  {
    "objectID": "lezioni/un_M.html#inferenza-statistica-e-metodi-monte-carlo",
    "href": "lezioni/un_M.html#inferenza-statistica-e-metodi-monte-carlo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Inferenza statistica e metodi Monte Carlo",
    "text": "Inferenza statistica e metodi Monte Carlo\nStabiliti i criteri per valutare la bontà di uno stimatore, rimane da capire come utilizzarli in pratica.\nNei corsi di Statistica II vengono presentati modelli e stimatori per i quali è possibile calcolare l’MSE analiticamente. Questo capita di rado nelle applicazioni reali.\nFortunatamente il metodo Monte Carlo che abbiamo visto nell’unità I può venire in aiuto in assenza di risultati analitici.\nAd esempio, lo scarto quadratico medio è per definizione un valore atteso, che possiamo quindi approssimare tramite integrazione Monte Carlo."
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-i",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota I",
    "text": "Modello gaussiano con varianza nota I\nSia \\(y = (y_1,\\dots,y_n)\\) un campione iid da una variabile casuale normale con media ignota \\(\\mu\\) e varianza nota e pari \\(\\sigma^2 = 16\\), ovvero \\(Y \\sim \\text{N}(\\mu, 16)\\).\nIl parametro \\(\\mu\\) è ignoto e siamo interessati a stimarlo.\nUno stima naturale per \\(\\mu\\), che oltretutto coincide con la SMV, è la media aritmetica \\[\n\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n y_i.\n\\]\nLa distribuzione (esatta!) dello stimatore \\(\\hat{\\mu}(Y)\\) è nota ed è pari \\[\n\\hat{\\mu}(Y) \\sim \\text{N}\\left(\\mu, \\frac{16}{n}\\right).\n\\]\n\nEsercizio\nSi dimostri che \\(\\text{MSE}\\{\\hat{\\mu}(Y)\\} = 16 / n\\). Se ne deduca che lo stimatore è consistente."
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-ii",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota II",
    "text": "Modello gaussiano con varianza nota II\nUn secondo possibile stimatore per \\(\\mu\\) è la mediana campionaria .\nLa distribuzione dello stimatore \\(\\text{Me}(Y)\\) è ignota. Di conseguenza, anche le relative proprietà sono ignote.\nLa mediana è uno stimatore distorto? Il suo scarto è maggiore o minore di quello della media aritmetica?\nIn assenza di risultati analitici, possiamo provare a fornire una risposta parziale tramite Monte Carlo.\nIn altri termini, indagheremo quale stimatore funziona meglio per degli specifici valori di \\(\\mu\\), ad esempio \\(\\mu = 10\\) oppure \\(\\mu = 15\\)."
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-iii",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota III",
    "text": "Modello gaussiano con varianza nota III\nSupponiamo di voler investigare il caso \\(\\mu = 10\\). Supponiamo inoltre che \\(n = 20\\).\nCominciamo simulando un singolo campione \\(y_1,\\dots,y_n\\) da una distribuzione \\(\\text{N}(\\mu, 16)\\).\n\nset.seed(100)\nn <- 20 # Numerosità campionaria\nmu <- 10 # Media teorica (solitamente ignota)\n\n# Campione y_1,...,y_n\ny <- rnorm(n, mean = mu, sd = sqrt(16))\n\n# Vero valore è mu = 10\nmean(y) \n\n[1] 10.43147\n\nmedian(y) \n\n[1] 10.37232\n\n\nIn questo caso specifico, la mediana si avvicina di più al vero valore della media (\\(\\mu = 10\\)). Tuttavia, questo vale per questo specifico campione."
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-iv",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-iv",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota IV",
    "text": "Modello gaussiano con varianza nota IV\nCoerentemente con quanto discusso nei paragrafi precedenti, un modo preciso per valutare la bontà dello stimatore si basa sul campionamento ripetuto.\nIn altri termini, vogliamo confrontare gli scarti quadratici medi dei due stimatori \\[\n\\text{MSE}\\{\\hat{\\mu}(Y)\\}, \\qquad \\text{MSE}\\{\\text{Me}(Y)\\}.\n\\]\nNel caso della media aritmetica con \\(\\sigma^2 = 16\\) ed \\(n = 20\\) i conti analitici implicano che \\(\\text{MSE}\\{\\hat{\\mu}(Y)\\} = 16 / 20 = 0.8\\). Ma nel caso della mediana?\nUtilizzando il metodo Monte Carlo, ottengo una stima dello scarto quadratico medio dello stimatore mediana, ovvero \\[\n\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}}.\n\\]\n\nEsercizio\nLo studente rilegga questa frase fino a convincersi della sua correttezza."
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-v",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-v",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota V",
    "text": "Modello gaussiano con varianza nota V\nL’approssimazione \\(\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}}\\) si basa sul metodo di integrazione Monte Carlo.\nSi supponga che \\(\\text{Me}_1, \\dots, \\text{Me}_R\\) siano \\(R\\) estrazioni casuali della mediana calcolata su un campione iid gaussiano (\\(\\mu = 10\\), \\(\\sigma^2 = 16\\)) di dimensione \\(n = 20\\).\nPossiamo ottenere \\(\\text{Me}_1, \\dots, \\text{Me}_R\\) simulando \\(R\\) campioni \\(Y\\) e calcolandone la mediana:\n\nset.seed(156)\nR <- 10^5\n# Ottengo R estrazioni della mediana campionaria Me_1,...Me_R\nmedian_hat <- replicate(R, median(rnorm(n = n, mean = mu, sd = sqrt(16))))\n\nL’approssimazione Monte Carlo è quindi pari a \\[\n\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}} = \\frac{1}{R}\\sum_{r=1}^R(\\text{Me}_r - \\mu)^2 \\approx \\mathbb{E}\\{ (\\text{Me}(Y) - \\mu)^2\\} = \\text{MSE}\\{\\text{Me}(Y)\\}.\n\\]\n\nmean((median_hat - mu)^2) # Stima dello scarto quadratico medio (MSE) della mediana\n\n[1] 1.172079"
  },
  {
    "objectID": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-vi",
    "href": "lezioni/un_M.html#modello-gaussiano-con-varianza-nota-vi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Modello gaussiano con varianza nota VI",
    "text": "Modello gaussiano con varianza nota VI\nLa mediana sembra essere meno efficiente della media aritmetica, quantomeno se \\(\\mu = 10, \\sigma^2 =16\\) ed \\(n = 20\\).\nNel seguito sono riportati alcuni risultati aggiuntivi, incluse le stime Monte Carlo relative alla media aritmetica.\n\nset.seed(156)\nR <- 10^5\n\nmu_hat <- replicate(R, mean(rnorm(n = n, mean = mu, sd = sqrt(16))))\nmedian_hat <- replicate(R, median(rnorm(n = n, mean = mu, sd = sqrt(16))))\n\nmean(mu_hat) - mu # Distorsione dello stimatore; valore teorico: 0\n\n[1] -0.004089293\n\nmean((mu_hat - mu)^2) # Scarto quadratico medio dello stimatore; valore teorico: 0.8\n\n[1] 0.8008738\n\nmean(median_hat) - mu # Distorsione dello stimatore; valore teorico: ??\n\n[1] -0.001820327\n\nmean((median_hat - mu)^2) # Scarto quadratico medio dello stimatore; valore teorico: ??\n\n[1] 1.172248"
  },
  {
    "objectID": "lezioni/un_M.html#distribuzione-degli-stimatori",
    "href": "lezioni/un_M.html#distribuzione-degli-stimatori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione degli stimatori",
    "text": "Distribuzione degli stimatori\n\npar(mfrow = c(1, 2))\nhist(mu_hat, breaks = 100, freq = F)\nhist(median_hat, breaks = 100, freq = F)"
  },
  {
    "objectID": "lezioni/un_M.html#commenti-conclusivi",
    "href": "lezioni/un_M.html#commenti-conclusivi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Commenti conclusivi",
    "text": "Commenti conclusivi\nLe approssimazioni coinvolte in questa ultima discussione sono di due differenti tipologie.\nDa un lato abbiamo la variabilità di \\(\\hat{\\theta}\\), che è legata ai dati \\(y_1,\\dots,y_n\\) e alla loro numerosità campionaria \\(n\\).\nDall’altro abbiamo la variabilità Monte Carlo di \\(\\widehat{\\text{MSE}\\{\\theta(Y)\\}}\\), che è invece legata alle repliche Monte Carlo e al numero di simulazioni \\(R\\).\nQuesti due concetti sono ben distinti e non vanno confusi tra loro.\nInoltre, mentre aumentare il numero di simulazioni \\(R\\) è sempre possibile (basta aspettare più tempo), non sempre disponiamo di dati aggiuntivi."
  },
  {
    "objectID": "lezioni/un_M.html#esercizio-riassuntivo",
    "href": "lezioni/un_M.html#esercizio-riassuntivo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo",
    "text": "Esercizio riassuntivo\nSi supponga che \\(Y_1,\\dots,Y_n\\) sono variabili aleatorie iid distribuite come un normale di media nota \\(\\mathbb{E}(Y_1) = 0\\), con \\(n = 20\\).\nLa varianza \\(\\sigma^2\\) è ignota e siamo interessati a stimarla.\nSi calcolino tramite simulazione la distorsione e l’errore quadratico dei seguenti stimatori della varianza, quando \\(\\sigma^2 = 16\\):\n\\[\n\\begin{aligned}\n    &S^2_1 = \\frac{1}{n}\\sum_{i=1}^n(Y_i - \\bar{Y})^2, &&\\quad S^2_2 = \\frac{1}{n -1}\\sum_{i=1}^n(Y_i - \\bar{Y})^2, \\\\\n    &S^2_3 = \\frac{1}{n}\\sum_{i=1}^nY_i^2, && \\quad S_4 = \\frac{1}{n+1}\\sum_{i=1}^n(Y_i - \\bar{Y})^2.\n\\end{aligned}\n\\]\n\nSchema della soluzione\n\nset.seed(520)\nR <- 10^5; n <- 20\nmu <- 0; sigma2 <- 16\n\n# Definisco le funzioni che calcolano gli stimatori\nvar1 <- function(x) mean(x^2) - mean(x)^2\nvar2 <- function(x) var(x) # Coincide con la definizione di R\nvar3 <- function(x) mean(x^2)\nvar4 <- function(x) (length(x) - 1) / (length(x) + 1) * var(x)\n\n# Esecuzione della simulazione\nS2_1 <- replicate(R, var1(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\nS2_2 <- replicate(R, var2(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\nS2_3 <- replicate(R, var3(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\nS2_4 <- replicate(R, var4(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\n\n# Distorsioni (approssimate)\nround(mean(S2_1 - sigma2), 2)\n\n[1] -0.85\n\nround(mean(S2_2 - sigma2), 2)\n\n[1] 0\n\nround(mean(S2_3 - sigma2), 2)\n\n[1] -0.03\n\nround(mean(S2_4 - sigma2), 2)\n\n[1] -1.56\n\n# Errore quadratico medio (approssimato)\nmean((S2_1 - sigma2)^2)\n\n[1] 24.96644\n\nmean((S2_2 - sigma2)^2)\n\n[1] 27.09368\n\nmean((S2_3 - sigma2)^2)\n\n[1] 25.40207\n\nmean((S2_4 - sigma2)^2)\n\n[1] 24.36703"
  },
  {
    "objectID": "lezioni/un_M.html#consistenza-i",
    "href": "lezioni/un_M.html#consistenza-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Consistenza I",
    "text": "Consistenza I\nSia \\(y_1,\\dots,y_n\\) un campione iid da una distribuzione uniforme in \\((0,\\theta)\\), dove \\(\\theta > 0\\) è un parametro ignoto. La stima di massima verosimiglianza in questo caso è pari a \\[\n\\hat{\\theta}_n = \\max\\{X_1,\\dots,X_n\\}.\n\\]\nVogliamo verificare tramite simulazione se lo stimatore è consistente, ovvero se \\[\n\\hat{\\theta}(Y) \\overset{p}{\\longrightarrow} \\theta.\n\\]\nIn pratica, ciò che possiamo fare è simulare alcuni valori di \\(\\hat{\\theta}\\) per valori di \\(n\\) crescenti e controllare se questi si avvicinano sempre più a \\(\\theta\\)."
  },
  {
    "objectID": "lezioni/un_M.html#consistenza-ii",
    "href": "lezioni/un_M.html#consistenza-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Consistenza II",
    "text": "Consistenza II\nSupponiamo che il vero valore del parametro sia \\(\\theta = 40\\).\n\ntheta0 <- 40\n\n# Numerosità campionarie\nnn <- c(10, 100, 300, 500, 1000)\n\n# Stime di massima verosimiglianza\nset.seed(123)\ntheta_hat <- c(\n  max(runif(nn[1], min = 0, max = theta0)),\n  max(runif(nn[2], min = 0, max = theta0)),\n  max(runif(nn[3], min = 0, max = theta0)),\n  max(runif(nn[4], min = 0, max = theta0)),\n  max(runif(nn[5], min = 0, max = theta0))\n)\ntheta_hat\n\n[1] 37.61869 39.77079 39.97618 39.86469 39.98096\n\n\nAll’aumentare di \\(n\\), lo stimatore tende a diventare sempre più preciso. Per valori di \\(n\\) ancora maggiori di \\(1000\\), la precisione aumenta ulteriormente."
  },
  {
    "objectID": "lezioni/un_M.html#consistenza-iii",
    "href": "lezioni/un_M.html#consistenza-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Consistenza III",
    "text": "Consistenza III\n\npar(mfrow=c(1,1))\nplot(nn, theta_hat,\n  type = \"b\",\n  xlab = \"Numerosità campionaria\",\n  ylab = \"Massima verosimiglianza\"\n)"
  },
  {
    "objectID": "lezioni/un_H.html",
    "href": "lezioni/un_H.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Variabili aleatorie discrete\nVariabili aleatorie continue\nSimulazione di valori (pseudo) casuali\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_H.html#variabili-aleatorie-ripasso",
    "href": "lezioni/un_H.html#variabili-aleatorie-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili aleatorie (ripasso)",
    "text": "Variabili aleatorie (ripasso)\nLa definizione formale di una variabile aleatoria coinvolge concetti di teoria della misura (\\(\\sigma\\)-algebre, misure di probabilità, etc), che lasceremo sullo sfondo.\nAi fini di questo corso, ci è sufficiente ricordare che una variabile aleatoria \\(X\\) a valori reali è univocamente identificata dalla sua funzione di ripartizione, ovvero \\[\nF(x) := \\mathbb{P}(X \\le x).\n\\]\nSe la funzione \\(F(x)\\) è costante a tratti, diremo che \\(X\\) è una variabile aleatoria discreta.\nSe la funzione \\(F(x)\\) è continua, diremo che \\(X\\) è una variabile aleatoria continua.\n\n\n\n\n\n\nSuggerimento\n\n\n\nNel caso non vi ricordaste la definizione di una variabile aleatoria è bene ricontrollare libri e appunti del corso Calcolo delle Probabilità!"
  },
  {
    "objectID": "lezioni/un_H.html#variabili-aleatorie-discrete-i-ripasso",
    "href": "lezioni/un_H.html#variabili-aleatorie-discrete-i-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili aleatorie discrete I (ripasso)",
    "text": "Variabili aleatorie discrete I (ripasso)\nCome anticipato, una variabile aleatoria si dice discreta se \\(F(x)\\) è costante a tratti.\nPiù precisamente, diremo che \\(X\\) è una variabile aleatoria discreta se esiste un insieme di cardinalità numerabile \\(\\mathcal{S} \\subseteq \\mathbb{R}\\), chiamato supporto, tale per cui \\[\n\\mathbb{P}(X \\in \\mathcal{S}) = \\sum_{x \\in \\mathcal{S}} \\mathbb{P}(X = x) = 1.\n\\]\nIn pratica, spesso avremo che il supporto \\(\\mathcal{S} \\subseteq \\{0, 1, 2, \\dots\\}\\) è un sotto-insieme dei numeri naturali. Inoltre, il supporto \\(\\mathcal{S}\\) può essere finito.\nIntuitivamente, diremo che la variabile aleatoria \\(X\\) può assumere solamente i valori del supporto \\(\\mathcal{S}\\)."
  },
  {
    "objectID": "lezioni/un_H.html#variabili-aleatorie-discrete-ii-ripasso",
    "href": "lezioni/un_H.html#variabili-aleatorie-discrete-ii-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili aleatorie discrete II (ripasso)",
    "text": "Variabili aleatorie discrete II (ripasso)\nLa funzione di probabilità di una variabile aleatoria discreta è pari a \\[\np(x) = \\mathbb{P}(X = x).\n\\]\nLa funzione \\(p(x)\\) identifica una variabile aleatoria discreta.\nPertanto, ovviamente, vale che \\(p(x) \\ge 0\\) e che \\(\\sum_{x \\in \\mathcal{S}} p(x) = 1\\).\nIl valore atteso di una variabile aleatoria è inoltre definito, se esiste, come \\[\n\\mathbb{E}(X) = \\sum_{x \\in \\mathcal{S}} x \\: p(x).\n\\]\nPiù in generale, il valore atteso di una trasformazione \\(g(X)\\), se esiste, è pari a \\[\n\\mathbb{E}\\{g(X)\\} = \\sum_{x \\in \\mathcal{S}} g(x) \\: p(x).\n\\]"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-binomiale-funzione-di-probabilità",
    "href": "lezioni/un_H.html#distribuzione-binomiale-funzione-di-probabilità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione binomiale (funzione di probabilità)",
    "text": "Distribuzione binomiale (funzione di probabilità)\nSia \\(X \\sim \\text{Bin}(n, \\pi)\\) una variabile aleatoria binomiale, per cui la funzione di probabilità è \\[\n\\mathbb{P}(X = k) = {n \\choose k } \\pi^k (1-\\pi)^{n-k}, \\qquad k=0,1,\\dots,n.\n\\]\nSupponendo che \\(n = 10\\) e \\(\\pi = 0.6\\), allora \\(\\mathbb{P}(X=4)\\) si calcola come segue:\n\nn <- 10 # Numero di tentativi\np <- 0.6 # Probabilità di successo\nk <- 4 # Numero di successi\n\nchoose(n, k) * p^k * (1 - p)^(n - k)\n\n[1] 0.1114767\n\n\nTuttavia, in R esiste una funzione apposita per il calcolo della funzione di probabilità:\n\ndbinom(k, size = n, prob = p)\n\n[1] 0.1114767"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-binomiale-funzione-di-ripartizione",
    "href": "lezioni/un_H.html#distribuzione-binomiale-funzione-di-ripartizione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione binomiale (funzione di ripartizione)",
    "text": "Distribuzione binomiale (funzione di ripartizione)\nIn maniera simile, possiamo anche calcolare la probabilità seguente, ovvero\n\\[\nF(x) =   \\mathbb{P}(X \\le x) = \\sum_{k=0}^x\\mathbb{P}(X = k), \\qquad X \\sim \\text{Bin}(n, \\pi).\n\\]\nSupponendo che \\(n = 10\\) e \\(\\pi = 0.6\\), allora il valore \\(F(5)\\) si calcola come segue:\n\nsum(dbinom(0:5, size = n, prob = p))\n\n[1] 0.3668967\n\npbinom(5, size = n, prob = p) # Funzione specifica di R\n\n[1] 0.3668967\n\n\nSupponiamo di essere invece interessati all’evento complementare, ovvero: \\[\n\\mathbb{P}(X > 5) = 1 - \\mathbb{P}(X \\le 5).\n\\]\n\n1 - pbinom(5, size = n, prob = p)\n\n[1] 0.6331033\n\npbinom(5, size = n, prob = p, lower.tail = FALSE)\n\n[1] 0.6331033"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-binomiale-valore-atteso",
    "href": "lezioni/un_H.html#distribuzione-binomiale-valore-atteso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione binomiale (valore atteso)",
    "text": "Distribuzione binomiale (valore atteso)\nIl valore atteso di una variabile aleatoria binomiale è pari a\n\\[\n\\mathbb{E}(X) = \\sum_{k=0}^n k \\: \\mathbb{P}(X = k) =  np, \\qquad X \\sim \\text{Bin}(n,p).\n\\]\nSupponendo come in precedenza che \\(n = 10\\) e \\(\\pi = 0.6\\), si ha che:\n\nn * p # Valore atteso ottenuto tramite calcoli analitici\n\n[1] 6\n\nsum(0:n * dbinom(0:n, size = n, prob = 0.6)) # Calcolo numerico\n\n[1] 6\n\n\nTramite il calcolo diretto, possiamo inoltre valutare ad esempio \\(\\mathbb{E}(\\sqrt{X})\\), infatti:\n\nsum(sqrt(0:n) * dbinom(0:n, size = n, prob = 0.6))\n\n[1] 2.427083\n\n\n\n\n\n\n\n\nNota\n\n\n\nIl calcolo del valore atteso è “semplice” quando il supporto della distribuzione discreta è finito."
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-binomiale-quantili",
    "href": "lezioni/un_H.html#distribuzione-binomiale-quantili",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione binomiale (quantili)",
    "text": "Distribuzione binomiale (quantili)\nIl quantile-\\(p\\) una distribuzione discreta è il più piccolo valore \\(k\\) tale \\(\\mathbb{P}(X \\le k) \\ge p\\). Quindi: \\[\n\\mathcal{Q}(p) = \\inf\\{x \\in \\mathbb{R} : F(x) \\ge p \\}.\n\\]\nSupponendo che \\(X \\sim \\text{Bin}(10, 0.6)\\), ad esempio il primo quartile è\n\\[\n\\mathcal{Q}(0.25) = \\inf\\{x \\in \\mathbb{R} : F(x) \\ge 0.25 \\} = 5.\n\\]\nIn R possiamo ottenere questi risultati come segue:\n\nqbinom(0.25, size = 10, prob = 0.6) # Primo quartile\n\n[1] 5\n\n\nInfatti, vale che:\n\npbinom(4, size = 10, prob = 0.6) # Il valore è minore di 0.25\n\n[1] 0.1662386\n\npbinom(5, size = 10, prob = 0.6) # Il valore è maggiore di 0.25\n\n[1] 0.3668967"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-binomiale-rappresentazione-grafica",
    "href": "lezioni/un_H.html#distribuzione-binomiale-rappresentazione-grafica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione binomiale (rappresentazione grafica)",
    "text": "Distribuzione binomiale (rappresentazione grafica)\n\nkk <- 0:n\nprob <- dbinom(0:n, size = n, prob = p)\nplot(kk, prob, type = \"h\", main = \"Bin(10,0.6)\", xlab = \"k\", ylab = \"P(X=k)\")"
  },
  {
    "objectID": "lezioni/un_H.html#variabili-aleatorie-continue-i-ripasso",
    "href": "lezioni/un_H.html#variabili-aleatorie-continue-i-ripasso",
    "title": "R per l’analisi statistica multivariata",
    "section": "Variabili aleatorie continue I (ripasso)",
    "text": "Variabili aleatorie continue I (ripasso)\nUna variabile aleatoria si dice continua se \\(F(x)\\) è continua.\nLa funzione di densità di una variabile aleatoria continua è una funzione \\(f(x) \\ge 0\\) tale per cui \\[\n\\mathbb{P}(a < X < b) = \\int_a^b f(x) \\mathrm{d} x, \\qquad f(x) = \\frac{\\partial}{\\partial x} F(x).\n\\]\nPertanto, per definizione: \\[\n\\mathbb{P}(X \\le b) = F(b) = \\int_{-\\infty}^b f(x) \\mathrm{d} x.\n\\]\nInoltre, il valore atteso di una trasformazione \\(g(X)\\), se esiste, è pari a \\[\n\\mathbb{E}\\{g(X)\\} = \\int_{\\mathbb{R}} g(x) \\: f(x) \\mathrm{d} x.\n\\]"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-normale-funzione-di-densità",
    "href": "lezioni/un_H.html#distribuzione-normale-funzione-di-densità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione normale (funzione di densità)",
    "text": "Distribuzione normale (funzione di densità)\nSia \\(X \\sim \\text{N}(\\mu, \\sigma^2)\\) una variabile gaussiana di media \\(\\mu\\) e varianza \\(\\sigma^2\\), ovvero avente densità \\[\nf(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\right\\}.\n\\]\nSe \\(X \\sim \\text{N}(3, 10)\\) allora possiamo calcolare il valore \\(f(1)\\) utilizzando i comandi di R:\n\nx <- 1 # Punto in cui calcolare f(x)\nmu <- 3 # Media\nsigma2 <- 10 # Varianza\n\n1 / sqrt(2 * pi * sigma2) * exp(-1 / (2 * sigma2) * (x - mu)^2)\n\n[1] 0.1032883\n\ndnorm(x, mean = 3, sd = sqrt(sigma2))\n\n[1] 0.1032883\n\n\n\n\n\n\n\n\nNota\n\n\n\nIl comando dnorm ha come argomento lo scarto quadratico medio \\(\\sigma\\), non la varianza \\(\\sigma^2\\)."
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-normale-funzione-di-ripartizione",
    "href": "lezioni/un_H.html#distribuzione-normale-funzione-di-ripartizione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione normale (funzione di ripartizione)",
    "text": "Distribuzione normale (funzione di ripartizione)\nSia \\(X \\sim \\text{N}(0,1)\\) una normale standard. Siamo interessati a calcolare la probabilità dell’evento seguente: \\[\n\\mathbb{P}(|X| \\le 1) = \\mathbb{P}(-1 \\le X \\le 1) = \\mathbb{P}(X \\le 1) - \\mathbb{P}(X < -1).\n\\]\nPossiamo calcolare questa probabilità (in modo inefficiente) tramite il comando integrate, pertanto:\n\nintegrate(dnorm, lower = -1, upper = 1)\n\n0.6826895 with absolute error < 7.6e-15\n\n\nTrattandosi di una variabile continua, otteniamo che \\(\\mathbb{P}(X < -1) = \\mathbb{P}(X \\le -1)\\).\nQuindi, possiamo calcolare questa probabilità in R utilizzando i comandi appositi:\n\npnorm(1) - pnorm(-1)\n\n[1] 0.6826895"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-normale-funzione-quantile",
    "href": "lezioni/un_H.html#distribuzione-normale-funzione-quantile",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione normale (funzione quantile)",
    "text": "Distribuzione normale (funzione quantile)\nLa continuità della funzione di ripartizione \\(F(x)\\) implica che la funzione quantile è pari a \\(\\mathcal{Q}(\\cdot) = F^{-1}(\\cdot)\\).\nPer esempio, si consideri il terzo quartile di una distribuzione normale standard, ovvero\n\nqnorm(0.75)\n\n[1] 0.6744898\n\n\nDi conseguenza, la funzione quantile e di ripartizione sono tale per cui \\[\nF(\\mathcal{Q}(0.75)) = F(F^{-1}(0.75))= 0.75.\n\\]\nInfatti:\n\npnorm(qnorm(0.75))\n\n[1] 0.75"
  },
  {
    "objectID": "lezioni/un_H.html#distribuzione-normale-rappresentazione-grafica",
    "href": "lezioni/un_H.html#distribuzione-normale-rappresentazione-grafica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione normale (rappresentazione grafica)",
    "text": "Distribuzione normale (rappresentazione grafica)\n\ncurve(dnorm(x, mean = 0, sd = 1), from = -3, to = 3, ylab = \"f(x)\", main = \"N(0,1)\")"
  },
  {
    "objectID": "lezioni/un_H.html#tabella-riassuntiva-i",
    "href": "lezioni/un_H.html#tabella-riassuntiva-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Tabella riassuntiva I",
    "text": "Tabella riassuntiva I\nR dispone di un’estesa collezione di funzioni dedicate alle principali distribuzioni di probabilità. Sia \\(X\\) una variabile casuale.\n\nddist (dove la d iniziale sta per density). Calcola la densità \\(f(x)\\) di una variabile continua \\(X\\) oppure la funzione di probabilità \\(p(x) = \\mathbb{P}(X = x)\\) nel caso \\(X\\) sia discreta.\npdist (dove la p iniziale sta per probability), che permette di calcolare il valore della funzione di ripartizione in un punto specificato, ovvero calcola \\(F(x) = \\mathbb{P}(X \\le x)\\).\nqdist (dove la q iniziale sta per quantile), che rappresenta la funzione quantile, ovvero: \\[\n\\mathcal{Q}(p) = \\inf\\{x \\in \\mathbb{R} : F(x) \\ge p\\}, \\qquad p \\in (0,1).\n\\]\nrdist (dove la r iniziale sta per random), che permette di generare numeri pseudo-casuali, che verranno illustrati nel seguito."
  },
  {
    "objectID": "lezioni/un_H.html#tabella-riassuntiva-ii",
    "href": "lezioni/un_H.html#tabella-riassuntiva-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Tabella riassuntiva II",
    "text": "Tabella riassuntiva II\n\n\n\nDistribuzione\nComando\nParametri\nDefault\n\n\n\n\nBinomiale\nbinom\nsize, prob\n-\n\n\nGeometrica\ngeom\nprob\n-\n\n\nPoisson\npois\nlambda\n-\n\n\nUniforme\nunif\nmin, max\n0, 1\n\n\nGamma\ngamma\nshape, rate\n-, 1\n\n\nEsponenziale\nexp\nrate\n1\n\n\nChi-quadrato\nchisq\ndf\n-\n\n\nNormale\nnorm\nmean, sd\n\n\n\n\n\n\n\n\n\n\nDanger\n\n\n\nAttenzione alla parametrizzazioni e/o ai significati degli argomenti. Si consulti la documentazione per sapere come sono definiti.\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\nSi rappresentino graficamente tutte le precedenti distribuzioni, per diverse scelte dei parametri."
  },
  {
    "objectID": "lezioni/un_H.html#numeri-pseudo-casuali-i",
    "href": "lezioni/un_H.html#numeri-pseudo-casuali-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Numeri pseudo-casuali I",
    "text": "Numeri pseudo-casuali I\nLa quarta classe di funzioni nella nostra lista è quella del tipo rdist, che permette quindi di ottenere dei valore casuali da una distribuzione.\nPer esempio, per campionare \\(5\\) valori indipendenti e identicamente distribuiti (iid) da una normale standard, ovvero \\[\nX_i \\overset{\\text{iid}}{\\sim} \\text{N}(0,1), \\qquad i=1,\\dots,5\n\\] possiamo usare in R il comando seguente:\n\nR <- 5\nrnorm(R, mean = 0, sd = 1)\n\n[1] -1.08255361  0.03147159  0.63943560  1.76963639 -0.61448717"
  },
  {
    "objectID": "lezioni/un_H.html#numeri-pseudo-casuali-ii",
    "href": "lezioni/un_H.html#numeri-pseudo-casuali-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Numeri pseudo-casuali II",
    "text": "Numeri pseudo-casuali II\nI valori generati dal comando rdist imitano i risultati di un processo casuale, ma sono in realtà deterministici. Tali valori sono quindi chiamati pseudo-casuali.\nEsistono in realtà dei metodi per generare numeri davvero casuali, basate ad esempio su rilevazioni atmosferiche.\nAl sito https://www.random.org/gaussian-distributions/ è possibile ottenere un numero limitato di valori casuali da una distribuzione gaussiana.\nLo svantaggio di quest’ultima classe di metodi è che sono relativamente costosi da ottenere \\(\\implies\\) ne vale la pena?\nA meno che non sussistano specifici problemi di sicurezza, i numeri pseudo-casuali costituiscono lo standard usato dalla quasi totalità degli utenti."
  },
  {
    "objectID": "lezioni/un_H.html#numeri-pseudo-casuali-in-01",
    "href": "lezioni/un_H.html#numeri-pseudo-casuali-in-01",
    "title": "R per l’analisi statistica multivariata",
    "section": "Numeri pseudo-casuali in \\((0,1)\\)",
    "text": "Numeri pseudo-casuali in \\((0,1)\\)\nSupponiamo di saper simulare dei valori \\(U_1,\\dots,U_n\\) da una distribuzione uniforme in \\((0,1)\\), ovvero quanto si ottiene ad esempio tramite il comando runif.\nPossiamo “facilmente” ottenere i valori casuali di una qualsiasi distribuzione considerando un’opportuna trasformazione dei valori \\(U_1,\\dots,U_n\\).\nLa parte difficile è quindi simulare valori pseudo-casuali \\(U_1,\\dots,U_n\\) in maniera tale che questi assomiglino il più possibile a realizzazioni iid da una distribuzione uniforme.\nTrattandosi di numeri pseudo-casuali, siamo quindi alla ricerca di un vero e proprio algoritmo che a partire da delle condizioni iniziali, produca \\(U_1,\\dots,U_n\\).\nLa condizione iniziale viene tipicamente chiamata seme (seed)."
  },
  {
    "objectID": "lezioni/un_H.html#numeri-pseudo-casuali-in-01-1",
    "href": "lezioni/un_H.html#numeri-pseudo-casuali-in-01-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Numeri pseudo-casuali in \\((0,1)\\)",
    "text": "Numeri pseudo-casuali in \\((0,1)\\)\nPresentiamo un metodo molto semplice per generare numeri pseudo-casuali (Wichmann & Hill, 1982), che tuttavia è stato molto popolare negli anni ’80 e ’90."
  },
  {
    "objectID": "lezioni/un_H.html#algoritmo-wichmann-hill-1982",
    "href": "lezioni/un_H.html#algoritmo-wichmann-hill-1982",
    "title": "R per l’analisi statistica multivariata",
    "section": "Algoritmo Wichmann & Hill (1982)",
    "text": "Algoritmo Wichmann & Hill (1982)\nVogliamo ottenere delle realizzazioni \\(u_1,\\dots, u_n\\) da una distribuzione uniforme \\((0,1)\\).\n\nInizializzazione. Si parte da tre numeri interi qualsiasi \\(x_0, y_0, z_0\\), che costituiscono la condizione iniziale, il cosiddetto seed.\nAggiornamento iterativo del seme. A ciascuna iterazione, si aggiornano i \\(3\\) numeri \\(x_i, y_i, z_i\\) a partire da quelli ottenuti alla iterazione precedente: \\[\n  \\begin{aligned}\n  x_i = (171 \\times x_{i-1})(\\text{mod}\\:30269) \\\\\n  y_i = (172 \\times y_{i-1})(\\text{mod}\\:30307) \\\\\n  z_i = (170 \\times z_{i-1})(\\text{mod}\\:30323) \\\\\n  \\end{aligned}\n\\] per ogni \\(i=1,\\dots,n\\). La funzione \\(\\text{mod}\\) (equivalente a %% in R) calcola il resto, per cui ad esempio \\(205 (\\text{mod}\\:10) = 5\\).\nOutput. Si ottiene una sequenza di realizzazioni come segue: \\[\nu_i = \\left(\\frac{x_i}{30269} + \\frac{y_i}{30307} + \\frac{z_i}{30323} \\right)(\\text{mod}\\: 1), \\qquad i=1,\\dots,n.\n\\]"
  },
  {
    "objectID": "lezioni/un_H.html#algoritmo-wichmann-hill-1982-1",
    "href": "lezioni/un_H.html#algoritmo-wichmann-hill-1982-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Algoritmo Wichmann & Hill (1982)",
    "text": "Algoritmo Wichmann & Hill (1982)\nL’algoritmo pertanto aggiorna iterativamente la condizione iniziale (seed). I valori finali \\(x_n, y_n, z_n\\) possono essere usati come seed per estrazioni successive.\nNon c’è nulla di “casuale” in questa sequenza di numeri. Per definizione, se i tre numeri di partenza \\(x_0, y_0, z_0\\) sono gli stessi, l’output sarà sempre uguale.\nQuesto algoritmo ha periodo circa pari a \\(m = 6.95 \\times 10^{12}\\). Pertanto \\[\nu_{i + m} = u_i.\n\\]\nPertanto, se eseguissimo questo metodo per un tempo sufficientemente lungo, la sequenza di numeri ottenuti è destinata a ripetersi!\nUna sequenza che si ripete è un problema? In teoria si, in pratica \\(m\\) negli algoritmi moderni (\\(m \\approx 2^{19937}\\)) è talmente grande che questo fattore è trascurabile.\n\n\n\n\n\n\nNota\n\n\n\nLa sequenza ottenuta andrebbe testata per verificare che in effetti “sembri” casuale ed uniforme in \\((0,1)\\)."
  },
  {
    "objectID": "lezioni/un_H.html#algoritmo-wichmann-hill-1982-2",
    "href": "lezioni/un_H.html#algoritmo-wichmann-hill-1982-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Algoritmo Wichmann & Hill (1982)",
    "text": "Algoritmo Wichmann & Hill (1982)\n\nrunif.wh <- function(n) {\n  a <- c(171, 172, 170)\n  b <- c(30269, 30307, 30323)\n  s <- .current.seed # Il seed corrent è presente nel \"global environment\"\n  u <- rep(0, n) # Inizializzazione dell'output\n  for (i in 1:n) {\n    s <- (a * s) %% b\n    u[i] <- sum(s / b) %% 1\n  }\n  .current.seed <<- s # Salva il seed finale nel \"global environment\"\n  u\n}\n\n.current.seed <- c(123, 456, 789)\nrunif.wh(5)\n\n[1] 0.7061613 0.9181272 0.1477225 0.6591895 0.3623401\n\n.current.seed\n\n[1] 24178  7775  9310"
  },
  {
    "objectID": "lezioni/un_H.html#simulazione-di-variabili-discrete",
    "href": "lezioni/un_H.html#simulazione-di-variabili-discrete",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simulazione di variabili discrete",
    "text": "Simulazione di variabili discrete\nSupponiamo di voler estrarre dei valori iid \\(X_1,\\dots,X_n\\) da una legge discreta.\nPer semplicità, assumiamo che il supporto \\(\\mathcal{S} = \\{x_1, \\dots, x_K\\}\\) sia finito e che \\((\\pi_1,\\dots,\\pi_K)\\) siano le probabilità associate, per cui \\[\n\\mathbb{P}(X_i = x_k) = \\pi_k, \\qquad k=1,\\dots,K.\n\\]\nA partire dalle variabili uniformi \\(U_1,\\dots,U_n\\) in \\((0,1)\\) è semplice ottenere \\(X_1,\\dots,X_n\\).\nDividiamo l’intervallo \\((0,1)\\) in \\(K\\) sotto-intervalli, ciascuno di lunghezza \\(\\pi_k\\). Il valore \\(X_i\\) corrisponde al valore associato all’intervallo a cui \\(U_i\\) appartiene.\nInfatti, sia \\(a_0 = 0\\) e \\((a_{k-1}, a_k)\\) il \\(k\\)-esimo intervallo tale che \\(a_k - a_{k-1} = \\pi_k\\). Allora \\[\n\\mathbb{P}(a_{k-1} < U_i < a_k) = \\pi_k \\implies \\mathbb{P}(X_i = x_k) = \\pi_k,\n\\] per \\(k=1,\\dots,K\\)."
  },
  {
    "objectID": "lezioni/un_H.html#esempio-distribuzione-binomiale",
    "href": "lezioni/un_H.html#esempio-distribuzione-binomiale",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esempio: distribuzione binomiale",
    "text": "Esempio: distribuzione binomiale\nPossiamo sfruttare la nostra funzione runif.wh per ottenere valori pseudo-casuali da una distribuzione binomiale.\n\nrbinom.wh <- function(n, size, prob) {\n  u <- runif.wh(n)\n  probs <- dbinom(0:size, size = size, prob = prob)\n  breaks <- cumsum(c(0, probs))\n  as.numeric(cut(u, breaks)) - 1 # Converte la variabile \"factor\" in numeri interi\n}\n\n.current.seed <- c(100, 200, 300)\nrbinom.wh(20, size = 5, prob = 0.5)\n\n [1] 2 3 2 2 1 2 4 2 1 4 3 3 0 3 2 4 4 2 4 4\n\n\n\n\n\n\n\n\nNota\n\n\n\nQuesto codice è riportato a soli fini didattici. In realtà, esistono modi più intelligenti (e molto più veloci!) per ottenere questo risultato."
  },
  {
    "objectID": "lezioni/un_H.html#esempio-il-lancio-di-un-dado-a-sei-facce",
    "href": "lezioni/un_H.html#esempio-il-lancio-di-un-dado-a-sei-facce",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esempio: il lancio di un dado a sei facce",
    "text": "Esempio: il lancio di un dado a sei facce\nUn dado a sei facce rappresenta una variabile casuale discreta \\(X\\) con funzione di probabilità chiamata Uniforme Discreta, ovvero\n\\[\n\\mathbb{P}(X = k) = \\frac{1}{6}, \\qquad k=1,\\dots,6.\n\\]\nPer simulare lancio di un dado a sei facce, costruiamo anzitutto un vettore contenente una sequenza di numeri da 1 a 6 corrispondenti ai possibili esiti del lancio.\n\ndice <- 1:6\n\nPossiamo usare il comando sample per effettuare il lancio:\n\nset.seed(123) # Comando di R per identificare il \"seed\"\nsample(x = dice, size = 1) # size = 1 implica che viene lanciato un solo dado\n\n[1] 3\n\n\n\n\n\n\n\n\nNota\n\n\n\nIl comando set.seed(numero) è il comando che consente di fissare il seme in R."
  },
  {
    "objectID": "lezioni/un_H.html#il-comando-sample",
    "href": "lezioni/un_H.html#il-comando-sample",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il comando sample",
    "text": "Il comando sample\nPiù in generale, la funzione sample(x, size, replace, prob) estrae casualmente un numero size di elementi da un’urna contenente gli oggetti x\n\ncon reinserimento, se replace = TRUE;\nsenza reinserimento, se replace = FALSE.\n\nSe l’argomento prob non viene specificato, la funzione sample assegna ad ogni elemento di x uguale probabilità.\nSe volessimo campionare con probabilità non uniformi, dovremmo indicare un vettore di probabilità di lunghezza pari agli elementi di x (provate per esercizio!)"
  },
  {
    "objectID": "lezioni/un_H.html#campionamento-con-reinserimento",
    "href": "lezioni/un_H.html#campionamento-con-reinserimento",
    "title": "R per l’analisi statistica multivariata",
    "section": "Campionamento con reinserimento",
    "text": "Campionamento con reinserimento\nIl campionamento con reinserimento equivale a fare \\(n\\) estrazioni indipendenti dalla stessa variabile aleatoria \\(X\\). Pertanto, per lanciare lo stesso dado \\(10\\) volte:\n\nset.seed(140)\nn <- 10\n# replace = TRUE implica che il dado è lanciato 10 volte\nsim <- sample(dice, size = n, replace = TRUE)\nsim\n\n [1] 3 1 1 1 3 6 4 5 1 6"
  },
  {
    "objectID": "lezioni/un_H.html#campionamento-senza-reinserimento",
    "href": "lezioni/un_H.html#campionamento-senza-reinserimento",
    "title": "R per l’analisi statistica multivariata",
    "section": "Campionamento senza reinserimento",
    "text": "Campionamento senza reinserimento\nPer effettuare una ipotetica estrazione del Lotto, si devono estrarre da un’urna 5 numeri, tra l’1 e il 90, senza reinserimento.\nIn R quindi:\n\nsample(1:90, size = 5, replace = FALSE)\n\n[1] 64 53 87 83 61\n\n\nSe specifichiamo solamente il seguente comando:\n\nsample(dice)\n\n[1] 5 3 1 2 6 4\n\n\notteniamo una permutazione casuale degli elementi di x.\nInfatti, i valore predefiniti sono replace = FALSE e size = length(x), ovvero un campionamento senza reinserimento di tutti gli elementi dell’urna."
  },
  {
    "objectID": "lezioni/un_H.html#il-metodo-dellinversione",
    "href": "lezioni/un_H.html#il-metodo-dellinversione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il metodo dell’inversione",
    "text": "Il metodo dell’inversione\nSia \\(X\\) una variabile aleatoria con funzione di ripartizione \\(F(x)\\) e funzione quantile \\[\n\\mathcal{Q}(p) = \\inf\\{x \\in \\mathbb{R} : F(x) \\ge p \\}.\n\\]\nInoltre, sia \\(U \\sim U(0,1)\\). Allora, vale che\n\\[\nX \\overset{d}{=} \\mathcal{Q}(U).\n\\]\n\nDimostrazione (schema)\n\\[\n\\mathbb{P}(Q(U) \\le x) =  \\mathbb{P}(U \\le F(x)) = F(x).\n\\]\n\n\nRisultato chiave\nSe la funzione quantile \\(\\mathcal{Q}(p)\\) è facile da calcolare, per simulare una variabile aleatoria è quindi sufficiente simulare \\(U \\sim U(0,1)\\) e poi calcolare \\(\\mathcal{Q}(U)\\)."
  },
  {
    "objectID": "lezioni/un_H.html#il-metodo-dellinversione-distribuzione-gaussiana",
    "href": "lezioni/un_H.html#il-metodo-dellinversione-distribuzione-gaussiana",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il metodo dell’inversione: distribuzione gaussiana",
    "text": "Il metodo dell’inversione: distribuzione gaussiana\nSupponiamo di voler generare dei valori \\(X_1,\\dots, X_n\\) da una distribuzione gaussiana.\nPossiamo usare il metodo dell’inversione, usando la funzione qnorm.\n\nrnorm.wh <- function(n, mean, sd) {\n  u <- runif.wh(n)\n  qnorm(u, mean = mean, sd = sd)\n}\n\n.current.seed <- c(100, 200, 300)\nrnorm.wh(n = 10, mean = 0, sd = 1) # 10 valori da una normale standard\n\n [1] -0.30055385  0.68773053 -0.60218766 -0.09437046 -1.79635403 -0.56676389\n [7]  1.37283913 -0.41755131 -1.26972731  1.73470371\n\n\n\n\n\n\n\n\nNota\n\n\n\nLa funzione qnorm è lenta e non facile da calcolare. Esistono modi ben più efficienti per campionare da una gaussiana."
  },
  {
    "objectID": "lezioni/un_H.html#il-metodo-dellinversione-distribuzione-binomiale",
    "href": "lezioni/un_H.html#il-metodo-dellinversione-distribuzione-binomiale",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il metodo dell’inversione: distribuzione binomiale",
    "text": "Il metodo dell’inversione: distribuzione binomiale\nSupponiamo di voler generare dei valori \\(X_1,\\dots, X_n\\) da una distribuzione binomiale.\nPossiamo usare anche in questo caso il metodo dell’inversione, usando la funzione qnorm.\n\nrbinom.wh2 <- function(n, size, prob) {\n  u <- runif.wh(n)\n  qbinom(u, size = size, prob = prob)\n}\n\n.current.seed <- c(100, 200, 300)\nrbinom.wh(n = 10, size = 5, prob = 0.5)\n\n [1] 2 3 2 2 1 2 4 2 1 4\n\n.current.seed <- c(100, 200, 300)\nrbinom.wh2(n = 10, size = 5, prob = 0.5)\n\n [1] 2 3 2 2 1 2 4 2 1 4\n\n\n\n\n\n\n\n\nEsercizio - proprietà\n\n\n\nSi dimostri che il metodo “diretto” per variabili discrete che abbiamo introdotto in precedenza coincide con il metodo dell’inversione."
  },
  {
    "objectID": "lezioni/un_H.html#esercizio-riassuntivo-i",
    "href": "lezioni/un_H.html#esercizio-riassuntivo-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo I",
    "text": "Esercizio riassuntivo I\nLa distribuzione continua chiamata half-normal ha la seguente densità: \\[\nf(y) = \\frac{\\sqrt{2}}{\\sqrt{\\pi}} \\exp\\left\\{ - \\frac{y^2}{2}\\right\\}, \\qquad y > 0.\n\\]\nInoltre, è noto che se \\(X \\sim N(0,1)\\) allora \\(Y = |X|\\) segue una distribuzione half-normal.\n\nSi scriva in R la funzione dhalf(y) che calcola la densità \\(f(y)\\).\nSi sviluppi una strategia per campionare dei valori pseudo-casuali da una half normal e la si implementi in R.\n\n\n\n\n\n\n\nNota\n\n\n\nIn generale, si deduca come campionare una variabile aleatoria \\(Y\\) tale che \\(Y = g(X)\\), dove \\(X\\) è una variabile aleatoria che è facile da campionare.\n\n\n\nSoluzione esercizio riassuntivo I\nImplementiamo in primo luogo la funzione dhalf, come richiesto:\n\ndhalf <- function(y) {\n  sqrt(2 / pi) * exp(-y^2 / 2)\n}\n\n# Non richiesto, controllo che integri a 1\nintegrate(function(x) dhalf(x), 0, Inf)\n\n1 with absolute error < 9.4e-05\n\n\nPer generare valori casuali da una half-normal è sufficiente generare valori pseudo-casuali da una normale standard e quindi considerarne il valore assoluto.\nIn generale, se vale \\(Y = g(X)\\) allora è sufficiente campionare i valori di \\(X\\) e poi trasformarli."
  },
  {
    "objectID": "lezioni/un_H.html#esercizio-riassuntivo-ii",
    "href": "lezioni/un_H.html#esercizio-riassuntivo-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo II",
    "text": "Esercizio riassuntivo II\nLa distribuzione continua Weibull ha la seguente densità: \\[\nf(x) = \\alpha \\beta x^{\\beta - 1} \\exp\\left\\{- \\alpha x^\\beta \\right\\}, \\qquad x > 0.\n\\]\n\nSi scriva in R la funzione dweibull che calcola la densità \\(f(x)\\).\nDopo averla ottenuta analiticamente, si implementi in R la funzione pweibull per la funzione di ripartizione \\(F(x)\\).\nDopo averla ottenuta analiticamente, si implementi in R la funzione qweibull per la funzione quantile \\(\\mathcal{Q}(p)\\).\nSi sviluppi una strategia per campionare dei valori pseudo-casuali da una Weibull basata sul metodo dell’inversione e si implementi in R la funzione rweibull.\n\n\nSoluzione esercizio riassuntivo II\nImplementiamo in primo luogo la funzione dweibull(x, alpha, beta):\n\ndweibull <- function(x, alpha, beta) {\n  alpha * beta * x^(beta - 1) * exp(-alpha * x^beta)\n}\n\nRicordiamo che la funzione di ripartizione è pari a \\[\nF(x) = \\int_0^xf(s) \\mathrm{d}s = \\alpha \\beta  \\int_0^x s^{\\beta - 1} \\exp\\left\\{- \\alpha s^\\beta \\right\\}\\mathrm{d}s =1 - e^{-\\alpha x^\\beta}, \\qquad x > 0.\n\\]\nQuindi, invertendo \\(F(x)\\), si ottiene che la funzione quantile è pari a \\[\n\\mathcal{Q}(p) = F^{-1}(p) = \\left(-\\frac{\\log{(1-p)}}{\\alpha}\\right)^{1/\\beta},\n\\] per \\(p \\in (0,1)\\).\n\npweibull <- function(x, alpha, beta) {\n  1 - exp(-alpha * x^beta)\n}\n\nqweibull <- function(p, alpha, beta) {\n  (-log(1 - p) / alpha)^(1 / beta)\n}\n\nrweibull <- function(R, alpha, beta) {\n  qweibull(runif(R), alpha, beta)\n}\n\nrweibull(10, 2, 2)\n\n [1] 1.1276566 0.8814093 0.4688023 0.7052449 0.6102069 0.8906791 0.4756895\n [8] 0.5512620 1.1274530 1.4573989"
  },
  {
    "objectID": "lezioni/un_I.html",
    "href": "lezioni/un_I.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Metodi Monte Carlo\nApprossimazione di un evento tramite Monte Carlo\nIntegrazione Monte Carlo\nIstogrammi & densità\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_I.html#i-metodi-monte-carlo",
    "href": "lezioni/un_I.html#i-metodi-monte-carlo",
    "title": "R per l’analisi statistica multivariata",
    "section": "I metodi Monte Carlo",
    "text": "I metodi Monte Carlo\nNell’unità H abbiamo dedicato moltissime energie per cercare di capire come simulare dei valori (pseudo) casuali da variabili aleatorie continue e discrete.\nCiò che tuttavia non abbiamo spiegato è l’utilità di queste tecniche.\nIl motivo è semplice: le possibili applicazioni sono talmente numerose che è necessario introdurle separatamente in questa lezione… e probabilmente scalfiremo solamente la superficie.\n\n\n\n\n\n\nMetodo Monte Carlo\n\n\n\nDefiniamo metodo Monte Carlo una qualsiasi procedura che coinvolga l’utilizzo di numeri (pseudo) casuali."
  },
  {
    "objectID": "lezioni/un_I.html#alcuni-cenni-storici",
    "href": "lezioni/un_I.html#alcuni-cenni-storici",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcuni cenni storici",
    "text": "Alcuni cenni storici\nI metodi Monte Carlo hanno una lunga storia; alcuni di essi sono stati usati perfino prima dell’invenzione dei computer.\nI primi utilizzi moderni, ovvero basati su numeri pseudo-casuali, sono stati condotti (tra gli altri) da Enrico Fermi, Nicholas Metropolis, Richard Feynman e John von Neumann tra gli anni ’30 e ’40.\nIl neonato metodo Monte Carlo aveva quindi delle importanti applicazioni in fisica. In particolare, importanti passi avanti furono fatti all’interno del progetto Manhattan.\nL’algoritmo di Metropolis, sviluppato in quegli anni, è tutt’oggi ampiamente usato. Purtroppo è prematuro presentarlo in questo corso: lo vederete più avanti!\n\nApprofondimento\n\nHitchcock (2003). A history of the Metropolis-Hastings algorithm. The American Statistician 57(4), 254–257."
  },
  {
    "objectID": "lezioni/un_I.html#the-monte-carlo-method",
    "href": "lezioni/un_I.html#the-monte-carlo-method",
    "title": "R per l’analisi statistica multivariata",
    "section": "“The Monte Carlo Method”",
    "text": "“The Monte Carlo Method”"
  },
  {
    "objectID": "lezioni/un_I.html#possibili-applicazioni",
    "href": "lezioni/un_I.html#possibili-applicazioni",
    "title": "R per l’analisi statistica multivariata",
    "section": "Possibili applicazioni",
    "text": "Possibili applicazioni\nI metodi Monte Carlo hanno applicazioni in tutte le discipline scientifiche, incluse la fisica, biologia, medicina, genetica, informatica, matematica.\nPer ovvie ragioni, noi approfondiremo le applicazioni legate alla probabilità e alla statistica. Alcuni esempi sono riportati nel seguito.\nIl metodo bootstrap tramite Monte Carlo è valso il “Nobel per la Statistica” a Brad Efron nel 2019. Link: https://en.wikipedia.org/wiki/International_Prize_in_Statistics.\nLa statistica bayesiana moderna fa uso intensivo dei metodi Monte Carlo.\nConcetti chiave di data mining & machine learning, come la suddivisione in insieme di stima & verifica o la convalida incrociata, sono per definizione basati sulla simulazione di numeri casuali.\nInfine, grazie alla simulazione è possibile verificare la validità dei risultati “asintotici” che vengono presentati nei corsi di inferenza statistica."
  },
  {
    "objectID": "lezioni/un_I.html#approssimazione-di-una-probabilità",
    "href": "lezioni/un_I.html#approssimazione-di-una-probabilità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Approssimazione di una probabilità",
    "text": "Approssimazione di una probabilità\nSi supponga di voler calcolare una determinata probabilità \\(\\pi\\) di un certo esperimento casuale. Definiamo una variabile aleatoria di bernoulli \\(Z\\) tale che \\[\n\\pi = \\mathbb{P}(Z = 1),\n\\]\novvero un indicatore binario che denota se l’evento si è verificato o meno.\nIn molti casi è difficile se non praticamente impossibile calcolare \\(\\pi\\) analiticamente.\n\nEsempio 1\nSi supponga che \\(X \\sim \\text{N}(0,1)\\) e si ponga \\(Y = \\cos(X)\\). Il calcolo di \\[\n\\pi = \\mathbb{P}(Y > 0) = \\mathbb{P}\\{\\cos(X) > 0\\},\n\\] non è affatto semplice usando solo “carta e penna”: provateci, se volete.\n\n\nEsempio 2\nLa probabilità di vittoria della tombola \\(\\pi\\) si potrebbe calcolare “carta e penna”, ma questa operazione sarebbe lunga e faticosa."
  },
  {
    "objectID": "lezioni/un_I.html#approssimazione-di-una-probabilità-1",
    "href": "lezioni/un_I.html#approssimazione-di-una-probabilità-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Approssimazione di una probabilità",
    "text": "Approssimazione di una probabilità\nIl metodo Monte Carlo prevede di simulare tante volte l’esperimento casuale in questione e contare la frazione di volte che l’evento si è verificato (ovvero \\(Z = 1\\)).\nIn altri termini, consideriamo delle variabili aleatorie binarie iid \\(Z_1,\\dots,Z_R\\) aventi probabilità \\(\\pi\\). La probabilità \\(\\pi\\) viene stimata tramite la frazione di successi.\nIl metodo Monte Carlo è di estrema utilità perché permette di approssimare una determinata probabilità senza fare alcun conto analitico.\n\n\n\n\n\n\nNota\n\n\n\nIl punto cruciale è che spesso è possibile simulare un esperimento casuale senza conoscere \\(\\pi\\), che infatti è la probabilità che siamo interessati ad approssimare.\n\n\n\nEsempio\nSi supponga nuovamente che \\(X \\sim \\text{N}(0,1)\\) e si ponga \\(Y = \\cos(X)\\). Siamo interessati a calcolare la probabilità: \\[\n    \\pi =\\mathbb{P}(Y > 0) = \\mathbb{P}\\{\\cos(X) > 0\\}.\n\\]\nDefiniamo quindi la variabile binaria \\[\nZ = \\mathbb{1}(Y > 0) = \\mathbb{1}\\{\\cos(X) > 0\\},\n\\] ovvero una variabile aleatoria bernoulliana che vale \\(1\\) se \\(\\cos(X) > 0\\) e vale \\(0\\) altrimenti.\nÉ facile verificare (fatelo per esercizio!) che \\[\n\\pi = \\mathbb{P}(Z = 1) = \\mathbb{P}(Y > 0).\n\\]\n\n\n\n\n\n\nRisultato chiave\n\n\n\nSimulare delle copie iid dalla legge di \\(Z\\) è molto semplice, nonostante la probabilità \\(\\pi\\) sia ignota.\n\n\n\n\nEsempio (continua)\nPer approssimare la probabilità \\(\\pi = \\mathbb{P}(Z = 1) = \\mathbb{P}\\{\\cos(X) > 0\\}\\) dobbiamo quindi generare tante copie iid da questa legge, ovvero \\(Z_1,\\dots,Z_R\\).\n\nR <- 5000 # Numero di repliche\n\nset.seed(123)\nX <- rnorm(R, 0, 1) # Ottengo R copie da una distribuzione gaussiana\nY <- cos(X) # Ottengo R copie dalla distribuzione di Y\nZ <- Y > 0 # Vettore logico che verifica se Y > 0 o meno\nZ[1:10]\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nIl numero \\(R\\) rappresenta il numero di repliche e determina, come vedremo, la precisione della nostra stima Monte Carlo.\nA questo punto, l’approssimazione si ottiene considerando la proporzione di successi\n\nprop.table(table(Z)) # Considero la frequenza relativa\n\nZ\n FALSE   TRUE \n0.1158 0.8842 \n\nmean(Z) # Oppure, più semplicemente\n\n[1] 0.8842"
  },
  {
    "objectID": "lezioni/un_I.html#errare-è-lunica-certezza",
    "href": "lezioni/un_I.html#errare-è-lunica-certezza",
    "title": "R per l’analisi statistica multivariata",
    "section": "Errare è l’unica certezza",
    "text": "Errare è l’unica certezza\nCome tutte le approssimazioni, anche il metodo Monte Carlo comporta un errore.\nLa peculiarità delle approssimazioni Monte Carlo è che sono, per definizione, casuali.\nQuesto significa che ogni volta che eseguiamo la procedura otteniamo un valore leggermente diverso. Ad esempio:\n\nset.seed(100) # Imposto un seed diverso da prima\nZ <- cos(rnorm(R, 0, 1)) > 0 # Calcolo gli indicatori (codice in forma compatta)\nmean(Z)\n\n[1] 0.8878\n\n\nPer cui sia la stima ottenuta che l’errore commesso sono aleatori!\nFortunatamente, questo è un contesto che dovreste conoscere molto bene. La nostra procedura Monte Carlo è infatti, a tutti gli effetti, uno stimatore di \\(\\pi\\)."
  },
  {
    "objectID": "lezioni/un_I.html#come-mai-funziona",
    "href": "lezioni/un_I.html#come-mai-funziona",
    "title": "R per l’analisi statistica multivariata",
    "section": "Come mai funziona?",
    "text": "Come mai funziona?\nSiano \\(Z_1,\\dots,Z_R\\) delle variabili aleatorie binarie indipendenti ed identicamente distribuite, aventi la stessa distribuzione della variabile \\(Z \\sim \\text{Ber}(\\pi)\\). Lo stimatore \\[\n\\hat{\\pi} = \\frac{1}{R}\\sum_{r=1}^R Z_r = (\\text{``Proporzione di successi''}),\n\\] coincide con l’approssimazione Monte Carlo.\nLo stimatore \\(\\hat{\\pi}\\) ha delle ottime proprietà inferenziali, che si studiano in un qualsiasi corso di inferenza statistica; torneremo a parlare di stimatori nell’unità M.\nIn primo luogo, lo stimatore \\(\\hat{\\pi}\\) è non distorto, infatti: \\[\n\\mathbb{E}(\\hat{\\pi}) = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}(Z_r) =  \\frac{1}{R}\\sum_{r=1}^R \\mathbb{P}(Z = 1) =  \\mathbb{P}(Z = 1) = \\pi.\n\\]\nInoltre, lo stimatore \\(\\hat{\\pi}\\) è consistente, infatti per la legge (forte) dei grandi numeri si ottiene che: \\[\n\\hat{\\pi}  = \\frac{1}{R}\\sum_{r=1}^R Z_r \\overset{\\text{q.c.}}{\\longrightarrow} \\mathbb{P}(Z = 1) = \\pi, \\qquad R \\rightarrow \\infty.\n\\]"
  },
  {
    "objectID": "lezioni/un_I.html#la-varianza-dello-stimatore-i",
    "href": "lezioni/un_I.html#la-varianza-dello-stimatore-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza dello stimatore I",
    "text": "La varianza dello stimatore I\nPossiamo infine calcolare la varianza di \\(\\hat{\\pi}\\), che risulta pari alla seguente quantità \\[\n\\begin{aligned}\n        \\text{var}(\\hat{\\pi}) = \\frac{1}{R^2}\\sum_{r=1}^R\\text{var}(Z_r) = \\frac{1}{R^2}\\sum_{r=1}^R \\pi(1-\\pi) = \\frac{\\pi ( 1- \\pi)}{R}.\n        \\end{aligned}\n\\]\nDa questa equazione è evidente il ruolo chiave del numero di repliche \\(R\\).\nIl numero di repliche \\(R\\) si può interpretare come se fosse una sorta di numerosità campionaria, che idealmente noi possiamo aumentare a piacere.\nUn numero di repliche elevato aumenta quindi la precisione ma ha un costo in termini di risorse computazionali (= il computer impiega più tempo).\n\n\n\n\n\n\nNota\n\n\n\nLa varianza \\(\\text{var}(\\hat{\\pi})\\) dipende dal valore di \\(\\pi\\), che è ignoto. Per cui una stima della varianza si ottiene rimpiazzando \\(\\pi\\) con la sua stima \\(\\hat{\\pi}\\).\n\n\nVogliamo valutare l’impatto della scelta di \\(R\\) ed implementiamo quindi la funzione MonteCarlo, che calcola sia l’approssimazione che la sua deviazione standard.\n\nMonteCarlo <- function(R) {\n  Z <- cos(rnorm(R, 0, 1)) > 0\n  estimate <- mean(Z)\n  std.error <- sqrt(estimate * (1 - estimate) / R)\n  out <- c(estimate, std.error)\n  names(out) <- c(\"estimate\", \"std.error\") # Aggiungo solo per ragioni estetiche\n  out\n}\n\nProviamo con alcuni valori diversi di \\(R\\). Si nota un progressivo miglioramento:\n\nMonteCarlo(100) # R = 100 conduce a uno std.error elevato\n\n estimate std.error \n0.8600000 0.0346987 \n\nMonteCarlo(5000) # R = 5000 conduce a uno std.error ragionevole\n\n   estimate   std.error \n0.891000000 0.004407244 \n\nMonteCarlo(10^6) # R = 10^6 conduce a uno std.error basso\n\n   estimate   std.error \n0.883934000 0.000320304"
  },
  {
    "objectID": "lezioni/un_I.html#esercizio-riassuntivo-i",
    "href": "lezioni/un_I.html#esercizio-riassuntivo-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo I",
    "text": "Esercizio riassuntivo I\nSia \\(X\\) una normale standard. Si approssimi tramite Monte Carlo la probabilità seguente \\[\n\\pi = \\mathbb{P}(1 < X < 2).\n\\]\n\nSi ottenga quindi una stima Monte Carlo dell’errore commesso. - Si ripeta la procedura per diversi valori del numero di repliche \\(R\\).\nSi confrontino i risultati con il vero valore di \\(\\mathbb{P}(1 < X < 2)\\). Le approssimazioni Monte Carlo migliorano al crescere di \\(R\\)?\n(Difficile) Si ottenga un intervallo di confidenza per lo stimatore \\(\\hat{\\pi}\\) di livello approssimato \\(1 - \\alpha = 0.95\\).\n\n\nSchema della soluzione\n\nMonteCarlo <- function(R) {\n  X <- rnorm(R)\n  Z <- (X > 1) & (X < 2)\n  estimate <- mean(Z)\n  std.error <- sqrt(estimate * (1 - estimate) / R)\n  out <- c(estimate, std.error)\n  names(out) <- c(\"estimate\", \"std.error\")\n  out\n}\n\n# Vero valore\npnorm(2) - pnorm(1)\n\n[1] 0.1359051\n\nMonteCarlo(100) # R = 100 conduce a std.error elevato\n\n estimate std.error \n     0.10      0.03 \n\nMonteCarlo(5000) # R = 5000 conduce a std.error ragionevole\n\n   estimate   std.error \n0.129800000 0.004752935 \n\nMonteCarlo(10^6) # R = 10^6 conduce a std.error basso\n\n    estimate    std.error \n0.1355270000 0.0003422856"
  },
  {
    "objectID": "lezioni/un_I.html#integrazione-monte-carlo-i",
    "href": "lezioni/un_I.html#integrazione-monte-carlo-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Integrazione Monte Carlo I",
    "text": "Integrazione Monte Carlo I\nL’idea di approssimare una probabilità tramite simulazione può essere generalizzata.\nIn particolare, supponiamo di voler calcolare un generico integrale del tipo \\[\n\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\mathbb{E}\\{g(X)\\},\n\\] dove \\(f(x)\\) è la densità una variabile aleatoria \\(X\\) avente supporto \\(\\mathcal{X}\\).\nLa probabilità di un evento è un caso particolare di questo contesto. Infatti se \\(g(x) = \\mathbb{1}(x \\in B)\\) si ottiene \\[\n\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\int_B f(x) \\mathrm{d}x = \\mathbb{P}(X \\in B).\n\\]\nEsattamente come per la probabilità di un evento, vogliamo usare la simulazione per ottenere un’approssimazione di \\(\\mathcal{I}\\)."
  },
  {
    "objectID": "lezioni/un_I.html#integrazione-monte-carlo-ii",
    "href": "lezioni/un_I.html#integrazione-monte-carlo-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Integrazione Monte Carlo II",
    "text": "Integrazione Monte Carlo II\nSia \\(X \\sim f(x)\\). Per approssimare l’integrale \\[\n\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\mathbb{E}\\{g(X)\\}\n\\] si simulano dei valori \\(X_1,\\dots,X_R\\) da \\(f(x)\\). Si calcolano quindi i valori \\(g(X_1),\\dots, g(X_R)\\) ed infine si considera la loro media campionaria.\nLa stima Monte Carlo \\(\\hat{\\mathcal{I}}\\) è tale che \\[\n\\hat{\\mathcal{I}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r) \\approx \\mathbb{E}\\{g(X)\\} = \\mathcal{I}.\n\\]\n\n\n\n\n\n\nNota\n\n\n\nIl metodo descritto può essere in realtà usato per approssimare un qualsiasi valore atteso \\(\\mathbb{E}\\{g(X)\\}\\), anche quando la variabile aleatoria \\(X\\) è discreta.\n\n\n\nEsempio\nSupponiamo di voler calcolare il valore del seguente integrale \\[\n\\mathcal{I} = \\int_0^1[\\cos(50x) + \\sin(20x)]^2\\mathrm{d}x.\n\\]\nSi noti che questo integrale coincide con il valore atteso di una trasformazione di una variabile aleatoria uniforme \\(U\\), ovvero \\[\n\\mathcal{I} = \\mathbb{E}[\\{\\cos(50 U) + \\sin(20 U)\\}^2], \\qquad U \\sim \\text{Unif}(0,1).\n\\]\nIn R pertanto possiamo calcolare \\(\\hat{\\mathcal{I}}\\) come segue\n\nU <- runif(10^6)\nI_hat <- mean((cos(50 * U) + sin(20 * U))^2)\nI_hat\n\n[1] 0.9656129\n\n\nQuesta funzione in realtà può essere integrata analiticamente: vale che \\(\\mathcal{I} \\approx 0.965201\\). Pertanto, l’approssimazione Monte Carlo sembra essere accurata.\nIl grafico della funzione integranda nell’intervallo \\((0,1)\\).\n\ncurve((cos(50 * x) + sin(20 * x))^2, n = 400)"
  },
  {
    "objectID": "lezioni/un_I.html#come-mai-funziona-procediamo-come-prima",
    "href": "lezioni/un_I.html#come-mai-funziona-procediamo-come-prima",
    "title": "R per l’analisi statistica multivariata",
    "section": "Come mai funziona? Procediamo come prima…",
    "text": "Come mai funziona? Procediamo come prima…\nSiano \\(X_1,\\dots,X_R\\) delle copie iid aventi densità \\(f(x)\\). Consideriamo quindi lo stimatore seguente \\[\n\\hat{\\mathcal{I}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r),\n\\] ovvero l’approssimazione Monte Carlo di \\(\\mathcal{I}\\) che abbiamo descritto.\nAnche in questo caso, otteniamo che \\(\\hat{\\mathcal{I}}\\) è uno stimatore di \\(\\mathcal{I}\\) con ottime proprietà inferenziali.\nCome in precedenza, lo stimatore $ $ risulta essere non distorto, infatti: \\[\n\\mathbb{E}(\\hat{\\mathcal{I}}) = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X_r)\\} =  \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X)\\} =  \\mathbb{E}\\{g(X)\\} = \\mathcal{I}.\n\\]\nInoltre, lo stimatore \\(\\hat{\\mathcal{I}}\\) è consistente. Infatti per la legge (forte) dei grandi numeri \\[\n\\hat{\\mathcal{I}}  = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X_r)\\} \\overset{\\text{q.c.}}{\\longrightarrow} \\mathbb{E}\\{g(X)\\} = \\mathcal{I}, \\qquad R \\rightarrow \\infty.\n\\]"
  },
  {
    "objectID": "lezioni/un_I.html#la-varianza-dello-stimatore-i-1",
    "href": "lezioni/un_I.html#la-varianza-dello-stimatore-i-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza dello stimatore I",
    "text": "La varianza dello stimatore I\nAnche in questo caso possiamo calcolare la varianza dello stimatore \\(\\hat{\\mathcal{I}}\\): \\[\n\\text{var}(\\hat{\\mathcal{I}}) = \\frac{1}{R^2}\\sum_{r=1}^R\\text{var}\\{g(X_r)\\} = \\frac{1}{R}\\text{var}\\{g(X)\\},\n\\] con \\(X \\sim f(x)\\).\nLa varianza \\(\\text{var}\\{g(X)\\}\\) è tipicamente ignota, ma può essere stimata utilizzando gli stessi valori usati per stimare \\(\\mathcal{I}\\), ad esempio tramite la varianza campionaria: \\[\n    \\widehat{\\text{var}\\{g(X)\\}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r)^2 - \\left(\\frac{1}{R}\\sum_{r=1}^R g(X_r)\\right)^2.\n\\]\nCome in precedenza, un numero di repliche \\(R\\) elevato aumenta quindi la precisione ma ha un costo computazionale."
  },
  {
    "objectID": "lezioni/un_I.html#la-varianza-dello-stimatore-ii",
    "href": "lezioni/un_I.html#la-varianza-dello-stimatore-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La varianza dello stimatore II",
    "text": "La varianza dello stimatore II\nL’implementazione in R si ottiene come segue:\n\nMonteCarlo <- function(R) {\n  U <- runif(R)\n  hU <- (cos(50 * U) + sin(20 * U))^2\n  estimate <- mean(hU)\n  std.error <- sd(hU) / sqrt(R)\n  out <- c(estimate, std.error)\n  names(out) <- c(\"estimate\", \"std.error\") # Aggiungo solo per ragioni estetiche\n  out\n}\n\nProviamo con alcuni valori diversi di \\(R\\). Si nota un progressivo miglioramento:\n\nMonteCarlo(100) # R = 100 conduce a uno std.error elevato\n\n  estimate  std.error \n0.92588110 0.09697723 \n\nMonteCarlo(5000) # R = 5000 conduce a uno std.error ragionevole\n\n  estimate  std.error \n0.97175199 0.01476928 \n\nMonteCarlo(10^6) # R = 10^6 conduce a uno std.error basso\n\n   estimate   std.error \n0.965958861 0.001045334"
  },
  {
    "objectID": "lezioni/un_I.html#istogrammi-e-densità",
    "href": "lezioni/un_I.html#istogrammi-e-densità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Istogrammi e densità",
    "text": "Istogrammi e densità\nSupponiamo di simulare delle variabili aleatorie continue \\(X_1,\\dots, X_R\\), aventi una certa densità \\(f(x)\\).\nSe disegniamo l’istogramma di tali numeri, intuitivamente ci aspetteremo un’alta densità nell’istogramma in corrispondenza dei valori molto probabili.\nIn realtà, il legame tra istogrammi e densità è molto più stretto. Consideriamo \\(\\lambda = 1 / R\\) (si veda unità D per la definizione), ovvero il valore che rende la somma delle aree dei rettangoli pari a \\(1\\).\nIn tale contesto, l’istogramma costituisce un’approssimazione della densità.\nIn termini più precisi, diremo che l’istogramma è uno stimatore nonparametrico della densità \\(f(x)\\).\n\nX <- rnorm(10^5)\nhist(X, freq = FALSE, breaks = 100)\ncurve(dnorm(x), add = TRUE) # add = TRUE Aggiunge la curva al grafico precedente"
  },
  {
    "objectID": "lezioni/un_I.html#istogrammi-e-densità-1",
    "href": "lezioni/un_I.html#istogrammi-e-densità-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Istogrammi e densità",
    "text": "Istogrammi e densità\nL’idea è approssimare la funzione \\(f(x)\\) con dei rettangoli. Quanti più rettangoli consideriamo, tanto più accurata sarà l’approssimazione.\nRicordiamo che se \\(X \\sim f(x)\\) allora vale che \\[\n\\mathbb{P}(a < X < b) = \\int_a^bf(x)\\mathrm{d}x.\n\\]\nQuindi idealmente l’altezza del rettangolo di base \\((a, b)\\) dev’essere tale che \\[\n(\\text{``Altezza rettangolo''}) = \\frac{\\mathbb{P}(a < X < b)}{b - a},\n\\] in maniera tale che l’area del rettangolo risulti pari a \\(\\mathbb{P}(a < X < b)\\).\nLe probabilità \\(\\mathbb{P}(a < X < b)\\) sono ulteriormente approssimate tramite Monte Carlo e sono poste pari alla proporzioni di valori \\(X_1,\\dots,X_R\\) contenuti nell’intervallo \\((a,b)\\)."
  },
  {
    "objectID": "lezioni/un_I.html#approssimazione-di-una-distribuzione-discreta",
    "href": "lezioni/un_I.html#approssimazione-di-una-distribuzione-discreta",
    "title": "R per l’analisi statistica multivariata",
    "section": "Approssimazione di una distribuzione discreta",
    "text": "Approssimazione di una distribuzione discreta\nUn principio simile a visto per istogrammi / densità vale anche nel caso discreto.\nSia \\(X\\) una variabile aleatoria discreta. In questo contesto, possiamo direttamente approssimare la funzione di probabilità \\[\np(x) = \\mathbb{P}(X = x),\n\\] utilizzando un metodo Monte Carlo.\nSupponendo di poter simulare \\(X_1,\\dots,X_R\\). Allora, una stima per \\(p(x)\\) è semplicemente pari alla proporzione di valori pari \\(x\\) che abbiamo ottenuto.\n\nX <- rpois(10^5, 10) # Simulazione di R variabili Poisson con media 10\nfreq_rel <- table(X) / sum(X) # Calcolo delle frequenze relative\n\npar(mfrow = c(1, 2)) # Grafici\nplot(freq_rel, ylab = \"P(X = k)\", xlab = \"k\", main = \"Distribuzione empirica\")\nplot(0:28, dpois(0:28, 10),\n  type = \"h\", ylab = \"P(X = k)\",\n  xlab = \"k\", main = \"Distribuzione teorica\"\n)"
  },
  {
    "objectID": "lezioni/un_I.html#esercizio-riassuntivo-i-1",
    "href": "lezioni/un_I.html#esercizio-riassuntivo-i-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo I",
    "text": "Esercizio riassuntivo I\nSi calcoli tramite Monte Carlo il valore del seguente integrale e se ne quantifichi l’incertezza \\[\n\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty\\sin^2(x)e^{-x^2/2}\\mathrm{d}x.\n\\]\nSi confronti il risultato con la funzione integrate.\n\nSchema della soluzione\n\nX <- rnorm(10^5)\nhX <- sin(X)^2\nmean(hX) # Estimate\n\n[1] 0.43398\n\nsd(hX) / sqrt(10^5) # Std.error\n\n[1] 0.001097362\n\n# Integrazione numerica\nintegrate(function(x) sin(x)^2 * dnorm(x), -Inf, Inf)\n\n0.4323324 with absolute error < 9.8e-06"
  },
  {
    "objectID": "lezioni/un_I.html#esercizio-riassuntivo-ii",
    "href": "lezioni/un_I.html#esercizio-riassuntivo-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo II",
    "text": "Esercizio riassuntivo II\nSi supponga di voler approssimare tramite Monte Carlo il seguente valore atteso \\[\n\\mathbb{E}(X^2), \\qquad X \\sim \\text{Ga}(3, 3).\n\\]\nSi dica, motivando la risposta, quale codice produce il risultato corretto.\n\nCodice 1\n\nmean(rgamma(10^5, 3, 3) * rgamma(10^5, 3, 3))\n\n[1] 0.9990672\n\n\n\n\nCodice 2\n\nX <- rgamma(10^5, 3, 3)\nmean(X * X)\n\n[1] 1.335139"
  },
  {
    "objectID": "lezioni/un_I.html#esercizio-riassuntivo-iii",
    "href": "lezioni/un_I.html#esercizio-riassuntivo-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio riassuntivo III",
    "text": "Esercizio riassuntivo III\nNel seguente video YouTube del canale Veritasium, viene introdotto un enigma che coinvolge un numero \\(n = 100\\) di prigionieri.\nUtilizzando la cosiddetta “loop strategy” che viene descritta nel video, si approssimi tramite Monte Carlo la probabilità di successo dei prigionieri, per \\(n = 100\\).\nI risultati della simulazione sono coerenti con quanto descritto nel video?\n\n\nSchema della soluzione\nI numeri nelle scatole (boxes), sconosciuti ai prigionieri, vengono generati casualmente.\n\nset.seed(400)\nn <- 100 # Numero di prigionieri\nboxes <- sample(1:n) # Effettua una permutazione dei numeri 1:n\n\nPer cui in questo caso (con questo seed), nella scatola 51 è contenuto il numero 97:\n\nboxes[51]\n\n[1] 97\n\n\nIn questa caso, le scatole contengono i numeri seguenti\n\nboxes\n\n  [1]  23  87  92  86  28  14  13  95  71  41  45  36  42  21  96  82  53  89\n [19]  65  69  35  20  54  57  47  27  10  62  18  60   4   1   9  93  44  79\n [37]  49  22  98  85  26   8  83  91  33  50  90  77   7   3  97  29  12  52\n [55]  94  61  64  39   2  51  99  88  30  48  70  76  66  15  80   5  25  58\n [73]   6  37  56 100  43  17  74  19  11  55  68  84  72  40  81  63  38  46\n [91]  59  75  78  34  24  73  32  31  67  16\n\n\nControlliamo ora se, tramite la “loop strategy”, i prigionieri riescono ad individuare il loro numero all’interno delle scatole (boxes). Partiamo dal primo prigioniero, che verificherà se il suo numero è presente nella prima scatola. In altri termini:\n\nfound <- boxes[1] == 1 # TRUE se il PRIMO prigioniero ha trovato il suo numero\n\nSe no, il prigionieri controlla anche in tutte le scatole seguenti, ovvero\n\n# Loop strategy, per il PRIMO prigioniero\nfound <- FALSE\nbox_checked <- 1 # Il PRIMO prigioniero parte dalla prima scatola\nfor (i in 1:(n / 2)) { # I prigionieri possono fare n / 2 tentativi\n  if (boxes[box_checked] == 1) {\n    found <- TRUE\n  }\n  box_checked <- boxes[box_checked] # Il numero successivo è pari al numero nella scatola corrente\n}\nfound\n\n[1] TRUE\n\n\nIl primo prigioniero ha trovato il suo numero. Ora verifichiamo se tutti i prigionieri riescono a fare lo stesso:\n\nfound <- rep(FALSE, n) # Vettore di TRUE/FALSE che identifica se i prigionieri hanno trovato il proprio numero.\n\nfor (j in 1:n) {\n  box_checked <- j # Il j-esimo prigioniero, parte dalla j-esima scatola\n  for (i in 1:(n / 2)) {\n    if (boxes[box_checked] == j) {\n      found[j] <- TRUE\n    }\n    box_checked <- boxes[box_checked]\n  }\n}\n\nAlcuni prigionieri riescono a trovare la loro scatola. In questo caso, tuttavia, non tutti individuano il proprio numero. Infatti:\n\nfound\n\n  [1]  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE\n [25] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n [37] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49] FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE\n [61] FALSE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE\n [85]  TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97]  TRUE  TRUE FALSE FALSE\n\nall(found) # TRUE solamente se tutti i valori del vettore sono TRUE\n\n[1] FALSE\n\n\nMettiamo quindi tutti i pezzi assieme, per poter svolgere la simulazione Monte Carlo:\n\nloop_strategy <- function(n) {\n  boxes <- sample(1:n)\n  found <- rep(FALSE, n)\n\n  for (j in 1:n) {\n    box_checked <- j\n    for (i in 1:(n / 2)) {\n      if (boxes[box_checked] == j) {\n        found[j] <- TRUE\n      }\n      box_checked <- boxes[box_checked]\n    }\n  }\n  all(found)\n}\n\n\n# Effettuo la simulazione, per R = 10000\nR <- 10000\nset.seed(200)\nZ <- replicate(R, loop_strategy(n = 100))\n\nLa probabilità di successo viene quindi approssimata tramite Monte Carlo come fatto in precedenza:\n\nestimate <- mean(Z) # Stima della probabilità di successo\nestimate\n\n[1] 0.314\n\n\nQuesta stima coincide, a meno dell’errore Monte Carlo, con quanto discusso nel video."
  },
  {
    "objectID": "lezioni/un_I.html#esercizi-aggiuntivi-non-risolti",
    "href": "lezioni/un_I.html#esercizi-aggiuntivi-non-risolti",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi aggiuntivi (non risolti)",
    "text": "Esercizi aggiuntivi (non risolti)\n\nEsercizio 1\nSi ottenga un’approssimazione Monte Carlo del seguente integrale \\[\n\\int_0^\\infty x^4 e^{-x}\\mathrm{d}x\n\\] e si quantifichi l’errore commesso. Si confronti il risultato con la funzione integrate.\n\n\nEsercizio 2\nSi ottenga un’approssimazione Monte Carlo del seguente integrale \\[\n\\int_0^1 x^{1/2}(1 - x)^{1/2}\\mathrm{d}x\n\\] e si quantifichi l’errore commesso. Si confronti il risultato con la funzione integrate."
  },
  {
    "objectID": "lezioni/un_K.html",
    "href": "lezioni/un_K.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Aspetti numerici legati all’inferenza tramite verosimiglianza\nStima numerica di massima verosimiglianza\nIl caso multiparametrico (grafici contour)\n\n\n\n\n\n\n\nNota\n\n\n\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_K.html#un-breve-sommario",
    "href": "lezioni/un_K.html#un-breve-sommario",
    "title": "R per l’analisi statistica multivariata",
    "section": "Un breve sommario",
    "text": "Un breve sommario\nIn questa unità procederemo tramite esempi, volti a mostrare alcuni aspetti numerici e grafici legati alla verosimiglianza in modelli parametrici.\nIn primo luogo, considereremo un esempio di modello con parametro scalare.\nQuindi, considereremo un esempio modello con parametro vettoriale.\nPer ovvie ragioni, non avremo tempo / modo di ripercorrere l’intero programma di Statistica II.\nPertanto è di fondamentale importanza che gli argomenti di inferenza statistica siano ben chiari."
  },
  {
    "objectID": "lezioni/un_K.html#ripasso-notazione",
    "href": "lezioni/un_K.html#ripasso-notazione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso & notazione",
    "text": "Ripasso & notazione\nNel caso assolutamente continuo, un modello statistico è una collezione di funzioni di densità \\[\n\\mathcal{F} = \\{f(\\cdot ; \\theta) : \\theta \\in \\Theta\\},\n\\] indicizzata da un vettori di parametri \\(\\theta \\in \\Theta\\), dove \\(\\Theta \\subseteq \\mathbb{R}^p\\) è lo spazio parametrico.\nNel caso discreto, la definizione di modello statistico è la medesima, ma considerando delle funzioni di probabilità \\(p(x ; \\theta)\\) al posto delle densità.\nAssumiamo inoltre che che \\(y = (y_1,\\dots,y_n)\\) sia un campione (spesso iid) con legge congiunta \\(f(y; \\theta)\\), per un qualche ignoto valore del parametro \\(\\theta\\).\nRelativamente ad un modello statistico \\(\\mathcal{F}\\) di cui è stato osservato un campione \\(y\\), si chiama verosimiglianza la funzione da \\(\\Theta\\) in \\(\\mathbb{R} \\cup \\{0\\}\\) \\[\n\\mathcal{L}(\\theta) = \\mathcal{L}(\\theta; y) = C \\: f(y; \\theta),\n\\] dove \\(C = C(y)\\) è una costante positiva che non dipende da \\(\\theta\\)."
  },
  {
    "objectID": "lezioni/un_K.html#ripasso-e-notazione",
    "href": "lezioni/un_K.html#ripasso-e-notazione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso e notazione",
    "text": "Ripasso e notazione\nAssumiamo che campione \\(y = (y_1,\\dots,y_n)\\) sia composto da realizzazioni indipendenti ed identicamente distribute da una variabile casuale legge \\(f(y; \\theta)\\). Quindi, si ottiene \\[\n    \\mathcal{L}(\\theta) = \\mathcal{L}(\\theta; y) = C \\: \\prod_{i=1}^n f(y_i; \\theta).\n    \\]\nDato che \\(\\mathcal{L}(\\theta)\\) è non-negativa, spesso si lavora con la funzione di log-verosimiglianza \\[\n    \\ell(\\theta) = \\ell(\\theta; y) = \\log\\mathcal{L}(\\theta) = c + \\sum_{i=1}^n\\log f(y_i; \\theta),\n    \\] dove \\(c \\in \\mathbb{R}\\) è una costante additiva che non dipende da \\(\\theta\\)."
  },
  {
    "objectID": "lezioni/un_K.html#ripasso-notazione-1",
    "href": "lezioni/un_K.html#ripasso-notazione-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ripasso & notazione",
    "text": "Ripasso & notazione\nLa stima di massima verosimiglianza (SMV) è il valore \\(\\hat{\\theta}\\) che rende massima la funzione di verosimiglianza \\(\\mathcal{L}(\\theta)\\) sullo spazio \\(\\Theta\\), cioè tale per cui \\[\n\\mathcal{L}(\\hat{\\theta}) = \\sup_{\\theta \\in \\Theta}\\mathcal{L}(\\theta).\n\\]\nLa SMV rende massimo anche la funzione di log-verosimiglianza, per cui \\[\n\\ell(\\hat{\\theta}) = \\sup_{\\theta \\in \\Theta}\\ell(\\theta).\n\\]\nDi conseguenza, sotto opportune condizioni di regolarità, la SMV si ottiene come soluzione dell’equazione \\(\\ell'(\\theta) = 0\\).\nNon è detto che la SMV esista.\nLa SMV \\(\\hat{\\theta} = \\hat{\\theta}(y)\\) è una funzione del campione, anche se a volte tale funzione non è rappresentabile esplicitamente."
  },
  {
    "objectID": "lezioni/un_K.html#parametro-scalare-modello-esponenziale",
    "href": "lezioni/un_K.html#parametro-scalare-modello-esponenziale",
    "title": "R per l’analisi statistica multivariata",
    "section": "Parametro scalare: modello esponenziale",
    "text": "Parametro scalare: modello esponenziale\nSia \\(y = (y_1,\\dots,y_n)\\) un campione iid da una variabile casuale esponenziale con tasso di guasto \\(\\lambda\\), ovvero \\(Y \\sim \\text{Exp}(\\lambda)\\).\nSi ricordi che la densità di un modello esponenziale è \\[\nf(y; \\lambda) = \\lambda e^{-\\lambda y}, \\qquad y, \\lambda > 0.\n\\]\nDi conseguenza, la funzione di log-verosimiglianza associata al campione \\(y\\) è \\[\n\\ell(\\lambda) = \\ell(\\lambda; y) = n \\log \\lambda - \\lambda\\sum_{i=1}^ny_i.\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\nNel caso la derivazione di \\(\\ell(\\lambda)\\) non fosse immediatamente chiara, si svolgano per esercizio tutti i passaggi."
  },
  {
    "objectID": "lezioni/un_K.html#parametro-scalare-modello-esponenziale-1",
    "href": "lezioni/un_K.html#parametro-scalare-modello-esponenziale-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Parametro scalare: modello esponenziale",
    "text": "Parametro scalare: modello esponenziale\nLa funzione che calcola la verosimiglianza in può essere implementata in vari modi.\n\nloglik <- function(lambda, y) {\n  length(y) * log(lambda) - lambda * sum(y)\n}\n\nloglik2 <- function(lambda, y) {\n  sum(dexp(y, rate = lambda, log = TRUE))\n}\n\nloglik3 <- function(lambda, y) {\n  sum(log(lambda) - lambda * y)\n}\n\nConsideriamo il dataset aircondit7 della libreria boot, contenente i tempi di rottura relativi al sistema di condizionamento di alcuni aeroplani.\n\nlibrary(boot)\ndata(\"aircondit7\")\ny <- aircondit7$hours\n\n\ncurve(loglik(x, y), 1e-4, 0.06) # log-verosimiglianza nell'intervallo (0.001, 0.06)"
  },
  {
    "objectID": "lezioni/un_K.html#le-funzione-vettorizzabili-i",
    "href": "lezioni/un_K.html#le-funzione-vettorizzabili-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Le funzione vettorizzabili I",
    "text": "Le funzione vettorizzabili I\nLe tre funzioni implementate sono apparentemente equivalenti:\n\nloglik(0.01, y)\n\n[1] -125.9141\n\nloglik2(0.01, y)\n\n[1] -125.9141\n\nloglik3(0.01, y)\n\n[1] -125.9141\n\n\nTuttavia, solamente la prima è correttamente vettorizzata:\n\n# Risultato corretto\nloglik(c(0.01, 0.02, 0.03), y)\n\n[1] -125.9141 -124.6686 -130.3274\n\n# I seguenti comandi producono invece dei risultati errati\nloglik2(c(0.01, 0.02, 0.03), y)\n\n[1] -127.97\n\nloglik3(c(0.01, 0.02, 0.03), y)\n\n[1] -127.97"
  },
  {
    "objectID": "lezioni/un_K.html#le-funzioni-vettorizzabili-ii",
    "href": "lezioni/un_K.html#le-funzioni-vettorizzabili-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Le funzioni vettorizzabili II",
    "text": "Le funzioni vettorizzabili II\nIl linguaggio R ama lavorare in modo vettoriale (e tipicamente odia i cicli for…)\nSolamente loglik è una funzione vettorizzata rispetto al parametro lambda.\nIn altri termini, la funzione loglik può essere valutata in un vettore di punti ed il risultato sarà il vettore di valori di log-verosimiglianza associati.\nFortunatamente, le funzioni possono essere “convertite” come segue:\n\nloglik2 <- Vectorize(loglik2, vectorize.args = \"lambda\")\nloglik3 <- Vectorize(loglik3, vectorize.args = \"lambda\")\n\nloglik(c(0.01, 0.02, 0.03), y)\n\n[1] -125.9141 -124.6686 -130.3274\n\nloglik2(c(0.01, 0.02, 0.03), y)\n\n[1] -125.9141 -124.6686 -130.3274\n\nloglik3(c(0.01, 0.02, 0.03), y)\n\n[1] -125.9141 -124.6686 -130.3274"
  },
  {
    "objectID": "lezioni/un_K.html#qualche-cenno-alle-performance",
    "href": "lezioni/un_K.html#qualche-cenno-alle-performance",
    "title": "R per l’analisi statistica multivariata",
    "section": "Qualche cenno alle performance",
    "text": "Qualche cenno alle performance\nNonostante producano lo stesso risultato, le tre funzioni non hanno la stessa efficienza in termini di tempo.\nUna funzione nativamente vettorizzata è tipicamente più rapida di una conversione.\nPossiamo misurare le performance usando, ad esempio, il pacchetto microbenchmark.\n\nlibrary(microbenchmark) # Se assente, va installata\nmicrobenchmark(\n  L1 = loglik(c(0.01, 0.02, 0.03), y),\n  L2 = loglik2(c(0.01, 0.02, 0.03), y),\n  L3 = loglik3(c(0.01, 0.02, 0.03), y)\n)\n\nUnit: microseconds\n expr    min      lq     mean  median      uq     max neval\n   L1  1.470  2.2820  3.03238  2.5275  3.2815   8.354   100\n   L2 41.497 42.4965 60.08649 43.9370 77.5380 237.846   100\n   L3 38.322 39.4220 54.63223 42.7470 72.9960 123.918   100"
  },
  {
    "objectID": "lezioni/un_K.html#la-stima-di-massima-verosimiglianza",
    "href": "lezioni/un_K.html#la-stima-di-massima-verosimiglianza",
    "title": "R per l’analisi statistica multivariata",
    "section": "La stima di massima verosimiglianza",
    "text": "La stima di massima verosimiglianza\nLa funzione punteggio e l’informazione osservata del modello esponenziale sono pari a \\[\n\\ell'(\\lambda) = \\frac{n}{\\lambda} - \\sum_{i=1}^ny_i, \\qquad j(\\lambda) = - \\ell''(\\lambda) = \\frac{n}{\\lambda^2}.\n\\]\nEntrambe queste funzioni sono utili per motivi inferenziali. Ad esempio la stima di massima verosimiglianza si ottiene (nei casi regolari) ponendo \\(\\ell'(\\lambda) = 0\\).\nIn questo caso quindi avremo \\[\n\\hat{\\lambda} = \\frac{n}{\\sum_{i=1}^ny_i} = \\frac{1}{\\bar{y}}.\n\\]\nL’informazione osservata (in questo caso coincidente con l’informazione attesa) è invece estremamente utile per costruire ad esempio intervalli di confidenza\nLa stima di massima verosimiglianza (numerica)\nCome vederemo in seguito, risolvere l’equazione \\(\\ell'(\\lambda) = 0\\) può essere problematico (ovviamente non nel caso esponenziale…)."
  },
  {
    "objectID": "lezioni/un_K.html#procedure-numeriche",
    "href": "lezioni/un_K.html#procedure-numeriche",
    "title": "R per l’analisi statistica multivariata",
    "section": "Procedure numeriche",
    "text": "Procedure numeriche\nIn questi casi “difficili”, la stima di massima verosimiglianza può essere ottenuta tramite procedure numeriche.\nIn altri termini, utilizzeremo un algoritmo iterativo che produce una sequenza di valori \\(\\lambda_1, \\lambda_2, \\dots\\), tali che, quantomeno idealmente, \\[\n\\ell(\\lambda_{k+1}) \\ge \\ell(\\lambda_k).\n\\]\nIl nuovo valore \\(\\lambda_{k+1}\\) è tipicamente ottenuto a partire dal valore precedente \\(\\lambda_k\\).\nPertanto, questa tipologia di algoritmi hanno bisogno di un valore iniziale \\(\\lambda_1\\) definito dall’utente.\nDopo un certo numero di iterazioni, quando non si osservano più variazioni significative in termini di \\(\\lambda\\) e/o \\(\\ell(\\lambda)\\), l’algoritmo si ferma e si dice che è arrivato a convergenza."
  },
  {
    "objectID": "lezioni/un_K.html#il-metodo-di-newton-raphson-i",
    "href": "lezioni/un_K.html#il-metodo-di-newton-raphson-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il metodo di Newton-Raphson I",
    "text": "Il metodo di Newton-Raphson I\nNel metodo di Newton-Raphson, consideriamo lo sviluppo di Taylor della funzione di log-verosimiglianza \\(\\ell(\\lambda)\\) nel generico punto \\(\\lambda_k\\), troncato al termine quadratico \\[\n\\ell(\\lambda) \\approx \\ell(\\lambda_k) + \\ell'(\\lambda_k)(\\lambda - \\lambda_k) +  \\frac{\\ell''(\\lambda_k)}{2}(\\lambda - \\lambda_k)^2.\n\\]\nMassimizziamo tale sviluppo, equivalente a trovare il vertice di una parabola, e quindi otteniamo l’equazione di verosimiglianza approssimata \\[\n\\ell'(\\lambda) - j(\\lambda_k)(\\lambda - \\lambda_k) = 0,\n\\] che risolta rispetto a \\(\\lambda\\) porta allo schema iterativo \\[\n\\lambda_{k + 1} = \\lambda_k + j(\\lambda_k)^{-1}\\ell'(\\lambda_k), \\qquad k=1,2,\\dots.\n\\]\n\n\n\n\n\n\nNota\n\n\n\nIl metodo considera di fatto una serie di approssimazioni paraboliche della log-verosimiglianza, per le quali si va ogni volta a valutare il punto di massimo."
  },
  {
    "objectID": "lezioni/un_K.html#il-metodo-di-newton-raphson-ii",
    "href": "lezioni/un_K.html#il-metodo-di-newton-raphson-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il metodo di Newton-Raphson II",
    "text": "Il metodo di Newton-Raphson II\nIl metodo Newton-Raphson appena descritto si può implementare in come segue:\n\nlambda <- numeric(10); lambda[1] <- 0.005 # Punto iniziale (cosa succede cambiandolo?)\nn <- length(y); sum_y <- sum(y)\n# Algorithmo Newton-Raphson\nfor(k in 1:5){\n  score <- n / lambda[k] - sum_y # Funzione score\n  obs_info <- n / lambda[k]^2 # Informazione osservata\n  lambda[k + 1] <- lambda[k] + score / obs_info # Passo iterativo\n  print(c(lambda[k + 1], loglik(lambda[k + 1], y)), digits = 3) # Mostro i risultati\n}\n\n[1]    0.0084 -127.6403\n[1]    0.0123 -124.4969\n[1]    0.0149 -123.8855\n[1]    0.0156 -123.8601\n[1]    0.0156 -123.8600\n\n\nIl risultato esatto, in questo caso, è facile da calcolare e lo riportiamo per un confronto:\n\nlambda_hat <- 1 / mean(y)\nc(lambda_hat, loglik(lambda_hat, y))\n\n[1]    0.01559454 -123.86002328"
  },
  {
    "objectID": "lezioni/un_K.html#metodi-di-massimizzazione",
    "href": "lezioni/un_K.html#metodi-di-massimizzazione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Metodi di massimizzazione",
    "text": "Metodi di massimizzazione\nIn pratica, in R esistono diverse funzioni per la massimizzazione, basate su varie elaborazioni del metodo di Newton-Raphson (che noi non vedremo).\nTutte queste funzioni richiedono un valore iniziale ma non necessitano dei valori delle derivate, che vengono approssimate internamente.\nLe funzioni richiedono inoltre un qualche criterio di arresto.\nAlcuni metodi permettono l’utilizzo di vincoli sui parametri.\n\n\n\n\n\n\nNota\n\n\n\nPer ragioni storiche, le funzioni di R identificano sempre il minimo della funzione cercata. Tuttavia: \\[\n\\arg \\max_{\\lambda \\in \\mathbb{R}} \\:\\ell(\\lambda) = \\arg \\min_{\\lambda \\in \\mathbb{R}} \\:- \\ell(\\lambda).\n\\] In altri termini, è sufficiente cambiare di segno la funzione obiettivo."
  },
  {
    "objectID": "lezioni/un_K.html#la-funzione-nlminb",
    "href": "lezioni/un_K.html#la-funzione-nlminb",
    "title": "R per l’analisi statistica multivariata",
    "section": "La funzione nlminb",
    "text": "La funzione nlminb\nLa funzione nlminb effettua minimizzazioni numeriche, anche vettoriali.\nÈ una routine generalmente considerata più stabile, robusta ed affidabile della funzione concorrente optim, che vedremo in seguito.\nInoltre, consente di incorporare dei vincoli sui parametri, qualora questi fossero presenti.\nNel modello esponenziale, per esempio, si ha il vincolo \\(\\lambda > 0\\).\n\n# start = 1 significa che il valore iniziale è pari a 1\n# lower = 1e-5 implica che lambda > 0\nfit_exp <- nlminb(start = 1, objective = function(lambda) - loglik(lambda, y), lower = 1e-5)\nfit_exp\n\n$par\n[1] 0.01559454\n\n$objective\n[1] 123.86\n\n$convergence\n[1] 0\n\n$iterations\n[1] 16\n\n$evaluations\nfunction gradient \n      24       19 \n\n$message\n[1] \"relative convergence (4)\"\n\n\n\nlambda_hat <- fit_exp$par # Stima di massima verosimiglianza\ncurve(loglik(x, y), 0.001, 0.05)\nabline(v = lambda_hat, lty = \"dotted\")\n\n\n\n\n\noptim(par = 1, fn = function(lambda) - loglik(lambda, y), lower = 1e-5, method = \"L-BFGS-B\", hessian = TRUE)\n\n$par\n[1] 0.01561446\n\n$value\n[1] 123.86\n\n$counts\nfunction gradient \n      29       29 \n\n$convergence\n[1] 0\n\n$message\n[1] \"CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH\"\n\n$hessian\n         [,1]\n[1,] 99253.17\n\n\n\n# Informazione osservata\nobs_info <- length(y) / lambda_hat^2\nobs_info\n\n[1] 98688.38"
  },
  {
    "objectID": "lezioni/un_K.html#adeguatezza-del-modello",
    "href": "lezioni/un_K.html#adeguatezza-del-modello",
    "title": "R per l’analisi statistica multivariata",
    "section": "Adeguatezza del modello",
    "text": "Adeguatezza del modello\n\nplot(ecdf(y))\ncurve(pexp(x, lambda_hat), col = \"red\", add = TRUE)"
  },
  {
    "objectID": "lezioni/un_K.html#parametro-vettoriale-il-modello-weibull-i",
    "href": "lezioni/un_K.html#parametro-vettoriale-il-modello-weibull-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Parametro vettoriale: il modello Weibull I",
    "text": "Parametro vettoriale: il modello Weibull I\nSia \\(y = (y_1,\\dots,y_n)\\) un campione iid da una variabile casuale Weibull di parametri \\((\\gamma, \\beta)\\), ovvero \\(Y \\sim \\text{Weib}(\\gamma, \\beta)\\).\nSi ricordi che la densità di un modello Weibull è \\[\nf(y; \\gamma, \\beta) = \\frac{\\gamma}{\\beta} \\left(\\frac{y}{\\beta}\\right)^{\\gamma - 1} e^{-(y / \\beta)^\\gamma}, \\qquad y, \\gamma, \\beta > 0.\n\\]\nDi conseguenza, la funzione di log-verosimiglianza associata al campione \\(y\\) è \\[\n\\ell(\\gamma, \\beta) = \\ell(\\gamma, \\beta; y) = n \\log \\gamma - n \\gamma \\log \\beta + \\gamma \\sum_{i=1}^n\\log y_i - \\sum_{i=1}^n \\left(\\frac{y_i}{\\beta}\\right)^\\gamma.\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\nSi ottenga la precedente log-verosimiglianza (carta e penna)"
  },
  {
    "objectID": "lezioni/un_K.html#parametro-vettoriale-il-modello-weibull-ii",
    "href": "lezioni/un_K.html#parametro-vettoriale-il-modello-weibull-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Parametro vettoriale: il modello Weibull II",
    "text": "Parametro vettoriale: il modello Weibull II\nLa funzione che calcola la verosimiglianza in R può essere implementata in vari modi. Ne presentiamo qui uno dei tanti basato sulla funzione dweibull\n\nloglik <- function(par, y) {\n  sum(dweibull(y, shape = par[1], scale = par[2], log = TRUE))\n}\n\nSiamo interessati a capire se il modello Weibull, che generalizza quello esponenziale, rappresenta una scelta modellistica migliore.\nConsideriamo anche in questo caso il dataset aircondit7 della libreria boot:\n\nlibrary(boot)\ndata(\"aircondit7\")\ny <- aircondit7$hours"
  },
  {
    "objectID": "lezioni/un_K.html#grafico-della-verosimiglianza-i-facoltativo",
    "href": "lezioni/un_K.html#grafico-della-verosimiglianza-i-facoltativo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Grafico della verosimiglianza I (facoltativo)",
    "text": "Grafico della verosimiglianza I (facoltativo)\nIn generale non è possibile disegnare dei grafici della verosimiglianza con parametri vettoriali.\nL’unica eccezione è il caso \\(p = 2\\), in cui possiamo usare i cosiddetti grafici contour, basati sulle curve di livello.\nPer fare questo tipo di grafico, bisogna procedere per step.\n\nStep 1. Anzitutto bisogna definire un per ciascuna componente del parametro.\nStep 2. Bisogna quindi calcolare la log-verosimiglianza in ciascuna coppia di punti della griglia definita dal prodotto cartesiano dei due intervalli."
  },
  {
    "objectID": "lezioni/un_K.html#grafico-della-verosimiglianza-ii-facoltativo",
    "href": "lezioni/un_K.html#grafico-della-verosimiglianza-ii-facoltativo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Grafico della verosimiglianza II (facoltativo)",
    "text": "Grafico della verosimiglianza II (facoltativo)\nGli estremi degli intervalli vanno scelti manualmente. In pratica, bisogna procedere per tentativi se si vuole disegnare la verosimiglianza in una regione “sensata”.\n\n# Definizione degli intervalli di punti\ngamma <- seq(0.1, 2.25, length = 200)\nbeta <- seq(0.5, 400, length = 200)\n\n# Ottenimento della griglia tramite prodotto cartesiano \nparvalues <- expand.grid(gamma, beta)\n\n# Calcolo valori di verosimiglianza\nllikvalues <- apply(parvalues, 1, loglik, y = y)\n\n# Ri-organizzazione dei valori della log-verosimiglianza in forma matriciale\nllikvalues <- matrix(llikvalues, nrow = length(gamma), ncol = length(beta), byrow = F)\n\nQuindi, il grafico contour oppure sua variante filled.contour si possono ottenere abbastanza facilmente.\n\ncontour(gamma, beta, llikvalues,\n  xlab = expression(gamma), ylab = expression(beta), # Produce le lettere greche nel grafico\n  levels = seq(from = -140, to = -120, by = 2),\n  main = \"Log-verosimiglianza (Modello Weibull)\")\n\n\n\n\n\nfilled.contour(gamma, beta, llikvalues,\n  xlab = expression(gamma), ylab = expression(beta),\n  levels = seq(from = -140, to = -120, by = 1),\n  col = terrain.colors(20), main = \"Log-verosimiglianza (Modello Weibull)\")"
  },
  {
    "objectID": "lezioni/un_K.html#stima-di-massima-verosimiglianza",
    "href": "lezioni/un_K.html#stima-di-massima-verosimiglianza",
    "title": "R per l’analisi statistica multivariata",
    "section": "Stima di massima verosimiglianza",
    "text": "Stima di massima verosimiglianza\nNel caso Weibull la funzione punteggio è un vettore di dimensione due, che conduce alle \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\gamma}\\ell(\\gamma, \\beta) & = \\frac{n}{\\gamma} - n \\log\\beta + \\sum_{i=1}^n\\log{y_i} - \\sum_{i=1}^n\\left(\\frac{y_i}{\\beta}\\right)^\\gamma \\log\\left(\\frac{y_i}{\\beta}\\right) = 0, \\\\\n\\frac{\\partial}{\\partial \\beta}\\ell(\\gamma, \\beta) &= - \\frac{n \\gamma}{\\beta} +\\frac{\\gamma}{\\beta^{\\gamma+1}} \\sum_{i=1}^ny_i^\\gamma = 0.\n\\end{aligned}\n\\]\nRisolvendo la seconda equazione otteniamo la stima vincolata \\(\\hat{\\beta}_\\gamma = \\left(\\frac{1}{n}\\sum_{i=1}^n y_i^\\gamma \\right)^{1/\\gamma}\\), per ogni \\(\\gamma\\) fissato.\n\n\n\n\n\n\nProblema chiave\n\n\n\nSostituendo \\(\\hat{\\beta}_\\gamma\\) nella prima equazione otteniamo quindi: \\[\n\\frac{n}{\\gamma} + \\sum_{i=1}^n\\log y_i - n \\frac{\\sum_{i=1}^n y_i^\\gamma \\log y_i}{\\sum_{i=1}^n y_i^\\gamma} = 0.\n\\] Quest’ultima equazione purtroppo non ammette una soluzione analitica."
  },
  {
    "objectID": "lezioni/un_K.html#stima-di-massima-verosimiglianza-1",
    "href": "lezioni/un_K.html#stima-di-massima-verosimiglianza-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Stima di massima verosimiglianza",
    "text": "Stima di massima verosimiglianza\nPer trovare la stima di massima verosimiglianza dobbiamo quindi procedere per via numerica.\nSebbene esistano in R dei comandi che calcolano gli zeri di una funzione (uniroot), per identificare il massimo è numericamente più stabile far uso di funzioni dedicate.\nOltretutto, questo ci evita di dover fare dei conti analitici, come la derivata prima.\nAnche in questo caso bivariato, si è specificato il limite inferiore del dominio della funzione, ovvero \\(\\gamma, \\beta > 0\\).\n\nfit_weibull <- nlminb(start = c(1, 1), function(par) -loglik(par, y), lower = c(1e-7, 1e-7))\nfit_weibull\n\n$par\n[1]  1.024919 64.792419\n\n$objective\n[1] 123.8483\n\n$convergence\n[1] 0\n\n$iterations\n[1] 21\n\n$evaluations\nfunction gradient \n      22       49 \n\n$message\n[1] \"relative convergence (4)\"\n\n\n\nplot(ecdf(y))\ncurve(pexp(x, fit_exp$par), col = \"red\", add = TRUE)\ncurve(pweibull(x, fit_weibull$par[1], fit_weibull$par[2]), col = \"blue\", add = TRUE)"
  },
  {
    "objectID": "exe/es_1.html",
    "href": "exe/es_1.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Si scriva in R la funzione f(x) associata a\n\\[\nf(x) = \\frac{|\\sin(\\pi/4 x^2)|}{x}, \\qquad x \\neq 0.\n\\]\n\nQuanto vale \\(f(1)\\)? Quanto vale \\(f(10^8)\\)?\nSi approssimino \\(f(1)\\) ed \\(f(10)\\) alle prime due cifre decimali.\nSi faccia un grafico della funzione \\(f(x)\\) nell’intervallo \\((1,3)\\).\nSi calcoli \\(\\sum_{k=1}^{K} f(k)\\), per \\(K = 500\\).\nDifficile. La funzione integrate di R (si veda la documentazione), permette di calcolare numericamente integrali del tipo \\[\nI = \\int_a^b f(x)\\mathrm{d}x,\n\\] dove \\(a < b\\) sono due valori reali. Si calcoli il valore dell’integrale \\(\\int_1^3 f(x)\\mathrm{d}x\\), dove \\(f(x)\\) è la funzione usata nei punti precedenti."
  },
  {
    "objectID": "exe/es_1.html#esercizio-b",
    "href": "exe/es_1.html#esercizio-b",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio B",
    "text": "Esercizio B\nSi verifichino numericamente le seguenti identità per \\(n = 10, 100, 1000\\) (ove possibile).\n\n\\[\n\\sum_{k=0}^n(-1)^k\\binom{n}{k} = 0.\n\\]\n\\[\n\\sum_{k=1}^n k \\binom{n}{k} = n 2^{n-1}.\n\\]\n\\[\n\\sum_{k=1}^n(-1)^{k}k \\binom{n}{k} = 0.\n\\]"
  },
  {
    "objectID": "exe/es_1.html#esercizio-c",
    "href": "exe/es_1.html#esercizio-c",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio C",
    "text": "Esercizio C\nSi scriva in R una funzione roots(a, b, c) che riceve come input i coefficienti del polinomio\n\\[\na x^2 + b x + c,\n\\] e restituisce il vettore dei valori di \\(x\\) che lo rendono pari a zero.\n\nSi calcoli roots(1, 5, 2);\nSi calcoli roots(1, 2, 1);\nSi calcoli roots(1, 1, 1) e si commenti il risultato."
  },
  {
    "objectID": "exe/es_1.html#esercizio-d",
    "href": "exe/es_1.html#esercizio-d",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio D",
    "text": "Esercizio D\nSi definisca in R una matrice simmetrica \\({\\bf A}\\) di dimensione \\(5 \\times 5\\), i cui elementi sono \\[\n{\\bf A} = \\begin{pmatrix}\n26 &  22 &  17 &  22 &  23 \\\\\n22 &  18 &  14 &  23 &  27 \\\\\n17 &  14 &  14 &  20 &  24 \\\\\n22 &  23 &  20 &  26 &  23 \\\\\n23 &  27 &  24 &  23 &  12 \\\\\n\\end{pmatrix}.\n\\]\n\nSi verifichi empiricamente che \\(\\text{det}({\\bf A}^{-1}) = 1 / \\text{det}({\\bf A})\\).\nSi verifichi empiricamente che \\(\\text{det}({\\bf A}^2) = \\text{det}({\\bf A})^2\\).\nSi calcoli la traccia di \\({\\bf A}\\), ovvero \\(\\text{tr}({\\bf A}) = \\sum_{i=1}^n a_{ii}\\), per \\(n = 5\\).\nSe verifichi empiricamente che \\(\\text{det}({\\bf A}) = \\prod_{i=1}^n \\lambda_i\\), dove \\(\\lambda_1,\\dots,\\lambda_n\\) sono gli autovalori di \\({\\bf A}\\)."
  },
  {
    "objectID": "exe/es_1.html#esercizio-e",
    "href": "exe/es_1.html#esercizio-e",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio E",
    "text": "Esercizio E\nLa distanza euclidea tra due vettori \\({\\bf x}\\) e \\({\\bf y}\\) in \\(\\mathbb{R}^p\\) è definita come \\[d({\\bf x},{\\bf y}) = \\sqrt{\\sum_{j=1}^p(x_j - y_j)^2}.\\]\n\nSi scriva la funzione R dist_euclid(x, y) che calcola la distanza euclidea tra due vettori.\nSe x = c(1, 4, 2, 2, 10) e y = c(8, 1, 8, 3, 6), quanto vale dist_euclid(x, y)?"
  },
  {
    "objectID": "exe/es_1.html#esercizio-f",
    "href": "exe/es_1.html#esercizio-f",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio F",
    "text": "Esercizio F\nLa norma di Frobenius \\(||{\\bf A}||_F\\) di una matrice \\({\\bf A}\\) a valori reali di dimensione \\(n \\times m\\) è definita come \\[||{\\bf A}||_F = \\sqrt{\\sum_{i=1}^n \\sum_{j=1}^m a_{ij}^2}.\\]\n\nSi scriva la funzione R frobenius_norm(A) che calcola la norma di Frobenius per una matrice A.\nSe A = cbind(1:5,6:10,11:15), quanto vale frobenius_norm(A)?"
  },
  {
    "objectID": "exe/es_1.html#esercizio-g",
    "href": "exe/es_1.html#esercizio-g",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio G",
    "text": "Esercizio G\nSi consideri il dataset data(mtcars), che è presente in R. Si risponda quindi alle seguendi domande:\n\nQuante righe e quante colonne compongono tale dataset?\nCome mai il comando mtcars[1:20] restituisce un errore? Qual è la differenza dal comando mtcars[1:20, ]?\nCiascuna delle seguenti righe contiene degli errori (bug). Si propongano delle modifiche per sistemarlo\n\n\nmtcars[mtcars$cyl = 4, ] \nmtcars[-1:4, ] \nmtcars[mtcars$cyl <= 5] \nmtcars[mtcars$cyl == 4 | 6, ]"
  },
  {
    "objectID": "exe/es_1.html#esercizio-h",
    "href": "exe/es_1.html#esercizio-h",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio H",
    "text": "Esercizio H\nSia \\({\\bf A}\\) una matrice di dimensione \\(n \\times n\\). Si implementi una funzione che estrae gli elementi della diagonale \\(a_{ii}\\), per \\(i = 1,\\dots,n\\) della matrice \\({\\bf A}\\). La si confronti quindi con la funzione diag di R."
  },
  {
    "objectID": "exe/es_1.html#esercizio-i",
    "href": "exe/es_1.html#esercizio-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio I",
    "text": "Esercizio I\nChe cosa restituisce la funzione f(10)? Si discuta il risultato senza eseguire il seguente codice\n\nh <- function(x) {\n  x^2 \n}\n\ng <- function(x) {\n  h(x) + 1 \n}\n\nf <- function(x) {\n  g(x)*2 \n}\n\nf(10)"
  },
  {
    "objectID": "exe/es_1.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "href": "exe/es_1.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)",
    "text": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)\n\nEsercizio 1.2, pag. 39.\nEsercizio 1.3, pag. 39.\nEsercizio 1.11, pag. 41."
  },
  {
    "objectID": "exe/es_1.html#esercizi-tratti-dai-libro-di-testo-robert-casella-rs",
    "href": "exe/es_1.html#esercizi-tratti-dai-libro-di-testo-robert-casella-rs",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Robert & Casella (RS)",
    "text": "Esercizi tratti dai libro di testo Robert & Casella (RS)\n\nEsercizio 1.3, pag. 9.\nEsercizio 1.4, pag. 9.\nEsercizio 1.5, pag. 9.\nEsercizio 1.9, pag. 31.\nEsercizio 1.12, pag. 38."
  },
  {
    "objectID": "exe/es_2.html",
    "href": "exe/es_2.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "La varianza campionaria dei dati \\({\\bf x} = (x_1,\\dots,x_n)\\) è definita come\n\\[\n\\text{var}({\\bf x}) = \\frac{1}{n}\\sum_{i=1}^n(x_i - \\bar{x})^2,\n\\] dove \\(\\bar{x}\\) è la media campionaria. Si noti che \\(\\text{var}({\\bf x})\\) ammette la rappresentazione alternativa\n\\[\\text{var}({\\bf x}) = \\frac{1}{2 n^2} \\sum_{i=1}^n \\sum_{j = 1}^n (x_i - x_j)^2.\\]\n\n\nSi scriva una funzione var2(x) che calcola la varianza di \\({\\bf x}\\) utilizzando la definizione.\nSi scriva una funzione var3(x) che calcola la varianza di \\({\\bf x}\\) utilizzando la formula basata sulle distanze tra coppie di elementi.\nSi supponga che x = c(1, 4, 2, 2, 10). Si verifichi che le due funzioni var2(x) e var3(x) forniscono lo stesso risultato.\nSi supponga ora che x <- 1:3000. Si notano differenze rispetto al punto precedente?\nSi confrontino le funzioni var2 e var3 con la funzione var implementata in R, utilizzando i dati del punto 3. Come mai i risultati differiscono, anche se di poco? Si consulti la documentazione per rispondere."
  },
  {
    "objectID": "exe/es_2.html#esercizio-b",
    "href": "exe/es_2.html#esercizio-b",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio B",
    "text": "Esercizio B\nQuesto esercizio ripercorre l’unità I del corso Statistica I, a cui si rimanda per un ripasso sugll’indice di Gini e una descrizione del problema.\nA questo link sono disponibili i dati delle elezioni municipali del 2016 presso il comune di Milano.\n\n\nSi carichino in memoria i dati.\nQuali variabili contiene il dataset elez? Di quale tipologia sono?\nSi ottenga il numero di voti ottenuti da ciascun candidato nei differenti Municipi di Milano.\nSi ottenga il numero di voti ottenuti da ciascun candidato e se ne faccia un grafico. Si ottenga inoltre la percentuale di voti ottenuti da ciascun candidato.\nSi scriva la funzione Gini(x) che calcola l’indice di Gini per una variabile qualitativa. L’indice di Gini è definito come \\[\nG = 1 - \\sum_{j=1}^k f_j^2,\n\\] dove \\(f_1,\\dots,f_k\\) sono le frequenze relative delle \\(k\\) modalità.\nSi scriva una funzione Gini_norm(x)che calcola l’indice di Gini normalizzato, ovvero \\[G_\\text{norm} = \\frac{k}{k-1} G.\\]\nSi valuti la polarizzazione dei voti tra i candidati nelle diverse municipalità utilizzando l’indice di Gini normalizzato. Si organizzino quindi i risultati in una tabella e si dica quale municipalità presenta la polarizzazione maggiore."
  },
  {
    "objectID": "exe/es_2.html#esercizio-c",
    "href": "exe/es_2.html#esercizio-c",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio C",
    "text": "Esercizio C\nQuesto esercizio riprende i dati considerati nell’unità J del corso Statistica I, a cui si rimanda per una descrizione più approfondita del dataset.\nI dati sono disponibili a questo link.\n\n\nSi carichino i dati in memoria e si salvi il dataset nell’oggetto province.\nQuali variabili contiene il dataset province? Di quale tipologia sono?\nSi rappresenti graficamente la variabile istruzione tramite istogramma. Si calcoli quindi media, mediana e varianza.\nSi rappresenti graficamente la funzione di ripartizione della variabile agricoltura.\nSi rappresenti il diagramma a dispersione delle variabili agricoltura e istruzione. Si può notare una qualche relazione?\nSi ottenga la matrice di varianza e covarianza.\nSi ottenga la matrice di correlazione. Si commenti la relazione esistente tra agricoltura e istruzione."
  },
  {
    "objectID": "exe/es_2.html#esercizio-d",
    "href": "exe/es_2.html#esercizio-d",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio D",
    "text": "Esercizio D\nNel dataset calcio disponibile a questo link, ciascuna unità statistica rappresenta una partita di calcio della Serie A italiana, relativa ai campionati 2008-2015. Il dataset è composto dalle seguenti variabili:\n\nDate indica la data della partita.\nHomeTeam e AwayTeam indicano, rispettivamente, la squadra che gioca in casa e la squadra ospite per ciascuna partita.\nFTR indica se la squadra che giocava in casa ha vinto (H), pareggiato (D), oppure perso (A).\nLe variabili B365H, B365D, B365A sono le quote per la vittoria, pareggio, sconfitta della squadra di casa.\n\nSupponendo di scommettere sulla vittoria della squadra di casa, puntando un euro su di essa si otterrebbero B365H euro in caso di vittoria.\n\n\nSi carichi il dataset in memoria.\nVerificare le tipologie di variabili presenti nel dataset calcio.\nControllare se esistono dei dati mancanti nel dataset. Se presenti, si escludano le righe contenenti dei valori mancanti dall’analisi. Suggerimento: si usi la funzione na.omit.\nCalcolare i principali indici descrittivi per la variabile B365H. Rappresentarla poi tramite istogramma ed il boxplot. Sono presenti valori anomali? Da cosa è possibile intuirlo?\nEffettuare l’analisi del punto precedenti sulla trasformazione logaritmica di B365H. Sono presenti valori anomali?\nValutare la correlazione presente tra B365H e B365A. Ci si poteva aspettare un risultato simile? Cosa implicherebbe una correlazione positiva?\nRappresentare con un grafico opportuno la relazione tra le trasformate logaritmiche delle variabili B365H e B365A. Si commenti il risultato.\nValutare la quota media B365H per ciascuna categoria della variabile FTR. Come si interpreta questo risultato?\nRappresentare tramite boxplot la variabile B365H per ciascuna categoria della variabile FTR. Si commenti il risultato."
  },
  {
    "objectID": "exe/es_2.html#esercizio-e",
    "href": "exe/es_2.html#esercizio-e",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio E",
    "text": "Esercizio E\nNel dataset imdb disponibile a questo link, ciascuna unità statistica è un film estratto dal sito http://www.imdb.com/ (Internet Movie Data Base). Per ciascun film, sono a disposizione le seguenti variabili:\n\nmovie_title è il titolo del film.\nduration è la durata del film espressa in minuti.\nlgrossè la trasformazione logaritmica dell’incasso lordo, espresso in dollari.\nlbudgetè la trasformazione logaritmica del budget, espresso in dollari.\nAction, Adventure, Animation, Comedy, Crime, Documentary, Drama, Family, Fantasy, History, Horror, Music, Romance, SciFi, Thriller, War, Western, sono variabili qualitative che indicano se il film appartiene o meno al genere. Ciascun film può appartenere a più generi contemporaneamente.\n\n\n\nSi carichi il dataset in memoria. Si controlli la tipologia delle variabili.\nQuante sono le unità statistiche?\nQual è la durata media dei film del dataset? E l’incasso medio?\nCi sono differenze tra la distribuzione della durata (duration) dei film drammatici (Drama) e quelli non drammatici? Si risponda tramite opportuni indici descrittivi ed analisi grafiche.\nQuali sono i 5 film che presentano, all’interno del dataset, i maggiori incassi? Suggerimento: si usi la funzione order.\nRappresentare con grafici appropriati le distribuzioni marginali e la distribuzione congiunta delle variabili lbudget e lgross. Che tipo di relazione sembra esserci tra le due variabili?\nSi calcoli la correlazione tra lbudget e lgross e si commenti il risultato.\nSi calcoli la correlazione tra duration e lgross e si commenti il risultato. Possiamo quindi concludere che, per guodagnare molto, sia sufficiente produrre un film della durata di 12 ore?"
  },
  {
    "objectID": "exe/es_2.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "href": "exe/es_2.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)",
    "text": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)\n\nEsercizio 1.14, pag. 41.\nEsercizio 2.1, pag. 75.\nEsercizio 2.2, pag. 75.\nEsercizio 2.3, pag. 75.\nEsercizi 2.4 e 2.5, pag. 75-76.\nEsercizio 2.10, pag. 77.\nEsercizio 2.12, pag. 77.\nEsercizio 3.1, pag. 96.\nEsercizio 3.4, pag. 98."
  },
  {
    "objectID": "exe/es_3.html",
    "href": "exe/es_3.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "È ragionevole supporre che la durata dei voli diretti Milano - New York si distribuisca come una normale di media \\(\\mu=500\\) minuti e varianza \\(\\sigma^2 = 625\\).\n\nCon quale probabilità un volo impiegherà meno di 9 ore (540 min) per arrivare a destinazione?\nCon quale probabilità un volo impiegherà più di 8 ore e mezza (510 min) per arrivare?\nSi valuti la percentuale di aerei che impiega un tempo compreso tra 470 e 520 minuti."
  },
  {
    "objectID": "exe/es_3.html#esercizio-b",
    "href": "exe/es_3.html#esercizio-b",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio B",
    "text": "Esercizio B\nLa funzione errore erf(x) ammette la seguente espansione in serie\n\\[\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-s^2}ds = \\frac{2}{\\sqrt{\\pi}} \\sum_{n=0}^\\infty(-1)^n \\frac{x^{2n +1}}{n!(2n+1)}.\\] Inoltre, si noti che\n\\[\n\\mathbb{P}(X \\le x) = \\Phi(x) = \\frac{1}{2}\\left[1 + \\text{erf}(x/\\sqrt{2}) \\right].\n\\] Dove \\(X \\sim N(0,1)\\) è una distribuzione normale standard.\n\nSi costruiscano le funzioni erf_approx(x,N) e pnorm_approx(x, N) basate su un troncamento al termine \\(N\\)-esimo della serie mostrata qui sopra. In altri termini, si usi l’approssimazione \\[\\text{erf}(x) \\approx \\frac{2}{\\sqrt{\\pi}} \\sum_{n=0}^N(-1)^n \\frac{x^{2n +1}}{n!(2n+1)}.\\]\nSi valutino le funzioni erf_approx(x,N) e pnorm_approx(x, N) nei punti \\(x = 0\\), \\(x = 1\\) e \\(x = 2\\), avendo fissato \\(N = 10\\). Si commentino i risultati.\nSi confrontino i valori del punto precedente con il valore ottenuto tramite la funzione pnorm. Si faccia quindi un ulteriore confronto nel punto \\(x = -3\\) usando \\(N = 10\\). Si commenti.\nSi approssimi la probabilità \\(\\mathbb{P}(X \\le -3)\\) tramite simulazione."
  },
  {
    "objectID": "exe/es_3.html#esercizio-c",
    "href": "exe/es_3.html#esercizio-c",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio C",
    "text": "Esercizio C\nIn un noto gioco da tavolo, si usano dadi a \\(20\\) facce. Il lancio del dado pertanto corrisponde ad una variabile aleatoria \\(X\\) tale che\n\\[\n\\mathbb{P}(X = k) = \\frac{1}{20}, \\qquad k=1,\\dots,20.\n\\]\n\nPer superare una determinata prova, un giocatore lancia il dado da \\(20\\). Dopo aver aggiunto \\(5\\) al risultato, il giocatore controlla se il totale è maggiore o uguale a \\(17\\). Si calcoli la probabilità di questo evento analiticamente e tramite simulazione.\n\nIn determinati contesti, al giocatore è concesso un vantaggio. Questo significa che può tirare il dado due volte e considerare il risultato più alto. In formule, siano \\(X_1,X_2\\) due variabili aleatorie indipendenti e distribuite come \\(X\\). Si ponga quindi \\(Z = \\max\\{X_1,X_2\\}\\).\n\nSi rappresenti graficamente la distribuzione di probabilità di \\(Z\\).\nSi ottenga tramite simulazione la probabilità \\(\\mathbb{P}(Z + 5 \\ge 17)\\). Si confronti il risultato con la probabilità ottenuta al punto precedente. Al giocatore è effettivamente concesso un vantaggio?"
  },
  {
    "objectID": "exe/es_3.html#esercizio-d-difficile",
    "href": "exe/es_3.html#esercizio-d-difficile",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio D (difficile)",
    "text": "Esercizio D (difficile)\nUna variabile aleatoria \\(X\\) è distribuita come una variabile di Cauchy (standard) se la sua densità è pari a\n\\[\nf(x) = \\frac{1}{\\pi}\\frac{1}{1 + x^2}, \\qquad x \\in \\mathbb{R}.\n\\] Suggerimento: si usino la funzioni dcauchy, pcauchy, qcauchy e rcauchy.\n\nSi rappresenti graficamente la funzione \\(f(x)\\) nell’intervallo \\((-4,4)\\) e si confronti il grafico con la densità di una normale standard.\nSi calcoli tramite simulazione la probabilità che \\(X\\) sia maggiore di \\(3\\). Si confronti il risultato ottenuto con il valore teorico.\nSiano \\(X_1,\\dots,X_n\\) dei valori iid da una Cauchy standard e si calcoli \\[\n\\frac{1}{n}\\sum_{i=1}^nX_i,\n\\] per vari valori di \\(n = 10^2, 10^3, 10^4, 10^5\\). Si ripeta l’esperimento alcune volte. La media aritmetica dei valori simulati sembra convergere? Si commenti il risultato."
  },
  {
    "objectID": "exe/es_3.html#esercizio-e",
    "href": "exe/es_3.html#esercizio-e",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio E",
    "text": "Esercizio E\nL’indice di asimmetria di Bowley di una variabile aleatoria è definito come segue\n\\[\nB = \\frac{\\mathcal{Q}(0.75) - 2\\mathcal{Q}(0.5) + \\mathcal{Q}(0.25)}{\\mathcal{Q}(0.75) - \\mathcal{Q}(0.25)}.\n\\]\n\nSi calcoli l’indice di asimmetria di Bowley di una distribuzione gaussiana di media \\(5\\) e varianza \\(25\\).\nSi calcoli l’indice di Bowley per una distribuzione gamma di parametri \\(\\alpha = 2\\) e \\(\\beta = 4\\) e si commenti il risultato.\nSi calcoli l’indice di Bowley per una distribuzione gamma di parametri \\(\\alpha = 200\\) e \\(\\beta = 400\\) e lo si confronti col valore ottenuto al punto precedente. Si commenti il risultato."
  },
  {
    "objectID": "exe/es_3.html#esercizio-f",
    "href": "exe/es_3.html#esercizio-f",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio F",
    "text": "Esercizio F\nLa distribuzione beta-binomiale di parametri \\(\\alpha, \\beta > 0\\) ed \\(n \\in \\mathbb{N}\\) di è una variabile aleatoria discreta \\(X\\) è tale che\n\\[\n\\mathbb{P}(X = k) = \\binom{n}{k}\\frac{\\mathcal{B}(k+\\alpha,n-k+\\beta)}{\\mathcal{B}(\\alpha,\\beta)},\\qquad k=0,\\dots,n.\n\\] dove \\(\\mathcal{B}\\) è la funzione beta.\n\nSi definiscano la funzione di probabilità dbetabinom(k, n, alpha, beta) e la funzione di ripartizione pbetabinom(k, n, alpha, beta) di una distribuzione beta-binomiale.\nSi controlli empiricamente che per \\(n = 40\\) e \\(\\alpha = \\beta = 2\\) le probabilità descritte nell’equazione precedente sommano a uno. Quindi, si rappresenti graficamente la distribuzione.\nUtilizzando i parametri del punto precedente, si calcolino numericamente media e varianza di \\(X\\)."
  },
  {
    "objectID": "exe/es_3.html#esercizio-g",
    "href": "exe/es_3.html#esercizio-g",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio G",
    "text": "Esercizio G\nCalcolare tramite simulazione il valore di\n\\[\\mathbb{E}\\left(e^{-|x|^3}\\right), \\quad X \\sim \\text{N}(0,1).\\]"
  },
  {
    "objectID": "exe/es_3.html#esercizio-h",
    "href": "exe/es_3.html#esercizio-h",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio H",
    "text": "Esercizio H\nSia \\(X\\) una variabile casuale e sia \\(g(\\cdot)\\) una funzione a valori non negativi. Allora, per ogni \\(k > 0\\)\n\\[\n\\mathbb{P}(g(X) \\ge k) \\le \\frac{\\mathbb{E}(g(X))}{k}.\n\\]\n\nSi verifichi tramite simulazione la disugaglianza di Markov nel caso \\(g(x) = x^2\\) e con \\(X \\sim \\text{N}(0,1)\\), per \\(k = 1,2,3\\). Si confronti il risultato con i valori teorici.\nSi verifichi tramite simulazione la disugaglianza di Markov nel caso \\(g(x) = e^{x/100}\\) e con \\(X \\sim \\text{Ga}(10,1/10)\\), per \\(k = 1,2,3\\)."
  },
  {
    "objectID": "exe/es_3.html#esercizio-i",
    "href": "exe/es_3.html#esercizio-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio I",
    "text": "Esercizio I\nIn un’aula universitaria sono presenti \\(50\\) persone, tutte nate nello stesso anno (non bisestile). Si supponga che la distribuzione del giorno del compleanno sia una distribuzione uniforme discreta nei valori \\(1,\\dots,365\\) e che le date di compleanno delle persone presenti possano essere considerate variabili aleatorie indipendenti.\nUsando la funzione duplicated ed i cicli for di R:\n\nSi calcoli la probabilità che due persone siano nate nello stesso giorno tramite simulazione.\nNell’ora successiva sono presenti in aula \\(25\\) persone. Si ricacolino le probabilità del punto precedente.\nSi scriva quindi del codice R che fa uso della funzione replicate al posto dei cicli for e si ri-ottengano i risultati dei punti precedenti. Ci sono dei miglioramenti in termini di tempo?"
  },
  {
    "objectID": "exe/es_3.html#esercizio-l",
    "href": "exe/es_3.html#esercizio-l",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio L",
    "text": "Esercizio L\nLa variabile aleatoria \\(X\\) ha distribuzione normale asimmetrica (skew normal) con parametro \\(\\alpha \\in \\mathbb{R}\\) se la sua funzione di densità è pari a\n\\[\nf(x) = 2\\phi(x)\\Phi(\\alpha x), \\qquad x \\in \\mathbb{R}.\n\\] in cui \\(\\phi(x)\\) e \\(\\Phi(x)\\) sono, rispettivamente, la densità e la funzione di ripartizione di una normale standard.\n\nSi scriva la funzione dsn(x, alpha) che calcola la densità \\(f(x)\\).\nSi tracci il grafico di \\(f(x)\\) nell’intervallo \\((-4,4)\\) utilizzando i valori \\(\\alpha = -5, 0, 5\\). Si proponga un’interpretazione per il parametro \\(\\alpha\\).\nSi scriva la funzione rsn(n, alpha) che simula \\(n\\) valori pseudo-casuali da una funzione normale asimmetrica di parametro \\(\\alpha\\) sfruttando la seguente relazione per \\(X\\) \\[\nX = \\sqrt{1 - \\delta^2} Z_1 + \\delta|Z_2|, \\qquad \\delta = \\frac{\\alpha}{\\sqrt{1 + \\alpha^2}}, \\qquad Z_1,Z_2 \\overset{\\text{iid}}{\\sim} \\text{N}(0,1).\n\\]\nSi usi la funzione rsn per simulare \\(10^4\\) valori da una normale asimmetrica di parametro \\(\\alpha = 7\\) e si confronti l’istogramma dei dati simulati con la funzione di densità."
  },
  {
    "objectID": "exe/es_3.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "href": "exe/es_3.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)",
    "text": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)\n\nEsercizio 13.1, pag 333."
  },
  {
    "objectID": "exe/es_3.html#esercizi-tratti-dai-libro-di-testo-robert-casella-rs",
    "href": "exe/es_3.html#esercizi-tratti-dai-libro-di-testo-robert-casella-rs",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Robert & Casella (RS)",
    "text": "Esercizi tratti dai libro di testo Robert & Casella (RS)\n\nEsercizio 3.3, pag. 111 (difficile)."
  },
  {
    "objectID": "exe/es_4.html",
    "href": "exe/es_4.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Siano \\(X_1,\\dots,X_n\\) delle variabili aleatorie indipendenti normali di media \\(\\mu\\) e varianza \\(\\sigma^2\\).\n\nSupponendo che i veri valori siano \\(\\mu = 5\\) e \\(\\sigma^2 = 12\\):\n\nSi verifichi empiricamente se la mediana costituisce uno stimatore consistente per la media \\(\\mu\\). Si tratta di uno stimatore distorto? Si risponda tramite simulazione.\nSi confrontino gli stimatori media aritmetica e la mediana in termini di errore quadratico medio, con \\(n = 30\\). Quale stimatore è preferibile?\nÈ verosimile pensare che lo stimatore mediana abbia una distribuzione asintoticamente normale? Si risponda tramite un’analisi grafica."
  },
  {
    "objectID": "exe/es_4.html#esercizio-b",
    "href": "exe/es_4.html#esercizio-b",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio B",
    "text": "Esercizio B\nMediante un opportuno studio di simulazione, si mostri che la varianza campionaria e la varianza campionaria corretta sono stimatori consistenti per la varianza della popolazione nel seguente caso:\n\nI dati \\(x_1,\\dots,x_n\\) sono realizzazioni indipendenti da \\(X\\), dove \\(X \\sim \\text{N}(0, 10)\\);"
  },
  {
    "objectID": "exe/es_4.html#esercizio-c",
    "href": "exe/es_4.html#esercizio-c",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio C",
    "text": "Esercizio C\nL’indice di asimmetria standardizzato per una variabile aleatoria \\(X\\) è definito come\n\\[\n\\gamma = \\mathbb{E}\\left\\{\\left(\\frac{X - \\mu}{\\sigma}\\right)^3\\right\\},\n\\] dove \\(\\mu\\) e \\(\\sigma\\) rappresentano, rispettivamente, media e varianza di \\(X\\). Lo stimatore usuale di \\(\\gamma\\) è\n\\[\n\\hat{\\gamma}_n = \\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{X_i - \\bar{X}}{S}\\right)^3,\n\\] dove \\(\\bar{X} = 1/\\sum_{i=1}^nX_i\\) e \\(S^2 = 1/n\\sum_{i=1}^n(X_i - \\bar{X})^2\\) indicano la media aritmetica e la varianza campionaria (non corretta).\n\nSia \\(X \\sim \\text{N}(3, 10)\\) e si noti che in questo caso \\(\\gamma = 0\\).\n\nLo stimatore \\(\\hat{\\gamma}_n\\) è consistente per \\(\\gamma\\)?\nLo stimatore \\(\\hat{\\gamma}_n\\) è distorto per \\(n = 10\\)? Se si, di quanto?\nA quanto è pari l’errore quadratico medio dello stimatore \\(\\hat{\\gamma}_n\\) se \\(n = 100\\)?\nLa distribuzione di \\(\\hat{\\gamma}_n\\) è approssimativamente normale, per \\(n = 100\\)?\nSi risponda a tutte le domande precedenti assumendo \\(X \\sim \\text{Ga}(10,2)\\) e \\(X \\sim \\text{Logistica}(0,1)\\).\n\nSuggerimenti: Si utilizzi la classe di funzioni *logis. È inoltre lecito utilizzare le pagine di Wikipedia distribuzione Gamma e distribuzione logistica per identificare i corrispettivi indici di asimmetria."
  },
  {
    "objectID": "exe/es_4.html#esercizio-d",
    "href": "exe/es_4.html#esercizio-d",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio D",
    "text": "Esercizio D\nSiano \\(x_1,\\dots,x_n\\) delle realizzazione indipendenti ed identicamente distribuite da una variabile aleatoria Weibull di parametri \\(\\alpha, \\lambda\\), la cui densità è pari a\n\\[\nf(x; \\alpha, \\lambda) = \\left(\\frac{\\alpha}{\\lambda}\\right)\\left(\\frac{x}{\\lambda}\\right)^{\\alpha - 1}\\exp\\left\\{- \\left(\\frac{x}{\\lambda}\\right)^\\alpha\\right\\}, \\qquad \\alpha > 0, \\quad \\lambda > 0.\n\\] Si consideriano inoltre i dati seguenti:\n\nx <- c(225, 171, 198, 189, 189, 135, 162, 135, 117, 162)\n\n\n\nSi crei in R la funzione loglik(alpha, lambda, x), ovvero la funzione di log-verosimiglianza, pari a \\[\\ell(\\alpha,\\lambda) = \\sum_{i=1}^n\\log f(x_i; \\alpha,\\lambda).\\] Se ritenuto utile, si noti che in R esiste la funzione dweibull.\nUtilizzando la funzione del punto precedente, si calcoli il valore della verosimiglianza quando \\(\\alpha = 6\\) e \\(\\lambda = 200\\).\nNon è possibile calcolare in forma chiusa la stima di massima verosimiglianza \\((\\hat{\\alpha},\\hat{\\lambda})\\). Si utilizzi quindi la funzione nlminb applicata a loglik per ottenerla. Si consulti la documentazione per capire come gestire il caso con due parametri.\nSi rappresentino i dati tramite istogramma e si rappresenti la curva \\(f(x,\\hat{\\alpha},\\hat{\\lambda})\\). La stima ottenuta sembra ragionevole?"
  },
  {
    "objectID": "exe/es_4.html#esercizio-e",
    "href": "exe/es_4.html#esercizio-e",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio E",
    "text": "Esercizio E\nSiano \\(X_1,X_2, \\ldots,X_n\\) variabili aleatorie iid (indipendenti ed identicamente distribuite) di Poisson di parametro \\(\\lambda\\). Si considerino, inoltre, i seguenti stimatori:\n\\[\nT_1 = \\sum_{i=1}^n X_i, \\qquad T_2 = \\sum_{i=1}^n i \\cdot X_i, \\qquad T_3 = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\] Supponendo che il vero valore sia \\(\\lambda = 3\\):\n\nSi verifichi empiricamente se costituiscono stimatori consistenti per \\(\\lambda\\). Si tratta di stimatori distorti? Si risponda tramite simulazione.\nSi confrontino gli stimatori in termini di errore quadratico medio, con \\(n = 50\\). Quale stimatore è preferibile?\nÈ verosimile pensare che abbiano distribuzione asintoticamente normale? Si risponda tramite un’analisi grafica."
  },
  {
    "objectID": "exe/es_4.html#esercizio-f",
    "href": "exe/es_4.html#esercizio-f",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio F",
    "text": "Esercizio F\nSi consideri un campione casuale di \\(n\\) osservazioni da una popolazione normale \\(N(0, \\theta)\\), dove \\(\\theta\\) rappresenta la varianza incognita della variabile aleatoria. Supponendo di avere osservato il seguente campione di \\(10\\) osservazioni:\n\nx <- c(2.52, 0.76, 1.55, 0.98, 4.03, 0.09, -2.27, 1.67, -0.54, -0.27)\n\n\nSi crei in R la funzione loglik(theta, x), ovvero la funzione di log-verosimiglianza, pari al logaritmo della funzione di verosimiglianza \\[\\mathscr{L}(\\theta) = (2\\pi\\theta)^{-n/2} e^{-\\frac{1}{2 \\theta}\\sum_{i=1}^n x_i^2}.\\]\nUtilizzando la funzione del punto precedente, si calcoli il valore della log-verosimiglianza quando \\(\\theta=3\\) e \\(\\theta=5\\). Quale è il valore più “verosimile”?\nSi utilizzi la funzione nlminb applicata a loglik per ottenere la stima di massima verosimiglianza.\nSi rappresentino i dati tramite istogramma e si rappresenti la densità stimata \\(f(x ; 0, \\hat{\\theta})\\). La stima ottenuta sembra ragionevole?"
  },
  {
    "objectID": "exe/es_4.html#esercizio-e-1",
    "href": "exe/es_4.html#esercizio-e-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizio E",
    "text": "Esercizio E\nSiano \\(x_1, \\ldots, x_n\\) delle realizzazioni iid da \\(X \\sim \\text{N}(5, 15)\\). Si realizzi uno studio di simulazione che confronti la media campionaria e la media troncata di livello \\(\\alpha = 5\\%\\). Si tratta di stimatori consistenti per la media della popolazione?\nLa media troncata non considera le prime ed ultime \\(k\\) osservazioni, dove \\(k = n \\cdot\\alpha\\) (approssimato all’intero più vicino). Se \\(x_{(1)},\\dots,x_{(n)}\\) è il campione ordinato, la media troncata è quindi definita come\n\\[\n\\hat{\\mu}_\\text{tr} = \\frac{1}{n - 2 k } \\sum_{i=k+1}^{n-k} x_{(i)}.\n\\] In R si può usare il comando mean(x, trim = alpha)."
  },
  {
    "objectID": "exe/es_4.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "href": "exe/es_4.html#esercizi-tratti-dai-libro-di-testo-albert-rizzo-ar",
    "title": "R per l’analisi statistica multivariata",
    "section": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)",
    "text": "Esercizi tratti dai libro di testo Albert & Rizzo (AR)\n\nEsercizio 13.2, pag 334.\nEsercizio 13.3, pag 334."
  },
  {
    "objectID": "esami/esame_04_02_2022.html",
    "href": "esami/esame_04_02_2022.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Si carichi in memoria il dataset birthwt della libreria MASS. Il dataset si riferisce a \\(n = 189\\) donne in gravidanza. Si consiglia di consultare la documentazione per la descrizione delle variabili coinvolte.\n\n(1pt) Si aggiunga al dataset birthwt la nuova variabile qualitativa age_class, la quale suddivide i valori della variabile age in 3 classi: low (età comprese tra 14 e 22), medium (età comprese tra 23 e 28) e high (età \\(\\ge 29\\)).\n(1pt) Si ottengano le frequenze assolute della variabile age_class.\n(2pt) La variabile bwt è espressa in grammi. La si converta in chilogrammi, sovrascrivendo quella presente nel dataset birthwt. Se ne faccia quindi un istogramma, considerando un numero di classi appropriato.\n(1pt) Si confrontino i tre boxplot della variabile bwt (espressa in chilogrammi) condizionatamente a ciascuna modalità della variabile age_class.\n(1pt) Si crei un nuovo dataset, chiamato birthwt_no_smoke contenente esclusivamente i valori delle donne non-fumatrici e si esegua la stessa analisi condotta al punto precedente. Suggerimento: si consulti la documentazione del dataset.\n(4pt) Si consideri nuovamente il dataset birthwt. Si costruisca una matrice \\(\\textbf{X}\\) di dimensione \\(n \\times 3\\) le cui colonne sono i vettori \\(x_1, x_2, x_3\\), ciascuno di dimensione \\(n \\times 1\\). Più precisamente, il primo vettore colonna è pari a \\(x_1 = (1,\\dots,1)^T\\), mentre i vettori colonna \\(x_2\\) ed \\(x_3\\) contengono i valori delle variabili age e ftv. Inoltre, il vettore colonna \\(y\\) contiene i valori della variabile bwt. Si ottenga il vettore \\(\\beta\\) di dimensione \\(3 \\times 1\\), definito come segue: \\[\n\\hat{\\beta} = (\\textbf{X}^T\\textbf{X})^{-1} \\textbf{X}^T y,\n\\] la cui utilità ed interpretazione risulterà chiara in corsi successivi."
  },
  {
    "objectID": "esami/esame_04_02_2022.html#problema-2",
    "href": "esami/esame_04_02_2022.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nSiano \\(p_1(x)\\) e \\(p_2(x)\\) due funzioni di probabilità relative a due variabili aleatorie discrete \\(X_1,X_2\\) aventi lo stesso supporto \\(\\mathcal{S} = \\{x_1,\\dots, x_k\\}\\). La divergenza di Kullback-Leibler di \\(X_1\\) da \\(X_2\\) è definita come segue\n\\[\n\\text{KL}(p_1 \\mid \\mid p_2) = \\sum_{j=1}^k p_1(x_j) \\log\\left\\{\\frac{p_1(x_j) }{p_2(x_j) }\\right\\}.\n\\]\n\n(3pt) Si supponga che \\(X_1, X_2\\) siano due distribuzioni binomiali di parametro \\(n = 20\\) e differenti probabilità di successo \\(\\theta_1 = 0.5\\) e \\(\\theta_2 = 0.2\\). Si calcoli la divergenza di Kullback-Leibler di \\(X_1\\) da \\(X_2\\).\n(3pt) Si noti che: \\[\n\\text{KL}(p_1 \\mid \\mid p_2) = E\\left[\\log\\left\\{\\frac{p_1(X_1) }{p_2(X_1) }\\right\\}\\right].\n\\] Si sfrutti questo risultato per ottenere una stima Monte Carlo della divergenza di KL del punto precedente. Si quantifichi inoltre l’errore commesso.\n(4pt) Siano \\(X_1, X_2\\) due distribuzioni Poisson di media \\(\\lambda_1\\) e \\(\\lambda_2\\). In questo caso la dimensione del supporto è \\(k = \\infty\\) e pertanto la definizione di divergenza di KL di \\(X_1\\) da \\(X_2\\) coinvolge una somma infinita. Si proponga una strategia appropriata per ottenere la divergenza KL e la si calcoli per \\(\\lambda_1 = 1\\) e \\(\\lambda_2 = 4\\)."
  },
  {
    "objectID": "esami/esame_04_02_2022.html#problema-3",
    "href": "esami/esame_04_02_2022.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSiano \\(y = (y_1,\\dots,y_n)\\) delle realizzazioni iid di una variabile aleatoria discreta con legge bernoulli di parametro \\(\\theta \\in (0,1)\\). La funzione di log-verosimiglianza, a meno di una costante additiva, è pari a\n\\[\n\\ell(\\theta) = \\ell(\\theta; y) = \\sum_{i=1}^ny_i\\log\\theta + \\sum_{i=1}^n(1 - y_i)\\log(1-\\theta).\n\\]\n\n(2pt) Si implementi la funzione loglik(theta, y) che calcola la funzione di log-verosimiglianza.\n(2pt) Si considerino le osservazioni 0, 0, 1, 0, 0, 0, 0, 1. Si disegni la funzione di log-verosimiglianza corrispondente nell’intervallo \\((0, 1)\\).\n(2pt) Utilizzando opportuni strumenti di approssimazione numerica si calcoli la stima di massima verosimiglianza \\(\\hat{\\theta}\\).\n(2pt) L’approssimazione parabolica della funzione di log-verosimiglianza, nel suo punto di massimo, è la seguente \\[\n\\ell(\\theta) \\approx \\ell(\\hat{\\theta}) - \\frac{n}{2 \\hat{\\theta}(1 - \\hat{\\theta})}(\\theta - \\hat{\\theta})^2.\n\\] Si implementi la funzione loglik_approx(theta, y) che calcola tale approssimazione, sapendo che \\(\\hat{\\theta} = \\bar{y}\\). Si confrontino graficamente la log-verosimiglianza e la sua approssimazione in \\((1/10, 1/2)\\), utilizzando i dati forniti in precedenza.\n(2pt) Si considerino le osservazioni 0, 0, 0, 0, 0, 0, 0, 0. Si disegni la funzione di log-verosimiglianza nell’intervallo \\((0, 1)\\) e si calcoli la stima di massima verosimiglianza \\(\\hat{\\theta}\\). Si provi quindi a disegnare l’approssimazione quadratica della verosimiglianza. Si commentino i risultati e/o eventuali errori."
  },
  {
    "objectID": "esami/sim_esame2020.html",
    "href": "esami/sim_esame2020.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Sia \\(X\\) una variabile casuale uniforme discreta avente supporto sugli interi da \\(1\\) a \\(365\\). Si assuma che il supporto di \\(X\\) sia associato ad ognuno dei giorni dell’anno (non bisestile); in particolare, \\(1\\) indica il primo Gennaio, mentre \\(365\\) il 31 Dicembre.\n\n\nA partire da queste informazioni si imposti uno studio di simulazione basato su \\(30000\\) repliche per stimare la probabilità che in un gruppo di \\(39\\) persone tutte siano nate in giorni diversi.\nSi stimi la probabilità dell’evento al punto precedente sotto l’ipotesi che nei primi \\(35\\) giorni dell’anno la probabilità di nascere sia doppia rispetto agli altri giorni dell’anno; si utilizzi lo stesso numero di repliche del punto precedente."
  },
  {
    "objectID": "esami/sim_esame2020.html#problema-2",
    "href": "esami/sim_esame2020.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nÈ noto che per generare numeri pseudo-casuali da una variabile casuale continua \\(Z\\) è sufficiente avere a disposizione un generatore di numeri pseudo-casuali da una variabile uniforme continua nell’intervallo \\([0,1]\\).\nInfatti, si ha \\(z_\\text{pc} = F^{-1}_Z(u_\\text{pc})\\) in cui \\(z_\\text{pc}\\) è un numero pseudo-casuale da \\(Z\\), \\(u_\\text{pc}\\) è un numero pseudo-casuale da una variabile casuale uniforme in \\([0,1]\\) e \\(F^{−1}_Z(\\cdot)\\) è l’inversa della funzione di ripartizione di \\(Z\\), ovvero la funzione quantile.\nSi supponga che \\(Z\\) sia una variabile casuale continua con funzione di ripartizione \\[\nF(z) = \\frac{e^z}{1 + e^z}.\n\\] Si generino, secondo la definizione \\(F^{-1}_Z(u_\\text{pc})\\), \\(10000\\) numeri pseudo-casuali da \\(Z\\). Quindi, utilizzando i numeri pseudo-casuali generati al punto precedente, si approssimino:\n\nIl valore atteso \\(\\mathbb{E}(Z)\\)\nLa varianza \\(\\text{var}(Z)\\)\nLa probabilità che \\(Z\\) sia compresa tra \\(1\\) e \\(2\\)."
  },
  {
    "objectID": "esami/sim_esame2020.html#problema-3",
    "href": "esami/sim_esame2020.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nNel file auto.txt disponibile al link https://tommasorigon.github.io/introR/data/auto.txt si riportano dati relativi ad alcuni modelli di autobili presenti in commercio negli Stati Uniti tra il 1973 e il 1974. Le variabili presenti nell’insieme di dati fornito sono\n\nmpg: consumo (miglia / galloni)\ncyl: numero di cilindri\ndisp: cilindrata (pollici cubici)\nhp: cavalli\ndrat: rapporto ase posteriore/anteriore\nwt: peso (in libbre)\nqsec: tempo a percorrere 1/4 di miglio con partenza da fermo\nvs: disposizione dei cilindri (0 = a V, 1 = in linea)\nam: cambio (0 = automatico, 1 = manuale)\ngear: numero di marce\ncarb: numero di carburatori\n\n\nUna volta caricati i dati in R:\n\nIndicare la classe dell’oggetto importato.\nIndicare il numero di righe e colonne dell’oggetto importato.\nIndicare la classe della variabile vs: se diversa da factor, convertirla e rinominare opportunamente i livelli come V e Linea.\nCalcolare le frequenze relative di cyl condizionate a gear=3.\nDire se è corretto affermare che “il \\(60\\)-simo percentile della distribuzione dei cavalli delle auto con disposizione dei cilindri a V è maggiore rispetto al numero medio di cavalli delle auto con disposizione dei cilindri in linea”."
  },
  {
    "objectID": "esami/esame_08_02_2021.html",
    "href": "esami/esame_08_02_2021.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "La funzione \\(f(x)\\) è definita come segue\n\\[\nf(x) = \\frac{e^x - 1}{1 + e^x}.\n\\]\n\nSi scriva in R la funzione f(x) associata ad \\(f(x)\\).\nSi calcoli il valore di \\(f(x)\\) nel punto \\(x = 4\\).\nSi approssimi il valore di \\(f(4)\\) alla seconda cifra decimale utilizzando il comando R appropriato.\nSi faccia il grafico di \\(f(x)\\) nell’intervallo \\((-2, 4)\\).\nSi calcolino i valori delle seguenti sommatorie: \\[\\sum_{k=5}^{10} \\frac{e^k - 1}{1 + e^k},\\] \\[\\sum_{k=5}^{100} \\frac{e^k - 1}{1 + e^k}.\\]\nUtilizzando la funzione integrate di R, si calcoli numericamente il valore dell’integrale\n\n\\[\n\\int_1^4\\frac{e^x - 1}{1 + e^x} \\mathrm{d}x.\n\\]"
  },
  {
    "objectID": "esami/esame_08_02_2021.html#problema-2",
    "href": "esami/esame_08_02_2021.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nSi consideri il dataset di R Pima.te presente nella libreria MASS. Se ne consulti la documentazione per ulteriori informazioni.\n\nQuante osservazioni sono contenute nel dataset Pima.te? Quante variabili sono presenti?\nSi calcoli la media aritmetica della pressione sanguigna (variabile bp).\nLa variabile bmi rappresenta il “body mass index”. Si crei la variabile bmi_log, contenente il logaritmo della variabile bmi. Si ottenga un istogramma di bmi_log, scegliendo opportunamente il numero di intervalli.\nSi scriva la funzione R asym(x) che calcola il coefficiente di asimmetria secondo Pearson, definito come \\[\n\\gamma = \\frac{1}{\\text{sqm}(x)^3} \\frac{1}{n}\\sum_{i=1}^n(x_i - \\bar{x})^3,\\] per dei dati \\(x_1,\\dots,x_n\\) aventi media \\(\\bar{x}\\). Per calcolare lo scarto quadratico medio \\(\\text{sqm(x)}\\) si faccia uso della funzione sd.\nSi calcoli il coefficiente di asimmetria secondo Pearson per le variabili bmi e bmi_log. Quale delle due variabili risulta maggiormente asimmetrica?\nÈ ragionevole supporre i dati della variabile bmi provengano una distribuzione gaussiana? E i dati di bmi_log? Si risponda tramite strumenti grafici.\nSi creino le variabili bmi_yes e bmi_no, contenenti rispettivamente i valori della variabile bmi per le donne aventi il diabete (type = Yes) e per le donne non aventi il diabete (type = No).\nSi confrontino le funzioni di ripartizioni empiriche delle variabili bmi_yes e bmi_no. Inoltre, si calcolino media e mediana delle variabili bmi_yes e bmi_no."
  },
  {
    "objectID": "esami/esame_08_02_2021.html#problema-3",
    "href": "esami/esame_08_02_2021.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSe \\(x_1,\\dots,x_n\\) sono un campione casuale semplice (iid) con numerosità \\(n\\) tratto da una distribuzione \\(\\text{Ga}(\\alpha,\\lambda)\\), allora la funzione di log-verosimiglianza è pari a\n\\[\n\\ell(x;\\alpha, \\lambda) = \\sum_{i=1}^n\\log{f(x_i; \\alpha, \\lambda)}, \\qquad  f(x; \\alpha, \\lambda) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\lambda x}.\n\\] Se \\(\\alpha\\) è noto, allora la stima di massima verosimiglianza per \\(\\lambda\\) è pari a \\[\\hat{\\lambda} = \\frac{n \\alpha}{\\sum_{i=1}^n x_i}.\\] Si supponga di aver osservato le seguenti \\(6\\) osservazioni da una distribuzione gamma di parametri \\(\\alpha = 2\\) e \\(\\lambda > 0\\). Il parametro \\(\\lambda\\) è ignoto e siamo interessati ad una sua stima.\n\n# Vettore delle osservazioni\nx <- c(2.1499496, 5.0539201, 3.1207749, 1.4512639, 3.8040806, 1.6647759)\n\n\nSi ottenga la stima di massima verosimiglianza per \\(\\lambda\\) con i dati a disposizione e supponendo \\(\\alpha = 2\\).\nSi scriva una funzione R loglik(x, alpha, lambda) che calcola la funzione di log-verosimiglianza.\nSi ottenga il valore della log-verosimiglianza \\(\\ell(x; 2, 1)\\). Si verifichi che tale valore è minore di \\(\\ell(x; 2, \\hat{\\lambda})\\) e se ne spieghi il motivo.\nSi “verifichi” tramite simulazione la consistenza dello stimatore di massima verosimiglianza per \\(\\lambda\\), quando \\(\\alpha\\) è noto. Per fare ciò, si ottengano le stime di massima verosimiglianza di \\(4\\) campioni simulati aventi numerosità \\(n = 100, 500, 1000, 10000\\), campionando da una distribuzione gamma di parametri \\((\\alpha, \\lambda) = (2, 1)\\)."
  },
  {
    "objectID": "esami/esame_19_11_2021.html",
    "href": "esami/esame_19_11_2021.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Si carichi in memoria il dataset Boston tramite il comando data(Boston) dopo aver caricato in memoria la libreria MASS.\n\n(1pt) Si crei un vettore numerico x contenente i valori della variabile crim del dataset Boston. Si calcolino media e mediana di tale variabile.\n(1pt) Si creino i vettori x_river e x_no_river contenenti i valori della variabile crim, rispettivamente per le osservazioni vicine al fiume (chas = 1) e lontane dal fiume (chas = 0).\n(4pt) Siano \\(x_1,\\dots,x_n\\) delle osservazioni numeriche. La differenza semplice media è un indicatore di variabilità definito come segue \\[\n\\Delta = \\frac{1}{n(n-1)} \\sum_{i=1}^n\\sum_{j=1}^n |x_i - x_j|.\n\\] Si definisca in R la funzione delta(x) che calcola l’indicatore \\(\\Delta\\) per un generico vettore numerico x. Si calcoli quindi tale indicatore per le variabili x_river e x_no_river.\n(4pt) Sia \\(x_{(1)}, \\dots, x_{(n)}\\) il campione ordinato dei dati \\(x_1,\\dots,x_n\\) e sia \\(\\bar{x}\\) la media aritmetica. La differenza semplice media ammette una rappresentazione alternativa, pari a: \\[\n\\Delta = \\frac{4}{n(n-1)}\\left( \\sum_{i=1}^n i x_{(i)}\\right) - 2\\bar{x} \\frac{n+1}{n-1}.\n\\] Si definisca in R la funzione delta2(x) che calcola l’indicatore \\(\\Delta\\) tramite questa formula alternativa. Si calcoli quindi tale indicatore per le variabili x_river e x_no_river e si verifichi che il risultato coincide con quello trovato al punto precedente."
  },
  {
    "objectID": "esami/esame_19_11_2021.html#problema-2",
    "href": "esami/esame_19_11_2021.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nUno studente del corso di laurea SSE dell’Università Milano-Bicocca sostiene di aver inventato una nuova variabile aleatoria. Pur non conoscendone la densità, definisce la variabile aleatoria \\(X\\) come segue:\n\\[\nX = \\sqrt{ - 2 \\log{U_1}} \\sin{(2\\pi U_2)},\n\\] dove \\(U_1\\) ed \\(U_2\\) sono due variabile aleatorie uniformi in \\((0,1)\\) ed indipendenti tra loro.\n\n(2pt) Si scriva in R la funzione r_log_sin(R) che simula R valori pseudo-casuali distribuiti come la variabile \\(X\\).\n(2pt) Si fornisca un’approssimazione delle quantità \\(E(X)\\) e \\(E(X^2)\\).\n(2pt) Si quantifichi l’errore commesso al punto precedente.\n(2pt) Si approssimino le probabilità \\(P(X \\le x)\\), per \\(x = -1, 0, 1\\).\n(2pt) Si ottenga una stima della densità di \\(X\\). Sulla base di quest’ultima stima e di tutti gli indicatori precedenti, a cosa “assomiglia” la distribuzione di \\(X\\)?"
  },
  {
    "objectID": "esami/esame_19_11_2021.html#problema-3",
    "href": "esami/esame_19_11_2021.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSiano \\(y = (y_1,\\dots,y_n)\\) delle realizzazioni iid di una variabile aleatoria continua con legge Laplace, la cui densità è\n\\[\nf(y ; \\theta) = \\frac{1}{2}e^{-|y - \\theta|}.\n\\]\nDi conseguenza, la funzione di log-verosimiglianza, a meno di una costante additiva, è pari a\n\\[\n\\ell(\\theta) = \\ell(\\theta; y) = - \\sum_{i=1}^n |y_i - \\theta|.\n\\]\n\n(3pt) Si scriva la funzione loglik(theta, y) che calcola la funzione di log-verosimiglianza. Ci si assicuri che la funzione sia opportunamente ``vettorizzata” rispetto a \\(\\theta\\).\n(3pt) Si considerino le osservazioni 10, 3, 12, 20, 32, 8. Si disegni la funzione di log-verosimiglianza corrispondente nell’intervallo \\((0, 30)\\).\n(3pt) Utilizzando opportuni strumenti di approssimazione numerica si calcoli la stima di massima verosimiglianza \\(\\hat{\\theta}\\).\n(2pt) Si calcoli il valore della log-verosimiglianza nel punto di massimo e la si confronti con il valore \\(\\ell(10 + \\pi/4)\\). Si commentino i risultati."
  },
  {
    "objectID": "esami/esame_22_07_2021.html",
    "href": "esami/esame_22_07_2021.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Si supponga che \\(X\\) sia una variabile casuale che si distribuisce come un’esponenziale di media \\(1/2\\). Inoltre, sia \\(Y\\) una variabile casuale tale che \\(Y\\) condizionata a \\(X = x\\) si distribuisce come una Poisson di media \\(\\exp(x / 4).\\)\n\n(5pt) Calcolare via simulazione il valore atteso \\(E(Y^2)\\).\n\nGrazie alle proprietà della distribuzione di Poisson, si ottiene che\n\\[\nE(Y^2 \\mid X = x) = e^{x/4} + e^{x / 2}.\n\\]\n\n(5pt) Si sfrutti questo risultato per ottenere una stima alternativa (ma equivalente) del valore atteso \\(E(Y^2)\\)."
  },
  {
    "objectID": "esami/esame_22_07_2021.html#problema-2",
    "href": "esami/esame_22_07_2021.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nSia \\(X\\) una variabile casuale distribuita in modo uniforme nell’intervallo \\((\\theta / 2, \\theta)\\), con \\(\\theta > 0\\). Sia \\(X_1,\\dots,X_n\\) un campione casuale da \\(X\\) e siano dati i due stimatori\n\\[\nT_1 = \\frac{4}{3}\\bar{X}, \\qquad T_2 = \\frac{2}{3}(X_{(1)} + X_{(n)}),\n\\] dove \\(X_{(1)}\\) e \\(X_{(n)}\\) rappresentano il minimo ed il massimo di \\(X_1,\\dots,X_n\\), rispettivamente. Supponendo \\(\\theta = 1\\) e \\(n = 20\\), si ottenga una stima Montecarlo delle seguenti quantità:\n\n(2pt) La distorsione degli stimatori \\(T_1\\) e \\(T_2\\), ovvero \\(E(T_1 - \\theta)\\) e \\(E(T_2 - \\theta)\\).\n(2pt) L’errore quadratico medio di \\(T_1\\) e \\(T_2\\), ovvero \\(E\\{(T_1 - \\theta)^2\\}\\) e \\(E\\{(T_2 - \\theta)^2\\}\\). Quale dei due stimatori risulta più efficiente?\n\nInoltre, supponendo \\(\\theta = 1\\)\n\n(6pt) Si conduca uno studio di simulazione e si verifichi empiricamente che lo stimatore \\(T_1\\) è consistente al crescere di \\(n\\)."
  },
  {
    "objectID": "esami/esame_22_07_2021.html#problema-3",
    "href": "esami/esame_22_07_2021.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSi considerino i dati sono disponibili al link https://tommasorigon.github.io/introR/data/province.csv\n\n(1pt) Si carichino i dati in memoria. Quante osservazioni sono presenti? Quante variabili?\n(1pt) Si ottenga la matrice di correlazione.\n(8pt) Si calcoli la correlazione parziale tra le variabili agricoltura e feritilità al netto della variabile istruzione, che si ottiene come segue. Si costruisca un modello di regressione lineare usando “agricoltura” come variabile risposta (\\(y\\)) e “istruzione” (\\(x\\)) come variabile esplicativa. Analogamente, si costruisca un modello di regressione usando “fertilità” come variabile risposta e “istruzione” come variabile esplicativa. Si ricordi che le stime ai minimi quadrati sono pari a \\[\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}, \\qquad \\hat{\\beta} = \\frac{\\text{cov}(x,y)}{\\text{var}(x)}.\n\\] Il coefficiente di correlazione parziale si ottiene quindi calcolando coefficiente di correlazione tra i residui di entrambi i modelli"
  },
  {
    "objectID": "esami/esiti.html",
    "href": "esami/esiti.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Nota. Dalla seguente tabella sono stati omessi gli studenti Assenti e Ritirati.\n\n\n\n\n\nMatricola\nEsito\n\n\n\n\n795145\nINS\n\n\n826036\nINS\n\n\n832344\n27\n\n\n832450\n18\n\n\n837297\n24\n\n\n837363\n20\n\n\n850960\nINS\n\n\n851007\nINS\n\n\n851534\nINS\n\n\n852054\nINS\n\n\n852225\nINS\n\n\n856942\nINS\n\n\n857880\n26\n\n\n861300\nINS\n\n\n861837\n19\n\n\n864426\n18\n\n\n864920\nINS\n\n\n864973\nINS\n\n\n865257\nINS\n\n\n865309\n25\n\n\n865336\n27\n\n\n865374\n21\n\n\n870789\n26\n\n\n871277\nINS\n\n\n871794\n18\n\n\n873133\nINS\n\n\n873335\nINS\n\n\n874624\n18\n\n\n874883\nINS\n\n\n875967\n22\n\n\n876170\n30"
  },
  {
    "objectID": "esami/esame_30_06_2021.html",
    "href": "esami/esame_30_06_2021.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "La cosiddetta \\(\\mathcal{D}\\) di Cohen è una statistica descrittiva molto utilizzata in Psicologia. Siano \\(x_1,\\dots,x_{n_x}\\) e \\(y_1,\\dots,y_{n_y}\\) due insieme di dati con numerosità campionarie \\(n_x\\) ed \\(n_y\\), rispettivamente. Siamo interessati a stabilire se questi due insiemi differiscono in media in maniera sostanziale. A tal fine, definiamo la \\(\\mathcal{D}\\) di Cohen come segue:\n\\[\n\\mathcal{D} = \\frac{|\\bar{x} - \\bar{y}|}{s}, \\qquad \\text{dove} \\qquad \\bar{x} = \\frac{1}{n_x}\\sum_{i=1}^{n_x}x_i, \\qquad \\bar{y} = \\frac{1}{n_y}\\sum_{i=1}^{n_y}y_i,\n\\]\nin cui \\(s > 0\\) è una misura della variabilità dei dati. Assumendo che la variabilità sia uguale tra le due popolazioni di dati, è ragionevole porre ad esempio\n\\[\ns^2 = \\frac{1}{n_x + n_y - 2}\\left\\{\\sum_{i=1}^{n_x}(x_i - \\bar{x})^2 + \\sum_{i=1}^{n_y}(y_i - \\bar{y})^2  \\right\\}.\n\\]\nL’ammontare della differenza tra le medie è spesso detta “debole” se \\(\\mathcal{D} \\approx 0.2\\), “media” se \\(\\mathcal{D} \\approx 0.5\\) e “forte” se \\(\\mathcal{D} \\approx 0.8\\). Si considerino inoltre i seguenti insiemi di dati\n\nx <- c(7.19, 8.27, 6.77, 6.65, 8.56, 6.56, 6.09)\ny <- c(6.37, 6.27, 7.95, 6.52, 7.72, 6.92, 6.34, 7.51, 6.07, 8.09, 6.03)\n\n\n(3pt) Si scriva in R la funzione cohenD(x, y) che calcola l’indicatore \\(\\mathcal{D}\\) di Cohen.\n(1pt) Utilizzando i dati forniti, si calcoli la \\(\\mathcal{D}\\) di Cohen associata.\n(1pt) Si generino due insiemi dati \\(x_1,\\dots,x_{n_x}\\) e \\(y_1,\\dots,y_{n_y}\\) campionando dei valori indipendenti da una distribuzione normale con media e varianza \\(N(0, 100)\\) e con \\(n_x = 500\\) e \\(n_y = 2000\\). Si calcoli quindi la \\(\\mathcal{D}\\) di Cohen associata. Il valore trovato suggerisce una differenza tra le medie “debole”?\n(1pt) Si generino due insiemi dati \\(x_1,\\dots,x_{n_x}\\) e \\(y_1,\\dots,y_{n_y}\\) campionandi dei valori indipendenti dalle distribuzioni normali \\(N(0, 100)\\) e \\(N(10, 100)\\), rispettivamente per le variabili \\(x\\) ed \\(y\\), supponendo anche in questo caso che \\(n_x = 500\\) e \\(n_y = 2000\\). Si calcoli quindi la \\(\\mathcal{D}\\) di Cohen. Il valore trovato suggerisce una differenza tra le medie “debole”?\n(4pt) Si effetti uno studio di simulazione nel quale i dati \\(x\\) ed \\(y\\) vengono generati varie volte come fatto nel punto precedente. Per ciascuna coppia di insiemi di dati \\(x\\) ed \\(y\\), si calcoli la \\(\\mathcal{D}\\) di Cohen associata. Si ripeta questa operazione R = 1000 volte, ottenendo quindi un vettore di dimensione 1000 che comprende i vari indici \\(\\mathcal{D}\\) di Cohen. Si disegni un istogramma di tali valori."
  },
  {
    "objectID": "esami/esame_30_06_2021.html#problema-2",
    "href": "esami/esame_30_06_2021.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nSi ponga \\(X_1 = 1\\). Si consideri una collezione di variabile casuali binarie ed indipendenti \\(X_1,\\dots,X_n\\), tali per per cui\n\\[\n\\text{P}(X_i = 1) = \\frac{\\alpha}{\\alpha + i - 1}, \\qquad i = 2,\\dots,n,\n\\]\ndove \\(\\alpha > 0\\) è un parametro positivo. Inoltre, si definisca\n\\[\nS = \\sum_{i=1}^n X_i.\n\\] Nota. La variabile \\(S\\) non si distribuisce come una binomiale, essendo somma di variabili Bernoulli con probabilità differenti.\n\n(4pt) Si scriva in R la funzione rS(R, n, alpha) che simula un R valori pseudo-casuali distribuiti come la variable \\(S\\).\n(2pt) Utilizzando \\(n = 100\\) e \\(\\alpha = 1\\), si ottenga una stima Monte Carlo del valore atteso \\(\\text{E}(S)\\), utilizzando un numero di repliche R appropriato.\n(2pt) Utilizzando \\(n = 500\\) e \\(\\alpha = \\pi / 4\\), si ottenga una stima Monte Carlo dell’evento \\(\\text{P}(3 \\le S \\le 5)\\), utilizzando un numero di repliche R appropriato.\n(2pt) 1. Utilizzando \\(n = 500\\) e \\(\\alpha = \\sqrt{2}\\), si ottenga una stima Monte Carlo della distribuzione di \\(S\\) e se ne faccia un grafico, utilizzando un numero di repliche R appropriato."
  },
  {
    "objectID": "esami/esame_30_06_2021.html#problema-3",
    "href": "esami/esame_30_06_2021.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSi consideri il dataset Animals della libreria MASS e lo si carichi in memoria.\n\n(1pt) Si ottengano le variabili lbody e lbrain, corrispondenti al logaritmo naturale delle variabili body e brain del dataset Animals, rispettivamente.\n(1pt) Si ottengano le medie campionarie e le mediane per le variabili lbody e lbrain. Si ottengano quindi il primo ed il terzo quartile. Sono presenti outlier nelle due distribuzioni?\n(2pt) Si ottengano gli istogrammi di tali variabili, scegliendo opportunamente il numero di intervalli.\n(1pt) Si ottenga un grafico che metta in relazione le variabili lbody e lbrain.\n(1pt) Si calcoli la correlazione tra le variabili lbody e lbrain.\n(4pt) In un modello di regressione lineare semplice \\(y = \\alpha + \\beta x\\), dove lbody rappresenta la variabile esplicativa (\\(x\\)) e lbrain rappresenta la variabile risposta (\\(y\\)), si ottengano le stime ai minimi quadrati, le quali sono pari a \\[\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}, \\qquad \\hat{\\beta} = \\frac{\\text{cov}(x,y)}{\\text{var}(x)}.\n\\]"
  },
  {
    "objectID": "esami/esame_20_11_2020.html",
    "href": "esami/esame_20_11_2020.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Dopo aver caricato in memoria la libreria MASS, si acceda al dataset forbes contenuto in tale libreria.\n\nSi acceda alla documentazione del dataset forbes e si descriva il contenuto del dataset: cosa rappresentano le variabili contenute in tale insieme di dati?\nSi ottengano le medie campionarie e le mediane per le variabili bp e pres. Si ottengano quindi il primo ed il terzo quartile. Sono presenti outlier nelle due distribuzioni?\nSi ottengano gli istogrammi di tali variabili, scegliendo opportunamente il numero di intervalli.\nSi ottenga un grafico che metta in relazione le variabili bp e pres.\nSi calcoli la correlazione tra le variabili bp e pres.\nIn un modello di regressione lineare semplice \\(y = \\alpha + \\beta x\\), dove bp rappresenta la variabile esplicativa (\\(x\\)) e pres rappresenta la variabile risposta (\\(y\\)), le stime ai minimi quadrati sono pari a \\[\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}, \\qquad \\hat{\\beta} = \\frac{\\text{cov}(x,y)}{\\text{var}(x)}.\n\\]\nSi rappresenti la retta di regressione ottenuta congiuntamenti ai dati. Il modello sembra adattarsi bene ai dati?"
  },
  {
    "objectID": "esami/esame_20_11_2020.html#problema-2",
    "href": "esami/esame_20_11_2020.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nUna variabile aleatoria \\(X \\sim \\text{Burr}(\\alpha,\\beta)\\) segue una distribuzione di Burr di parametri \\(\\alpha, \\beta > 0\\). Si tratta di una variabile casuale assolutamente continua e a valori positivi avente la seguente densità:\n\\[\nf(x ; \\alpha, \\beta) = \\alpha \\beta \\frac{x^{\\alpha-1}}{(1 + x^\\alpha)^{\\beta+1}}, \\qquad x > 0.\n\\]\nÈ facile verificare che la funzione di ripartizione coincide con\n\\[\nF(x; \\alpha, \\beta) = 1 - \\frac{1}{(1 + x^\\alpha)^\\beta}, \\qquad x > 0.\n\\]\n\nSi ottenga analiticamente (ovvero utilizzando carta e penna) la funzione quantile \\(F^{-1}(p; \\alpha,\\beta)\\) della distribuzione di Burr, ovvero la funzione inversa di \\(F(x;\\alpha,\\beta) = p\\). Quindi, si scrivano in R le funzioni per il calcolo della densità, della funzione di ripartizione e la funzione quantile. Si chiamino queste funzioni dburr(x, alpha, beta), pburr(x, alpha, beta) e qburr(p, alpha, beta), rispettivamente.\nSi faccia un grafico della funzione di densità \\(f(x ; \\alpha, \\beta)\\) con \\(\\alpha = 2\\) e \\(\\beta = 1\\), in un intervallo opportuno.\nPer generare valori (pseudo) casuali dalla distribuzione di Burr è possibile utilizzare il metodo dell’inversione. Un singolo valore da una distribuzione di Burr si ottiene tramite il comando qburr(runif(1), alpha, beta). Si definisca quindi la funzione rburr(R, alpha, beta) che genera R valori pseudo casuali da una distribuzione di Burr.\nUtilizzando i numeri pseudo-casuali generati tramite la funzione rburr con \\(\\alpha = 2\\) e \\(\\beta = 1\\) si approssimino:\n\nIl valore atteso \\(E(X)\\).\nLa varianza \\(\\text{var}(X)\\).\nLa probabilità che \\(X\\) sia compresa tra \\(2\\) e \\(3\\).\n\nSi faccia un istogramma dei valori simulati al punto precedente e lo si confronti con la densità \\(f(x;\\alpha,\\beta)\\) per \\(\\alpha = 2\\) e \\(\\beta = 1\\).\nSi ottenga la funzione di ripartizione empirica dei valori simulati in precedenza e la si confronti con la funzione di ripartizione teorica \\(F(x;\\alpha,\\beta)\\) per \\(\\alpha = 2\\) e \\(\\beta = 1\\)."
  },
  {
    "objectID": "esami/esame_22_02_2022.html",
    "href": "esami/esame_22_02_2022.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Si carichi in memoria il dataset swiss presente in R. Il dataset si riferisce a \\(n = 47\\) province della svizzera Francese.\n\n(1pt) Si aggiunga al dataset una nuova variabile, chiamata logEducation, la quale contiene il logaritmo della variabile Education.\n(1pt) Si produca un grafico opportuno che metta in relazione la variabile logEducation e Agriculture.\n(2pt) Si ottengano le matrici di covarianza e di correlazione relative alle variabili Fertility, Agriculture e logEducation.\n(2pt) Si calcolino degli opportuni indici di posizione e variabilità per la variabile Agriculture.\n(6pt) Si calcoli la correlazione parziale tra le variabili Agriculture e Fertility al netto della variabile logEducation, che si ottiene come segue. Si costruisca un modello di regressione lineare usando Agriculture come variabile risposta (\\(y\\)) e logEducation (\\(x\\)) come variabile esplicativa. Analogamente, si costruisca un modello di regressione usando Fertility come variabile risposta e logEducation come variabile esplicativa. Si ricordi che le stime ai minimi quadrati sono pari a \\[\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}, \\qquad \\hat{\\beta} = \\frac{\\text{cov}(x,y)}{\\text{var}(x)}.\n\\] Il coefficiente di correlazione parziale si ottiene quindi calcolando il coefficiente di correlazione tra i residui di entrambi i modelli."
  },
  {
    "objectID": "esami/esame_22_02_2022.html#problema-2",
    "href": "esami/esame_22_02_2022.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nUna variabile aleatoria continua \\(X\\) segue una distribuzione di Kumaraswamy di parametri \\(\\alpha, \\beta\\) se la sua densità è pari a:\n\\[\nf(x) = \\alpha \\beta x^{\\alpha - 1}(1 - x^\\alpha)^{\\beta - 1}, \\qquad 0 < x < 1.\n\\]\nÈ inoltre possibile dimostrare che la funzione di ripartizione è pari a\n\\[\nF(x) = 1 - (1 - x^\\alpha)^\\beta, \\qquad 0 < x < 1.\n\\] Infine, la funzione quantile è pari a\n\\[\n\\mathcal{Q}(p) = (1 - (1 - p)^{1/\\beta})^{1/ \\alpha}, \\qquad 0 < p < 1.\n\\]\n\n(4pt) Si implementino le funzioni dkum(x, alpha, beta), pkum(x, alpha, beta) e qkum(x, alpha, beta) le quali fanno riferimento rispettivamente alla densità, alla funzione di ripartizione e alla funzione quantile.\n(2pt). Si faccia un grafico nell’intervallo \\((0, 1)\\) di tutte e tre le funzioni precedenti, per \\(\\alpha = \\beta = 2\\).\n(2pt) Si costruisca una funzione rkum(R, alpha, beta) che campiona R valori pseudo-casuali dalla variabile aleatoria di Kumaraswamy.\n(2pt) Si ottenga una stima Monte Carlo della densità di \\(X\\), quando \\(\\alpha = \\beta = 2\\) e la si confronti con la funzione di densità dkum ottenuta in precedenza.\n(2pt) Si ottenga un’approssimazione Monte Carlo della media \\(E(X)\\), quando \\(\\alpha = \\beta = 2\\). Si quantifichi opportunamente l’errore commesso."
  },
  {
    "objectID": "esami/esame_22_02_2022.html#problema-3",
    "href": "esami/esame_22_02_2022.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSiano \\(y = (y_1,\\dots,y_n)\\) delle realizzazioni iid di una variabile aleatoria discreta con legge Poisson di parametro \\(\\lambda\\). Si considerino i seguenti stimatori per la probabilità \\(\\psi = P(Y = 0)\\), dove \\(Y \\sim \\text{Pois}(\\lambda)\\)\n\\[\nT_1 = e^{-\\bar{y}}, \\qquad T_2 = \\frac{1}{n}\\sum_{i=1}^n I(y_i = 0),\n\\] in cui \\(\\bar{y}\\) e \\(I(\\cdot)\\) rappresentano la media aritmetica e la funzione indicatrice.\n\n(4pt) Supponendo \\(\\lambda = 2\\), si verifichi empiricamente se i due stimatori sono consistenti.\n(2pt) Supponendo \\(\\lambda = 2\\) e per \\(n = 20\\), si effettui uno studio di simulazione e si calcoli la distorsione degli stimatori \\(T_1\\) and \\(T_2\\).\n(2pt) Supponendo \\(\\lambda = 2\\) e per \\(n = 20\\), si stabilisca quale dei due stimatori è preferibile in termini di errore quadratico medio."
  },
  {
    "objectID": "esami/esame_24_02_2021.html",
    "href": "esami/esame_24_02_2021.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "I numeri di Stirling del secondo tipo \\(S(n,k)\\) rappresentano il numero di possibili partizioni di un insieme di \\(n\\) elementi formate da \\(k\\) termini. È possibile dimostrare che\n\\[\nS(n, k) = \\frac{1}{k!}\\sum_{j=0}^k(-1)^{k-j}\\binom{k}{j}j^n,\n\\] per qualsiasi valore di \\(k =1,\\dots,n\\). I numeri di Bell \\(B(n)\\) rappresentano invece il numero di possibili partizioni di un insieme di \\(n\\) elementi, independentemente dal numero di termini, ovvero\n\\[\nB(n) = \\sum_{k=1}^n S(n, k).\n\\]\n\n(6pt) Si scrivano in R le funzioni stirling2(n, k) e Bell(n) che calcolano, rispettivamente, i coefficienti \\(S(n,k)\\) e \\(B(n)\\).\n(1pt) Utilizzando le funzioni del punto precedente, si dica in quanti modi è possibile dividere un insieme di \\(10\\) elementi utilizzando \\(5\\) gruppi.\n(1pt) Utilizzando le funzioni dei punti precedenti, si dica in quanti modi è possibile partizionare un insieme di \\(10\\) elementi."
  },
  {
    "objectID": "esami/esame_24_02_2021.html#problema-2",
    "href": "esami/esame_24_02_2021.html#problema-2",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 2",
    "text": "Problema 2\nIl numero armonico generalizzato è definito come\n\\[\nH(n,\\alpha) = 1 + \\frac{1}{2^\\alpha} + \\cdots + \\frac{1}{n^\\alpha} = \\sum_{k=1}^n\\frac{1}{k^\\alpha}, \\qquad \\alpha > 0.\n\\]\nInoltre, una variabile aleatoria discreta \\(X\\) con supporto \\(\\{1,\\dots, n\\}\\) segue una distribuzione di Zipf se\n\\[\nP(X = k) = \\frac{k^{-\\alpha}}{H(n, \\alpha)}, \\qquad k=1,\\dots,n,\n\\] ed è pari a \\(0\\) altrimenti.\n\n(2pt) Si scriva in R la funzione H(n, alpha) che calcola il numero armonico generalizzato. Quanto vale H(10, 1)?\n(2pt) Si scriva in R la funzione di probabilità dzipf(k, n, alpha) di una legge Zipf di parametri \\(n\\) ed \\(\\alpha\\) e la si calcoli nei valori dzipf(5, 10, 2).\n(2pt) Per \\(n = 50\\) e \\(\\alpha = 1\\), si rappresenti graficamente la legge di probabilità di una distribuzione Zipf tramite un diagramma a bastoncini.\n(2pt) Si supponga che \\(X\\) segua una Zipf di parametri \\(n = 100\\) e \\(\\alpha = 2\\). Si calcoli la probabilità \\(P(X \\ge 10)\\).\n(3pt) Si scriva in R la funzione rzipf(R, n, alpha) che simula R valori casuali da una distribuzione Zipf. Suggerimento: si faccia uso della funzione sample.\n(2pt) Sfruttando la funzione rzipf, si ottenga un’approssimazione del valore atteso \\(E(X)\\), quando \\(n = 50\\) e \\(\\alpha = 1\\)."
  },
  {
    "objectID": "esami/esame_24_02_2021.html#problema-3",
    "href": "esami/esame_24_02_2021.html#problema-3",
    "title": "R per l’analisi statistica multivariata",
    "section": "Problema 3",
    "text": "Problema 3\nSi consideri il dataset bacteria della libreria MASS e lo si carichi in memoria. La variabile y indica la presenza (y) o l’assenza (n) del batterio “H influenzae” in alcuni bambini. La variabile trt indica invece il trattamento ricevuto.\n\n(3pt) L’indice di eterogeneità di Gini è definito come \\(G = 1 - \\sum_{j=1}^kf_j^2\\), dove \\(f_1,\\dots,f_k\\) sono le frequenze relative di una variabile qualitativa con modalità \\(c_1,\\dots,c_k\\). Si costruisca in R la funzione Gini(x) che calcola l’indice di Gini di una variabile qualitativa x. Si ottenga quindi Gini(bacteria$trt).\n(1pt) Si costruisca dataset bacteria2 contenente le osservazioni relative alla sesta settimana di sorveglianza (week = 6). Da quante osservazioni è composto?\n(1pt) Utilizzando il dataset bacteria2, si costruisca una tabella di contingenza che mette in relazione le variabili y e trt.\n(2pt) Utilizzando il dataset bacteria2, si ottengano le distribuzioni di frequenza condizionate della variabile y, per ciascun valore della variabile trt. Ci sono delle differenze tra queste distribuzioni?\n(2pt) Utilizzando il dataset bacteria2, si ri-eseguano i due punti precedenti (ovvero 3. e 4.) dopo aver raggruppato i valori drug e drug+ della variabile trt in un unico valore, chiamato ad esempio drug_and_drug+. I risultati sono diversi da quelli ottenuti al punto precedente (4.)?"
  },
  {
    "objectID": "lezioni/un_J.html",
    "href": "lezioni/un_J.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "In questa unità studieremo tramite simulazione alcuni giochi d’azzardo.\nIn particolare, analizzeremo cosa succede ad un ipotetico giocatore che persiste a scommettere per varie volte alla roulette.\nConsidereremo scenari progressivamente più complessi, ipotizzando da principio un semplice gioco in cui due giocatori si sfidano al lancio della monetina.\nIn seguito, considereremo il caso in cui il gioco sia “truccato” ovvero non equo, come ad esempio la roulette di un casinò.\nInfine, considereremo un’ulteriore elaborazione del caso precedente, includendo nella simulazione il fatto che i giocatori coinvolti hanno un budget limitato."
  },
  {
    "objectID": "lezioni/un_J.html#un-primo-semplice-gioco",
    "href": "lezioni/un_J.html#un-primo-semplice-gioco",
    "title": "R per l’analisi statistica multivariata",
    "section": "Un primo semplice gioco",
    "text": "Un primo semplice gioco\n\n\n\n\n\n\nNote\n\n\n\nDue persone A e B si sfidano al (non così appassionante) gioco del lancio della monetina. Se esce testa, il giocatore A consegna \\(10\\) euro al giocatore B; viceversa se esce croce.\n\n\nAssumiamo quindi che A e B giochino ad esempio 50 volte al lancio della monetina.\nQuanti soldi avrà mediamente vinto / perso il giocatore A al termine dei \\(50\\) lanci?\nQual è la distribuzione del guadagno finale?\nQual è la probabilità di vittoria, ovvero la probabilità che il guadagno sia positivo?"
  },
  {
    "objectID": "lezioni/un_J.html#il-lancio-della-monetina",
    "href": "lezioni/un_J.html#il-lancio-della-monetina",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il lancio della monetina",
    "text": "Il lancio della monetina\nIl comando che simula una singola partita, ovvero \\(50\\) lanci di monetina dal punto di vista del giocatore A, è il seguente:\n\nset.seed(123)\nsample(c(-10, 10), 50, replace = TRUE) # Gioco 50 volte ai dadi contro B\n\n [1] -10 -10 -10  10 -10  10  10  10 -10 -10  10  10  10 -10  10 -10  10 -10 -10\n[20] -10 -10  10 -10 -10 -10 -10  10  10 -10  10 -10  10 -10  10  10 -10 -10 -10\n[39] -10  10 -10  10  10 -10 -10 -10 -10  10 -10 -10\n\n\nNoi siamo tuttavia interessati al guadagno del giocatore A. Ovviamente per ottenere i guadagni di B è sufficiente cambiare il segno dei risultati.\nIl guadagno del giocatore A dopo ciascun lancio di monetina è pari a\n\nset.seed(123)\ncumsum(sample(c(-10, 10), 50, replace = TRUE))\n\n [1]  -10  -20  -30  -20  -30  -20  -10    0  -10  -20  -10    0   10    0   10\n[16]    0   10    0  -10  -20  -30  -20  -30  -40  -50  -60  -50  -40  -50  -40\n[31]  -50  -40  -50  -40  -30  -40  -50  -60  -70  -60  -70  -60  -50  -60  -70\n[46]  -80  -90  -80  -90 -100"
  },
  {
    "objectID": "lezioni/un_J.html#il-lancio-della-monetina-1",
    "href": "lezioni/un_J.html#il-lancio-della-monetina-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il lancio della monetina",
    "text": "Il lancio della monetina\n\npar(mfrow=c(1,2))\nset.seed(250)\n\nplot(1:50, cumsum(sample(c(-10, 10), 50, replace = TRUE)), type = \"b\", xlab = \"# Lancio\", ylab = \"Guadagno\")\nabline(h = 0, lty = \"dotted\")\n\nplot(1:50, cumsum(sample(c(-10, 10), 50, replace = TRUE)), type = \"b\", xlab = \"# Lancio\", ylab = \"Guadagno\")\nabline(h = 0, lty = \"dotted\")"
  },
  {
    "objectID": "lezioni/un_J.html#simulazione-di-unintera-partita",
    "href": "lezioni/un_J.html#simulazione-di-unintera-partita",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simulazione di un’intera partita",
    "text": "Simulazione di un’intera partita\nSiamo interessati ad indagare la variabile aleatoria \\(X\\), che rappresenta il guadagno finale del giocatore A, ovvero la somma algebrica dei guadagni e delle perdite.\nPer esempio, un’estrazione casuale dalla distribuzione di \\(X\\), ovvero il risultato finale di una partita si ottiene come segue:\n\n# Ottengo il guadagno finale (una volta sola)\nset.seed(123)\nsum(sample(c(-10, 10), 50, replace = TRUE))\n\n[1] -100\n\n\nPossiamo quindi usare il comando replicate, che ripete la stessa operazione varie volte. In questo modo otteniamo \\(R\\) copie iid \\(X_1,\\dots,X_R\\).\n\n# Ripeto questa operazione R volte per ottenere dei campioni\nset.seed(123)\nR <- 10^5\n# Otteniamo 10^5 copie iid aventi la stessa distribuzione di X\nfinal_earning <- replicate(R, sum(sample(c(-10, 10), 50, replace = TRUE)))\nfinal_earning[1:5]\n\n[1] -100  -40  120  -40  100"
  },
  {
    "objectID": "lezioni/un_J.html#analisi-dei-risultati",
    "href": "lezioni/un_J.html#analisi-dei-risultati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Analisi dei risultati",
    "text": "Analisi dei risultati\nGrazie ai risultati teorici dell’unità I, possiamo utilizzare i valori simulati \\(X_1,\\dots,X_R\\) per imparare qualcosa sulla distribuzione di \\(X\\).\nIn primo luogo approssimiamo il valore atteso tramite la somma \\[\n\\mathbb{E}(X) \\approx \\frac{1}{R}\\sum_{r=1}^RX_r.\n\\]\n\nmean(final_earning) # Media del guadagno finale\n\n[1] -0.3518\n\n\nNe concludiamo quindi che si tratta di un gioco equo, dato che mediamente né vince né si perde, ovvero \\(\\mathbb{E}(X) \\approx 0\\).\nTuttavia, i risultati differiscono molto da una partita ad un’altra, dato che:\n\nsd(final_earning) # Deviazione standard del guadagno finale\n\n[1] 70.65155"
  },
  {
    "objectID": "lezioni/un_J.html#analisi-dei-risultati-1",
    "href": "lezioni/un_J.html#analisi-dei-risultati-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Analisi dei risultati",
    "text": "Analisi dei risultati\n\npar(mfrow = c(1, 1))\nplot(table(final_earning) / R, xlab = \"Guadagno finale (50 partite)\", ylab = \"Funzione di probabilità\")\n\n\n\n\nLa distribuzione del guadagno finale è quindi simmetrica attorno allo zero.\nVogliamo infine calcolare la probabilità di vittoria, definita come \\[\n\\mathbb{P}(X > 0).\n\\]\nConsideriamo quindi la variabile aleatoria binaria \\(Z = \\mathbb{1}(X > 0)\\).\nApprossimiamo l’evento contando i successi verificatisi tra le variabili \\(Z_1,\\dots,Z_R\\).\n\nmean(final_earning > 0) # Probabilità di vincere, ovvero P(X > 0)\n\n[1] 0.44253\n\n\nLa probabilità di vittoria è pertanto inferiore a \\(0.5\\), mentre la probabilità di parità, ovvero \\(\\mathbb{P}(X = 0)\\), è positiva:\n\nmean(final_earning == 0) # Probabilità di pareggiare, ovvero P(X = 0)\n\n[1] 0.11225"
  },
  {
    "objectID": "lezioni/un_J.html#la-roulette-americana-i",
    "href": "lezioni/un_J.html#la-roulette-americana-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "La roulette americana I",
    "text": "La roulette americana I\n\nIl gioco del “lancio della monetina’’ è concettualmente identico ad un gioco d’azzardo ben più popolare, la roulette.\nSupponendo di scommettere sul rosso (o sul nero) 10 euro, questo gioco d’azzardo può essere simulato usando sostanzialmente lo stesso codice discusso finora.\nC’è però una differenza importante, soprattutto da un punto di vista finanziario: la presenza dello zero e del doppio zero."
  },
  {
    "objectID": "lezioni/un_J.html#la-roulette-americana-ii",
    "href": "lezioni/un_J.html#la-roulette-americana-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "La roulette americana II",
    "text": "La roulette americana II\nSupponendo di scommettere 10 euro sul rosso, la probabilità di vincerne altrettanti non è più \\(1/2\\), come nel caso del lancio della monetina, bensì: \\[\n\\mathbb{P}(\\text{``Vincere puntando sul rosso''}) = \\frac{18}{38} \\approx 0.474.\n\\] Si tratta quindi, come ben noto, di un gioco non equo, in cui il banco dispone di un vantaggio.\nSiamo interessati ad indagare la variabile aleatoria \\(X\\), che rappresenta il guadagno finale del giocatore nei confronti del banco:\n\np_winning <- 18 / 38\np_winning\n\n[1] 0.4736842\n\n# Ottengo il guadagno finale (una volta sola)\nset.seed(123)\nsum(sample(c(-10, 10), 50, replace = TRUE, prob = c(1 - p_winning, p_winning)))\n\n[1] 0"
  },
  {
    "objectID": "lezioni/un_J.html#simulazione-ed-analisi-dei-risultati",
    "href": "lezioni/un_J.html#simulazione-ed-analisi-dei-risultati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simulazione ed analisi dei risultati",
    "text": "Simulazione ed analisi dei risultati\nTramite gli stessi comandi usati in precedenza, ripetiamo \\(R\\) volte l’operazione per studiare la distribuzione di \\(X\\).\n\nset.seed(123)\nR <- 10^5\nfinal_earning <- replicate(R, sum(sample(c(-10, 10), 50, replace = TRUE, \n                                         prob = c(1 - p_winning, p_winning))))\n\n\n# Media del guadagno finale\nmean(final_earning)\n\n[1] -26.3814\n\n\n\n# Deviazione standard del guadagno finale\nsd(final_earning)\n\n[1] 70.54601\n\n\n\n# Probabilità di vittoria, ovvero P(X > 0)\nmean(final_earning > 0)\n\n[1] 0.30387\n\n\n\n# Probabilità di pareggio, ovvero P(X == 0)\nmean(final_earning == 0)\n\n[1] 0.10483\n\n\n\npar(mfrow = c(1, 1))\nplot(table(final_earning) / R, xlab = \"Guadagno finale (50 partite)\", ylab = \"Funzione di probabilità\")"
  },
  {
    "objectID": "lezioni/un_J.html#distribuzione-di-probabilità",
    "href": "lezioni/un_J.html#distribuzione-di-probabilità",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione di probabilità",
    "text": "Distribuzione di probabilità\n\nplot(table(final_earning) / R, xlab = \"Guadagno finale (50 partite)\", ylab = \"Funzione di probabilità\")\n\n\n\n\nPossiamo osservare un “picco” di probabilità nel valore \\(-100\\) e pertanto circa il \\(25\\%\\) delle volte il giocatore finisce in bancarotta.\nCon un budget di 100,000 euro, è impossibile che il banco vada in rovina.\nAl tempo stesso, il valore atteso rimane negativo, ovvero \\(\\mathbb{E}(X) = -24\\), ma è tuttavia superiore a quello ottenuto nel modello con budget illimitato, ovvero circa \\(-26\\).\nIn un certo senso, il banco non può sottrarre al giocatore i soldi che questo non possiede.\nDa questo desumiamo la strategia di gioco ottimale alla roulette: bisogna entrare nel casinò con pochi spiccioli in portafoglio o, idealmente, con assolutamente nulla."
  },
  {
    "objectID": "lezioni/un_J.html#commenti-ai-risultati",
    "href": "lezioni/un_J.html#commenti-ai-risultati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Commenti ai risultati",
    "text": "Commenti ai risultati\nIl valore atteso del guadagno finale \\(\\mathbb{E}(X)\\) è negativo e circa pari a \\(-26\\).\nLa probabilità di vittoria e di pareggio diminuiscono rispetto al “lancio della monetina”.\nL’intera distribuzione è spostata verso valori negativi rispetto al primo scenario.\nQuesti risultati sono una formalizzazione del detto popolare “il banco vince sempre”. Per questo gli statistici non giocano d’azzardo, o quantomeno non alla roulette!\n\n\n\n\n\n\nEsercizio - Proprietà\n\n\n\nI valori attesi, le varianze e le probabilità calcolate tramite simulazione possono essere in realtà ottenute anche analiticamente. Si provi a calcolarle tramite “carta e penna”.\nNegli ultimi paragrafi considereremo quindi un esempio leggermente più sofisticato, che renderebbe molto più difficile (anche se non impossibile) fare i conti analitici."
  },
  {
    "objectID": "lezioni/un_J.html#uno-scenario-più-realistico",
    "href": "lezioni/un_J.html#uno-scenario-più-realistico",
    "title": "R per l’analisi statistica multivariata",
    "section": "Uno scenario più realistico",
    "text": "Uno scenario più realistico\nL’implicita ipotesi delle simulazioni precedenti è che sia il giocatore che il banco abbiano un budget superiore a \\(500\\) euro, ovvero la perdita massima.\nConsideriamo quindi il caso in cui il giocatore abbia un budget massimo, ad esempio \\(100\\) euro, così come il banco, ad esempio \\(100,000\\) euro.\n\n\n\n\n\n\nNota\n\n\n\nSe questi numeri sembrano irrealistici, è sufficiente ripetere la simulazione cambiando ordine di grandezza, ad esempio moltiplicando tutto per 10 o 100.\n\n\nIl giocatore continua a scommettere fino ad un massimo di \\(50\\) volte solo se ha ancora soldi a disposizione. Altrimenti, è costretto a fermarsi.\n\n# Funzione che simula il guadagno finale dopo 50 scommesse\nsim_match <- function(player_budget, casino_budget, p_winning){\n  \n  player_money <- player_budget\n  casino_money <- casino_budget\n  \n  for(r in 1:50){\n    outcome <- sample(c(-10, 10), 1, prob = c(1 - p_winning, p_winning))\n    player_money <- player_money + outcome # Aggiorno il budget giocatore\n    casino_money <- casino_money - outcome # Aggiorno il budget casinò\n    if(player_money <= 0){\n      # Giocatore in rovina: il giocatore perde tutto il budget\n      return(- player_budget)\n    }\n    if(casino_money <= 0){\n      # Casinò in rovina: il casinò perde tutto il budget\n      return(casino_budget)\n    }\n  }\n  player_money - player_budget # guadagno rispetto al valore iniziale\n}\n\nset.seed(220)\nsim_match(100, 100000, p_winning)\n\n[1] -60"
  },
  {
    "objectID": "lezioni/un_J.html#simulazione-ed-analisi-dei-risultati-1",
    "href": "lezioni/un_J.html#simulazione-ed-analisi-dei-risultati-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simulazione ed analisi dei risultati",
    "text": "Simulazione ed analisi dei risultati\nTramite gli stessi comandi usati in precedenza, ripetiamo \\(R\\) volte l’operazione per studiare la distribuzione di \\(X\\).\n\nset.seed(123)\nR <- 10^5\nfinal_earning <- replicate(10^5, sim_match(100, 100000, p_winning))\n\n\n# Media del guadagno finale\nmean(final_earning)\n\n[1] -24.0002\n\n\n\n# Deviazione standard del guadagno finale\nsd(final_earning)\n\n[1] 64.52637\n\n\n\n# Probabilità di vittoria, ovvero P(X > 0)\nmean(final_earning > 0)\n\n[1] 0.30288\n\n\n\n# Probabilità di pareggio, ovvero P(X == 0)\nmean(final_earning == 0)\n\n[1] 0.10084"
  },
  {
    "objectID": "lezioni/un_J.html#distribuzione-di-probabilità-1",
    "href": "lezioni/un_J.html#distribuzione-di-probabilità-1",
    "title": "R per l’analisi statistica multivariata",
    "section": "Distribuzione di probabilità",
    "text": "Distribuzione di probabilità\n\nplot(table(final_earning) / R, xlab = \"Guadagno finale (50 partite)\", ylab = \"Funzione di probabilità\")\n\n\n\n\nPossiamo osservare un “picco” di probabilità nel valore \\(-100\\) e pertanto circa il \\(25\\%\\) delle volte il giocatore finisce in bancarotta.\nCon un budget di 100,000 euro, è impossibile che il banco vada in rovina.\nAl tempo stesso, il valore atteso rimane negativo, ovvero \\(\\mathbb{E}(X) = -24\\), ma è tuttavia superiore a quello ottenuto nel modello con budget illimitato, ovvero circa \\(-26\\).\nIn un certo senso, il banco non può sottrarre al giocatore i soldi che questo non possiede.\nDa questo desumiamo la strategia di gioco ottimale alla roulette: bisogna entrare nel casinò con pochi spiccioli in portafoglio o, idealmente, con assolutamente nulla."
  },
  {
    "objectID": "lezioni/un_J.html#il-lancio-della-monetina-i",
    "href": "lezioni/un_J.html#il-lancio-della-monetina-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il lancio della monetina I",
    "text": "Il lancio della monetina I\nIl comando che simula una singola partita, ovvero \\(50\\) lanci di monetina dal punto di vista del giocatore A, è il seguente:\n\nset.seed(123)\nsample(c(-10, 10), 50, replace = TRUE) # Gioco 50 volte ai dadi contro B\n\n [1] -10 -10 -10  10 -10  10  10  10 -10 -10  10  10  10 -10  10 -10  10 -10 -10\n[20] -10 -10  10 -10 -10 -10 -10  10  10 -10  10 -10  10 -10  10  10 -10 -10 -10\n[39] -10  10 -10  10  10 -10 -10 -10 -10  10 -10 -10\n\n\nNoi siamo tuttavia interessati al guadagno del giocatore A. Ovviamente per ottenere i guadagni di B è sufficiente cambiare il segno dei risultati.\nIl guadagno del giocatore A dopo ciascun lancio di monetina è pari a\n\nset.seed(123)\ncumsum(sample(c(-10, 10), 50, replace = TRUE))\n\n [1]  -10  -20  -30  -20  -30  -20  -10    0  -10  -20  -10    0   10    0   10\n[16]    0   10    0  -10  -20  -30  -20  -30  -40  -50  -60  -50  -40  -50  -40\n[31]  -50  -40  -50  -40  -30  -40  -50  -60  -70  -60  -70  -60  -50  -60  -70\n[46]  -80  -90  -80  -90 -100"
  },
  {
    "objectID": "lezioni/un_J.html#il-lancio-della-monetina-ii",
    "href": "lezioni/un_J.html#il-lancio-della-monetina-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il lancio della monetina II",
    "text": "Il lancio della monetina II\n\npar(mfrow=c(1,2))\nset.seed(250)\n\nplot(1:50, cumsum(sample(c(-10, 10), 50, replace = TRUE)), type = \"b\", xlab = \"# Lancio\", ylab = \"Guadagno\")\nabline(h = 0, lty = \"dotted\")\n\nplot(1:50, cumsum(sample(c(-10, 10), 50, replace = TRUE)), type = \"b\", xlab = \"# Lancio\", ylab = \"Guadagno\")\nabline(h = 0, lty = \"dotted\")"
  },
  {
    "objectID": "lezioni/un_L.html",
    "href": "lezioni/un_L.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "Modelli linearizzabili\nMinimi quadrati non lineari\nGli alberi di ciliegio nero\n\n\n\n\n\n\n\nRiferimenti aggiuntivi\n\n\n\n\nL’Unità K del corso Statistica I\nL’Unità L del corso Statistica I\nGli esercizi R associati sono disponibili a questo link"
  },
  {
    "objectID": "lezioni/un_L.html#descrizione-del-problema",
    "href": "lezioni/un_L.html#descrizione-del-problema",
    "title": "R per l’analisi statistica multivariata",
    "section": "Descrizione del problema",
    "text": "Descrizione del problema\nPer \\(n = 31\\) alberi di ciliegio nero sono disponibili le misure del diametro del tronco (misurato a circa \\(1\\)m dal suolo) ed il volume ricavato dall’albero dopo l’abbattimento.\nSi vogliono utilizzare i dati per ottenere un’equazione che permetta di prevedere il volume, ottenibile solo dopo l’abbattimento dell’albero, avendo a disposizione il diametro, che è invece facilmente misurabile.\nIn altri termini, stiamo cercando una qualche funzione \\(f(\\cdot)\\) tale che\n\\[\n\\text{(volume)} \\approx f(\\text{diametro}).\n\\]\nUna simile equazione ha differenti utilizzi.\nAd esempio, può essere utilizzata per decidere quanti e quali alberi tagliare per ricavare un certo ammontare di legno, oppure per determinare il “prezzo” di un bosco."
  },
  {
    "objectID": "lezioni/un_L.html#importazione-dei-dati-ciliegi",
    "href": "lezioni/un_L.html#importazione-dei-dati-ciliegi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Importazione dei dati ciliegi",
    "text": "Importazione dei dati ciliegi\nCome fatto in precedenza, anzitutto è necessario scaricare il file ciliegi.csv e salvarlo nel proprio computer. Link al file\n\nciliegi <- read.table(\"../dataset/ciliegi.csv\", header = TRUE, sep = \",\")\n\nIn alternativa, possiamo semplice ottenerli usando il link:\n\npath <- \"https://tommasorigon.github.io/introR/data/ciliegi.csv\"\nciliegi <- read.table(path, header = TRUE, sep = \",\")\n\n\nhead(ciliegi)\n\n  diametro volume\n1      8.3   10.3\n2      8.6   10.3\n3      8.8   10.2\n4     10.5   16.4\n5     10.7   18.8\n6     10.8   19.7"
  },
  {
    "objectID": "lezioni/un_L.html#diagramma-a-dispersione",
    "href": "lezioni/un_L.html#diagramma-a-dispersione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Diagramma a dispersione",
    "text": "Diagramma a dispersione\n\nplot(ciliegi)"
  },
  {
    "objectID": "lezioni/un_L.html#alcune-considerazioni-geometriche-recap",
    "href": "lezioni/un_L.html#alcune-considerazioni-geometriche-recap",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcune considerazioni geometriche (recap)",
    "text": "Alcune considerazioni geometriche (recap)\nNelle Unità K ed Unità L del corso Statistica I abbiamo costruito dei modelli statistici del tipo \\(\\text{(volume)} \\approx f(\\text{diametro})\\) basati sulla geometria degli alberi.\nDopo varie considerazioni di tipo geometrico, si era giunti ad una specificazione del tipo \\[\n\\text{(volume)} = \\eta \\:\\text{(diametro)}^{\\lambda},\n\\] per due costanti positive \\(\\eta, \\lambda > 0\\).\nPotremmo determinare i valori appropriati per \\(\\eta\\) e \\(\\lambda\\) utilizzando i minimi quadrati, ovvero considerando \\[\n(\\hat{\\eta}_{\\text{ls}}, \\hat{\\lambda}_{\\text{ls}}) = \\arg\\min_{\\eta, \\lambda} \\frac{1}{n} \\sum_{i=1}^n\\left(y_i - \\eta x_i^\\lambda\\right)^2.\n\\]\nPurtroppo non esiste una soluzione in forma chiusa a questo problema, che infatti necessita dell’utilizzo di tecniche numeriche."
  },
  {
    "objectID": "lezioni/un_L.html#minimi-quadrati-non-lineari",
    "href": "lezioni/un_L.html#minimi-quadrati-non-lineari",
    "title": "R per l’analisi statistica multivariata",
    "section": "Minimi quadrati non-lineari",
    "text": "Minimi quadrati non-lineari\nLa procedura di stima per \\((\\hat{\\eta}_{\\text{ls}}, \\hat{\\lambda}_{\\text{ls}})\\) prende il nome di minimi quadrati non-lineari e richiede una minimizzazione numerica, come quelle che abbiamo visto nell’Unità K.\nGrazie ad R ed ai suoi strumenti computazionali, possiamo quindi svolgere un calcolo che nei corsi precedenti non era risolvibile. In particolare, possiamo usare nlminb.\nIn primo luogo, definiamo la funzione obiettivo o funzione di perdita:\n\n# Funzione di perdita che vogliamo minimizzare\nloss <- function(par, y, x) {\n  mean((y - par[1] * x^par[2])^2)\n}\n\nAd esempio, tale funzione, valutata nel punto \\((1,1)\\) vale circa \\(460.83\\), infatti:\n\nloss(c(1, 1), ciliegi$volume, ciliegi$diametro)\n\n[1] 460.8329"
  },
  {
    "objectID": "lezioni/un_L.html#stima-ai-minimi-quadrati",
    "href": "lezioni/un_L.html#stima-ai-minimi-quadrati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Stima ai minimi quadrati",
    "text": "Stima ai minimi quadrati\nLa stima ai minimi quadrati si ottiene quindi usando nlminb. In questo caso, siamo effettivamente interessati a minimizzare una funzione.\n\nfit_ls <- nlminb(start = c(1, 1), function(param) loss(param, ciliegi$volume, ciliegi$diametro),\n                 lower = c(1e-6, 1e-6))\nfit_ls\n\n$par\n[1] 0.08661007 2.23638534\n\n$objective\n[1] 10.12108\n\n$convergence\n[1] 0\n\n$iterations\n[1] 27\n\n$evaluations\nfunction gradient \n      41       61 \n\n$message\n[1] \"relative convergence (4)\"\n\n\n\n# Salvo i risultati\nparam_hat_ls <- fit_ls$par\nparam_hat_ls\n\n[1] 0.08661007 2.23638534"
  },
  {
    "objectID": "lezioni/un_L.html#commenti-ai-risultati",
    "href": "lezioni/un_L.html#commenti-ai-risultati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Commenti ai risultati",
    "text": "Commenti ai risultati\nI comandi precedenti quindi implicano che la stima ai minimi quadrati (non lineari) è pari a \\[\\hat{\\eta}_{\\text{ls}} = 0.0866, \\qquad \\hat{\\lambda}_{\\text{ls}} = 2.2364.\n\\]\nInoltre, la varianza residuale è pari a \\[\n    \\frac{1}{n} \\sum_{i=1}^n\\left(y_i - \\hat{\\eta}_{\\text{ls}} x_i^{\\hat{\\lambda}_{\\text{ls}}}\\right)^2 = 10.121.\n\\]\nInfatti:\n\nfit_ls$objective\n\n[1] 10.12108\n\n\nCome ricorderete, questo problema di stima può essere affrontato alternativamente tramite la procedura di linearizzazione del modello.\nSupponendo che la relazione sia del tipo \\(\\text{(volume)} = \\eta \\:\\text{(diametro)}^{\\lambda}\\), allora applicando la funzione \\(\\log\\) ambo i lati, si ottiene \\[\n\\log{\\text{(volume)}} = \\log{\\eta}  + \\lambda\\log{\\text{(diametro)}}.\n\\]\nQuindi, la relazione non lineare che abbiamo supposto tra diametro e volume corrisponde ad una relazione lineare tra i logaritmi delle due variabili."
  },
  {
    "objectID": "lezioni/un_L.html#il-modello-linearizzato",
    "href": "lezioni/un_L.html#il-modello-linearizzato",
    "title": "R per l’analisi statistica multivariata",
    "section": "Il modello linearizzato",
    "text": "Il modello linearizzato\nLa relazione in scala logaritmica descrive un modello linearizzato. Si tratta di un modello di regressione lineare semplice in cui \\[\nz_i = \\log y_i, \\qquad w_i = \\log{x_i}, \\qquad i=1,\\dots,n.\n\\]\nIntroducendo esplicitamente il termine di errore, avremo quindi che \\[\nz_i = \\alpha + \\beta w_i + \\epsilon_i\n\\] in cui \\(\\alpha = \\log \\eta\\) e \\(\\beta = \\lambda\\).\nPossiamo determinare i parametri trasformati ottimali \\(\\hat{\\alpha}\\) e \\(\\hat{\\beta}\\) ed i parametri originali \\(\\hat{\\eta}_{\\text{ols}}\\) ed \\(\\hat{\\lambda}_{\\text{ols}}\\) utilizzando il criterio dei minimi quadrati sulla scala trasformata, ovvero \\[\n\\min_{\\alpha, \\beta} \\frac{1}{n} \\sum_{i=1}^n\\left(z_i - \\alpha - \\beta w_i \\right)^2 = \\min_{\\eta, \\lambda} \\frac{1}{n} \\sum_{i=1}^n\\left(\\log{y_i} - \\log{\\eta} - \\lambda \\log{x_i} \\right)^2.\n\\]\nVarrà quindi la relazione \\(\\hat{\\eta}_{\\text{ols}} = \\exp\\{\\hat{\\alpha}\\}\\) e che \\(\\hat{\\lambda}_{\\text{ols}} = \\hat{\\beta}\\)."
  },
  {
    "objectID": "lezioni/un_L.html#stima-ai-minimi-quadrati-modello-linearizzato",
    "href": "lezioni/un_L.html#stima-ai-minimi-quadrati-modello-linearizzato",
    "title": "R per l’analisi statistica multivariata",
    "section": "Stima ai minimi quadrati (modello linearizzato)",
    "text": "Stima ai minimi quadrati (modello linearizzato)\nLa stima ai minimi quadrati in scala trasformata ammette una soluzione esplicita.\n\nz <- log(ciliegi$volume)\nw <- log(ciliegi$diametro)\n\nbeta_hat_ols <- cov(w, z) / var(w)\nalpha_hat_ols <- mean(z) - mean(w) * beta_hat_ols\n\n# Stima ai minimi quadrati, scala trasformata\nparam_hat_ols <- c(exp(alpha_hat_ols), beta_hat_ols)\nparam_hat_ols\n\n[1] 0.09505259 2.19996993\n\n# Varianza residuale\nloss(param_hat_ols, ciliegi$volume, ciliegi$diametro)\n\n[1] 10.2531\n\n\nI comandi precedenti quindi implicano che la stima ai minimi quadrati (modello linearizzato) è pari a \\[\n\\hat{\\eta}_{\\text{ols}} = 0.095, \\qquad \\hat{\\lambda}_{\\text{ols}} = 2.200.\n\\]\nInoltre, la varianza residuale \\(n^{-1} \\sum_{i=1}^n(y_i - \\hat{\\eta}_{\\text{ols}} x_i^{\\hat{\\lambda}_{\\text{ols}}})^2 = 10.253\\) è superiore a quella ottenuta in precedenza ({come mai?), anche se di poco."
  },
  {
    "objectID": "lezioni/un_L.html#confronto-tra-modelli",
    "href": "lezioni/un_L.html#confronto-tra-modelli",
    "title": "R per l’analisi statistica multivariata",
    "section": "Confronto tra modelli",
    "text": "Confronto tra modelli\n\nplot(ciliegi)\ncurve(param_hat_ls[1] * x^param_hat_ls[2], \n      add = TRUE, lty = \"dashed\") # Stime numeriche non-lineari\ncurve(param_hat_ols[1] * x^param_hat_ols[2], \n      add = TRUE, lty = \"dashed\", col = \"red\") # Modello linearizzato"
  },
  {
    "objectID": "lezioni/un_L.html#commenti-conclusivi",
    "href": "lezioni/un_L.html#commenti-conclusivi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Commenti conclusivi",
    "text": "Commenti conclusivi\nI due approcci sono sostanzialmente equivalenti in questo specifico esempio, nel senso che producono risultati quasi indistinguibili.\nSi noti che il modello è lo stesso, abbiamo solo cambiato metodo di stima!\nTuttavia, in generale non è detto che sia possibile linearizzare il modello originale. In questi casi, non esiste un’alternativa semplice.\nInfine, a seconda della funzione di perdita utilizzata, due diversi metodi di stima potrebbero differire di molto nonostante il modello sia lo stesso.\nAd esempio, alcuni stimatori sono più robusti di altri rispetto alla presenza di valori anomali."
  },
  {
    "objectID": "lezioni/un_intro.html#struttura-del-corso-ii",
    "href": "lezioni/un_intro.html#struttura-del-corso-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Struttura del corso II",
    "text": "Struttura del corso II\nL’analisi statistica multivariata riguarda l’analisi congiunta di più variabili misurate sul medesimo insieme di unità statistiche.\nNei corsi precedenti (ad es. Statistica I), ci si è concentrati su una o due variabili alla volta. In contesti reali le variabili coinvolte sono quasi sempre ben più di 2.\nIl modulo AE è la naturale prosecuzione di un corso di statistica descrittiva, applicato al caso in cui le variabili sono più di 2.\nIl modulo MS estende e analizza nel dettaglio il modello lineare, nel caso in cui le variabili esplicative sono molte.\nLe tecniche per l’analisi di dati multivariati possono avere una natura descrittiva / esplorativa (AE) oppure inferenziale (MS)."
  },
  {
    "objectID": "lezioni/un_intro.html#asm-r",
    "href": "lezioni/un_intro.html#asm-r",
    "title": "R per l’analisi statistica multivariata",
    "section": "ASM-R",
    "text": "ASM-R\nIl modulo R è in larga misura una revisione di argomenti che dovreste già conoscere bene. Nello specifico, ci occuperemo di\n\nStatistica descrittiva (Statistica I);\nCalcolo delle probabilità;\nInferenza statistica (Statistica II).\n\nAl tempo stesso, il modulo R è un esame di programmazione in R.\n\nNota\nASM-R non è una “introduzione” al software R. Lo scopo del corso è mostrare come risolvere problemi statistici reali disponendo di un computer.\nIn altre parole, all’esame verranno valutati sia la forma (programmazione) che il contenuto (analisi statistica)."
  },
  {
    "objectID": "lezioni/un_py_A.html",
    "href": "lezioni/un_py_A.html",
    "title": "R per l’analisi statistica multivariata",
    "section": "",
    "text": "A-B-C: il software Python come calcolatrice scientifica\nOperazioni di routine: pulizia del workspace, simboli speciali\nFunzioni matematiche, grafico di una funzione, operazioni logiche\nOperazioni con vettori e matrici\n\n\n\n\n\n\n\nNota\n\n\n\nEsercizi Python associati sono diponibili a questo link"
  },
  {
    "objectID": "lezioni/un_py_A.html#calcolatrice-scientifica",
    "href": "lezioni/un_py_A.html#calcolatrice-scientifica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Calcolatrice scientifica",
    "text": "Calcolatrice scientifica\nAnzitutto, Python può essere usato come se fosse una calcolatrice scientifica:\n\n2 + 2\n\n4\n\n\n\n4 * (3 + 5) # La somma entro parentesi viene eseguita per prima\n\n32\n\n\n\nfrom numpy import pi\npi / 4 # Pi greco quarti\n\n0.7853981633974483\n\n\nPer calcolare la potenza \\(a^b\\) si usa:\n\n2**5\n\n32\n\n\nLe quantità \\(\\sqrt{2}\\) e \\(\\sin(\\pi/4)\\) si ottengono invece con i comandi:\n\nimport numpy as np\nnp.sqrt(2)\n\n1.4142135623730951\n\n\n\nnp.sin(pi / 4)\n\n0.7071067811865475\n\n\n\n\n\n\n\n\nNota\n\n\n\nTutto ciò che viene scritto dopo un cancelletto (#) è considerato un commento."
  },
  {
    "objectID": "lezioni/un_py_A.html#assegnazione-di-un-valore",
    "href": "lezioni/un_py_A.html#assegnazione-di-un-valore",
    "title": "R per l’analisi statistica multivariata",
    "section": "Assegnazione di un valore",
    "text": "Assegnazione di un valore\nÈ possibile salvare un valore assegnandolo ad un oggetto tramite il simbolo =.\n\n# Assegna il valore 5 all'oggetto x\nx = np.sqrt(5)\n\nIl valore contenuto in x può essere successivamente richiamato, modificato e salvato in un nuovo oggetto, chiamato ad esempio y.\n\ny = x + pi # ovvero pi greco + radice quadrata di 5\ny\n\n5.377660631089583\n\n\nPer rimuovere un oggetto dalla memoria, si usa il comando del, ovvero delete.\n\ndel x # x non è più presente nel \"workspace\"\n\n\n\n\n\n\n\nNota\n\n\n\nPython è case sensitive, pertanto l’oggetto x è diverso dall’oggetto X."
  },
  {
    "objectID": "lezioni/un_py_A.html#pulizia-del-workspace",
    "href": "lezioni/un_py_A.html#pulizia-del-workspace",
    "title": "R per l’analisi statistica multivariata",
    "section": "Pulizia del workspace",
    "text": "Pulizia del workspace\nÈ buona norma mantenere pulito il workspace, ovvero l’ambiente di lavoro.\nSe un oggetto non è più necessario, è possibile eliminarlo tramite il comando del.\nÈ possibile visualizzare la lista di oggetti salvati in memoria tramite il comando seguente:\n\ndir() # Nel workspace è presente l'oggetto y"
  },
  {
    "objectID": "lezioni/un_py_A.html#alcune-funzioni-matematiche-i",
    "href": "lezioni/un_py_A.html#alcune-funzioni-matematiche-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcune funzioni matematiche I",
    "text": "Alcune funzioni matematiche I\nSupponiamo che x sia un numero reale.\nCiò che seguono sono una lista di funzioni disponibili in Python:\n\nx = 1/2 # Esempio di numero reale\n\n\nnp.exp(x) # Esponenziale e logaritmo naturale\n\n1.6487212707001282\n\n\n\nnp.log(x)\n\n-0.6931471805599453\n\n\n\nnp.abs(x) # Valore assoluto\n\n0.5\n\n\n\nnp.sign(x) # Funzione segno\n\n1.0"
  },
  {
    "objectID": "lezioni/un_py_A.html#alcune-funzioni-matematiche-ii",
    "href": "lezioni/un_py_A.html#alcune-funzioni-matematiche-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Alcune funzioni matematiche II",
    "text": "Alcune funzioni matematiche II\n\nnp.sin(x) # Funzioni trigonometriche (seno, coseno, tangente)\n\n0.479425538604203\n\n\n\nnp.cos(x)\n\n0.8775825618903728\n\n\n\nnp.tan(x)\n\n0.5463024898437905\n\n\n\nnp.arcsin(x) # Funzioni trigonometriche (seno, coseno, tangente)\n\n0.5235987755982988\n\n\n\nnp.arccos(x)\n\n1.0471975511965976\n\n\n\nnp.arctan(x)\n\n0.46364760900080615\n\n\n\n\n\n\n\n\nNota\n\n\n\nLe funzioni di Python si possono combinare tra loro, ad esempio np.log(np.abs(x))."
  },
  {
    "objectID": "lezioni/un_py_A.html#ulteriori-funzioni-matematiche-i",
    "href": "lezioni/un_py_A.html#ulteriori-funzioni-matematiche-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ulteriori funzioni matematiche I",
    "text": "Ulteriori funzioni matematiche I\nSupponiamo che x e y siano due numeri reali. Inoltre, siano n e k due numeri naturali.\nSi noti l’uso del ; che può essere usato per separare due comandi nella stessa riga.\n\nx = 1 / 2; y = 1 / 3 # Numeri reali \nn = 5; k = 2 # Numeri naturali\n\n\nimport scipy.special as scp\nscp.factorial(n) # n!\n\n120.0\n\n\n\nscp.binom(n, k) # Coefficiente binomiale\n\n10.0\n\n\n\nnp.around(x, 2) # Arrotonda x usando 2 cifre decimali\n\n0.5\n\n\n\nnp.floor(x) # Arrotonda x all'intero più vicino, per difetto\n\n0.0\n\n\n\nnp.ceil(x) # Arrotonda x all'intero più vicino, per eccesso\n\n1.0"
  },
  {
    "objectID": "lezioni/un_py_A.html#ulteriori-funzioni-matematiche-ii",
    "href": "lezioni/un_py_A.html#ulteriori-funzioni-matematiche-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Ulteriori funzioni matematiche II",
    "text": "Ulteriori funzioni matematiche II\nLa funzione gamma \\(\\Gamma(x) = \\int_0^\\infty s^{x-1} e^{-s} d s\\) si calcola in Python come segue:\n\nscp.gamma(x) # Funzione gamma\n\n1.7724538509055159\n\n\nLa funzione beta \\(\\mathcal{B}(x,y) = \\int_0^1 s^{x-1}(1-s)^{y-1}ds\\) si calcola in Python come segue:\n\nscp.beta(x, y) # Funzione beta\n\n4.206546315976361"
  },
  {
    "objectID": "lezioni/un_py_A.html#la-documentazione-ufficiale",
    "href": "lezioni/un_py_A.html#la-documentazione-ufficiale",
    "title": "R per l’analisi statistica multivariata",
    "section": "La documentazione ufficiale",
    "text": "La documentazione ufficiale\nLa documentazione di Python è la principale fonte di informazioni.\nA cosa serve una funzione? Qual è la definizione dei suoi argomenti? La risposta va sempre cercata nella documentazione ufficiale e non in queste slide.\nIl comando help(funzione) apre una finestra in cui vengono descritta nel dettaglio una funzione. Esempio:\n\n# Documentazione della funzione log\nhelp(np.log) \n\nHelp on ufunc:\n\nlog = <ufunc 'log'>\n    log(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n    \n    Natural logarithm, element-wise.\n    \n    The natural logarithm `log` is the inverse of the exponential function,\n    so that `log(exp(x)) = x`. The natural logarithm is logarithm in base\n    `e`.\n    \n    Parameters\n    ----------\n    x : array_like\n        Input value.\n    out : ndarray, None, or tuple of ndarray and None, optional\n        A location into which the result is stored. If provided, it must have\n        a shape that the inputs broadcast to. If not provided or None,\n        a freshly-allocated array is returned. A tuple (possible only as a\n        keyword argument) must have length equal to the number of outputs.\n    where : array_like, optional\n        This condition is broadcast over the input. At locations where the\n        condition is True, the `out` array will be set to the ufunc result.\n        Elsewhere, the `out` array will retain its original value.\n        Note that if an uninitialized `out` array is created via the default\n        ``out=None``, locations within it where the condition is False will\n        remain uninitialized.\n    **kwargs\n        For other keyword-only arguments, see the\n        :ref:`ufunc docs <ufuncs.kwargs>`.\n    \n    Returns\n    -------\n    y : ndarray\n        The natural logarithm of `x`, element-wise.\n        This is a scalar if `x` is a scalar.\n    \n    See Also\n    --------\n    log10, log2, log1p, emath.log\n    \n    Notes\n    -----\n    Logarithm is a multivalued function: for each `x` there is an infinite\n    number of `z` such that `exp(z) = x`. The convention is to return the\n    `z` whose imaginary part lies in `[-pi, pi]`.\n    \n    For real-valued input data types, `log` always returns real output. For\n    each value that cannot be expressed as a real number or infinity, it\n    yields ``nan`` and sets the `invalid` floating point error flag.\n    \n    For complex-valued input, `log` is a complex analytical function that\n    has a branch cut `[-inf, 0]` and is continuous from above on it. `log`\n    handles the floating-point negative zero as an infinitesimal negative\n    number, conforming to the C99 standard.\n    \n    References\n    ----------\n    .. [1] M. Abramowitz and I.A. Stegun, \"Handbook of Mathematical Functions\",\n           10th printing, 1964, pp. 67. http://www.math.sfu.ca/~cbm/aands/\n    .. [2] Wikipedia, \"Logarithm\". https://en.wikipedia.org/wiki/Logarithm\n    \n    Examples\n    --------\n    >>> np.log([1, np.e, np.e**2, 0])\n    array([  0.,   1.,   2., -Inf])"
  },
  {
    "objectID": "lezioni/un_py_A.html#simboli-speciali",
    "href": "lezioni/un_py_A.html#simboli-speciali",
    "title": "R per l’analisi statistica multivariata",
    "section": "Simboli speciali",
    "text": "Simboli speciali\nNumeri molto grandi, come \\(10^{15}\\), e molto piccoli, come \\(10^{-15}\\), in Python vengono rappresentati come segue:\n\n10**15\n\n1000000000000000\n\n\n\n10**(-15)\n\n1e-15"
  },
  {
    "objectID": "lezioni/un_py_A.html#errori-di-approssimazione-numerica",
    "href": "lezioni/un_py_A.html#errori-di-approssimazione-numerica",
    "title": "R per l’analisi statistica multivariata",
    "section": "Errori di approssimazione numerica",
    "text": "Errori di approssimazione numerica\nÈ ben noto che \\(\\sin(\\pi) = 0\\). Tuttavia, in Python si ottiene un numero molto vicino a \\(0\\), ma strettamente positivo. Infatti:\n\nnp.sin(pi)\n\n1.2246467991473532e-16\n\n\nPython è uno strumento di calcolo numerico e pertanto sono sempre presenti errori di approssimazione numerica.\nFortunatamente, nella maggior parte dei casi pratici la differenza tra \\(0\\) e \\(10^{-16}\\) è del tutto irrilevante.\nIn altre situazioni, errori di approssimazione numerica possono portare a conclusioni fuorvianti. Occorre quindi fare attenzione e valutare caso per caso.\nAd ogni modo, l’approssimazione numerica potrebbe anche migliorare. Ad esempio:\n\nnp.cos(pi)\n\n-1.0"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-logiche",
    "href": "lezioni/un_py_A.html#operazioni-logiche",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni logiche",
    "text": "Operazioni logiche\nIn Python è spesso necessario verificare se una o più condizioni sono verificate o meno.\n\nx = 5\n\n\nx < 0 # Controlla se il valore di x è minore di 0\n\nFalse\n\n\n\na = (x == -3) # Controlla se il valore di x è uguale a -3\na\n\nFalse\n\n\nIl valore di a è un indicatore binario o booleano, ovvero può essere vero (True) oppure falso (False).\nAltre funzioni logiche disponibili (assumendo che y sia un numero e b un booleano) sono:\n\na = True; b = False; x = 5; y = 7\nx >= y # Controlla se x è maggiore o uguale a y (Si usa \"<=\" per minore uguale)\n\nFalse\n\n\n\nx != y # Controlla se x è diverso da y\n\nTrue\n\n\n\na & b # a AND b. Controlla se i valori booleani a e b sono entrambi veri\n\nFalse\n\n\n\na | b # a OR b. Controlla se Almeno uno tra a ed b è vero\n\nTrue"
  },
  {
    "objectID": "lezioni/un_py_A.html#liste-e-vettori",
    "href": "lezioni/un_py_A.html#liste-e-vettori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Liste e vettori",
    "text": "Liste e vettori\nUna lista in Python viene definito tramite la funzione [], come nel seguente esempio:\n\nx = [4, 2, 2, 8, 10]\nx\n\n[4, 2, 2, 8, 10]\n\n\n\n\n\n\n\n\nNota\n\n\n\nCon il termine generico “lista” in Python non si fa riferimento alla nozione dell’algebra lineare ma semplicemente ad una stringa di valori ordinati.\n\n\nIl seguente oggetto è una lista in Python, nonostante l’oggetto x sia composto sia numeri che da lettere\n\nx = [\"A\", \"B\", 2, 8, 10]\nx\n\n['A', 'B', 2, 8, 10]"
  },
  {
    "objectID": "lezioni/un_py_A.html#vettori",
    "href": "lezioni/un_py_A.html#vettori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Vettori",
    "text": "Vettori\nUn vettore in Python viene definito tramite la libreria numpy e salvato in un oggetto di tipo array, come nel seguente esempio:\n\nimport numpy as np\nx = np.array([4, 2, 2, 8, 10])\nx\n\narray([ 4,  2,  2,  8, 10])"
  },
  {
    "objectID": "lezioni/un_py_A.html#creazione-di-vettori",
    "href": "lezioni/un_py_A.html#creazione-di-vettori",
    "title": "R per l’analisi statistica multivariata",
    "section": "Creazione di vettori",
    "text": "Creazione di vettori\nTalvolta è comodo creare dei vettori i cui elementi sono dei numeri consecutivi\n\nx = np.arange(5, 11) # Equivalente a: x = np.array([5, 6, 7, 8, 9, 10])\nx\n\narray([ 5,  6,  7,  8,  9, 10])\n\n\nPer creare una successione di numeri reali si usa il comando linspace:\n\nx = np.linspace(start = 0, stop = 1, num = 20)\nx\n\narray([0.        , 0.05263158, 0.10526316, 0.15789474, 0.21052632,\n       0.26315789, 0.31578947, 0.36842105, 0.42105263, 0.47368421,\n       0.52631579, 0.57894737, 0.63157895, 0.68421053, 0.73684211,\n       0.78947368, 0.84210526, 0.89473684, 0.94736842, 1.        ])\n\n\nPer creare un vettore di valori ripetuti si usa il comando ones:\n\nx = np.repeat(10., 7) # Vettore in cui il numero 10 è ripetuto 7 volte\nx\n\narray([10., 10., 10., 10., 10., 10., 10.])\n\n\n\nx = np.zeros(7) # Vettore in cui il numero 0 è ripetuto 7 volte\nx\n\narray([0., 0., 0., 0., 0., 0., 0.])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sui-vettori-i",
    "href": "lezioni/un_py_A.html#operazioni-sui-vettori-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori I",
    "text": "Operazioni sui vettori I\nLa maggior parte delle funzioni matematiche di numpy sono vettorizzate. In altri termini, le funzioni agiscono su tutti gli elementi di un vettore.\n\nx = np.linspace(0, 4, 10)\nnp.exp(x) + x / 2 + 1 # Esempio 1\n\narray([ 2.        ,  2.78184572,  3.8768699 ,  5.46033456,  7.80558248,\n       11.33892546, 16.72524943, 25.00152607, 37.78504082, 57.59815003])\n\n\n\nx = np.array([10, 10**2, 10**3, 10**4, 10**5, 10**6]) # Esempio 2\nnp.log10(x)\n\narray([1., 2., 3., 4., 5., 6.])\n\n\n\nx = np.linspace(0, 10, 10)\nx > 4 # Esempio 3\n\narray([False, False, False, False,  True,  True,  True,  True,  True,\n        True])\n\n\nAltre funzioni invece sono utili proprio nel caso in cui l’argomento sia un vettore:\n\nx = np.array([2, 3, 1, 3, 10, 5])\nlen(x) # Lunghezza del vettore\n\n6\n\n\n\nnp.sum(x) # Somma degli elementi del vettore\n\n24\n\n\n\nnp.cumsum(x) # Somme cumulate\n\narray([ 2,  5,  6,  9, 19, 24])\n\n\n\n# Una sintassi alternativa\nx.sum()\n\n24\n\n\n\nx.cumsum()\n\narray([ 2,  5,  6,  9, 19, 24])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sui-vettori-ii",
    "href": "lezioni/un_py_A.html#operazioni-sui-vettori-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori II",
    "text": "Operazioni sui vettori II\nUlteriori semplici operazioni in cui l’argomento è un vettore sono elencate nel seguito:\n\nx = np.array([2, 3, 1, 3, 10, 5])\nx.prod()\n\n900\n\n\n\nx.cumprod()\n\narray([  2,   6,   6,  18, 180, 900])\n\n\n\nx.min()\n\n1\n\n\n\nx.argmin() # Posizione del valore corrispondente al minimo\n\n2\n\n\nIl funzionamento delle seguenti funzioni dovrebbero essere intuibile da quanto visto finora:\n\nx.max() # Valore massimo\n\n10\n\n\n\nx.argmax() # Posizione del valore corrispondente al massimo\n\n4\n\n\nPer ordinare un vettore, è possibile usare il comando sort:\n\nnp.sort(x)\n\narray([ 1,  2,  3,  3,  5, 10])\n\n\nAttenzione alla alla differenza con la sua sintassi alternativa:\n\nx.sort()\nx\n\narray([ 1,  2,  3,  3,  5, 10])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sui-vettori-iii",
    "href": "lezioni/un_py_A.html#operazioni-sui-vettori-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sui vettori III",
    "text": "Operazioni sui vettori III\nÈ possibile selezionare gli elementi di un vettore usando le parentesi quadrate, come nei seguenti esempi:\n\n# Concatenazione di vettori\nx = np.concatenate([pi * np.ones(2), np.array([np.sqrt(2), 10, 7])])\nx\n\narray([ 3.14159265,  3.14159265,  1.41421356, 10.        ,  7.        ])\n\n\n\nx[2] # Estrae il terzo elemento dal vettore x, ovvero sqrt(2)\n\n1.4142135623730951\n\n\n\nx[[0, 2, 4]] # Estrae il primo, il terzo ed il quinto elemento\n\narray([3.14159265, 1.41421356, 7.        ])\n\n\n\nnp.delete(x, [0, 2, 4]) # Elimina il primo, il terzo ed il quinto elemento\n\narray([ 3.14159265, 10.        ])\n\n\n\nx[x > 3.5] # Estrae gli elementi maggiori di 3.5\n\narray([10.,  7.])\n\n\nL’ultimo comando suggerisce che gli elementi di un vettore possono essere selezionati tramite una condizione relativa al vettore stesso."
  },
  {
    "objectID": "lezioni/un_py_A.html#grafico-di-una-funzione",
    "href": "lezioni/un_py_A.html#grafico-di-una-funzione",
    "title": "R per l’analisi statistica multivariata",
    "section": "Grafico di una funzione",
    "text": "Grafico di una funzione\nIn Python è possibile disegnare una qualsiasi funzione tramite il comando curve.\nSe ad esempio si considera la funzione \\[f(x) = \\frac{\\sin(x)}{x},\\] allora possiamo disegnare \\(f(x)\\) nell’intervallo \\((0,15)\\) come segue:\n\nimport matplotlib.pyplot as plt\n\nx = np.linspace(1e-15, 15, 200)\ny = np.sin(x) / x\n\nplt.plot(x, y, 'r')\nplt.show()"
  },
  {
    "objectID": "lezioni/un_py_A.html#matrici",
    "href": "lezioni/un_py_A.html#matrici",
    "title": "R per l’analisi statistica multivariata",
    "section": "Matrici",
    "text": "Matrici\nUna matrice \\({\\bf A}\\) è una collezione di elementi \\((a)_{ij}\\) per \\(i=1,\\dots,n\\) e \\(j=1,\\dots,m\\).\nPer esempio, la matrice quadrata di dimensione \\(2 \\times 2\\)\n\\[{\\bf A} = \\begin{pmatrix}\n5 & 2\\\\\n1 & 4 \\\\\n\\end{pmatrix},\\] si può definire in Python tramite il comando matrix come segue:\n\nA = np.array([[5, 2], [1, 4]])\nA\n\narray([[5, 2],\n       [1, 4]])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-i",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-i",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici I",
    "text": "Operazioni sulle matrici I\nÈ possibile selezionare gli elementi di una matrice in maniera analoga a quanto fatto con i vettori.\n\nA[0, 1] # Estrazione di elemento in posizione (1,2)\n\n2\n\n\n\nA[:, 1] # Estrazione seconda colonna\n\narray([2, 4])\n\n\n\nA[0, :] # Estrazione prima riga\n\narray([5, 2])\n\n\nAlcuni comandi di base per manipolare le matrici sono i seguenti\n\nA.shape\n\n(2, 2)\n\n\n\na = A.reshape(4) # Converte la matrice in un vettore\na\n\narray([5, 2, 1, 4])\n\n\n\nA.diagonal() # Restituisce la diagonale della matrice\n\narray([5, 4])\n\n\n\nA.transpose() # Calcola la matrice trasposta A'\n\narray([[5, 1],\n       [2, 4]])\n\n\n\nA.sum() # Somma di tutti gli elementi di A\n\n12"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-ii",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-ii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici II",
    "text": "Operazioni sulle matrici II\nCome per i vettori, le operazioni elementari (somma, prodotto, log, exp, etc.) vengono eseguite elemento per elemento.\n\nnp.exp(A)\n\narray([[148.4131591 ,   7.3890561 ],\n       [  2.71828183,  54.59815003]])\n\n\nSiano \\({\\bf A}\\) e \\({\\bf B}\\) due matrici aventi lo stesso numero di colonne e definiamo\n\\[\n{\\bf C} = \\begin{pmatrix}{\\bf A} \\\\ {\\bf B} \\end{pmatrix}.\n\\]\n\nB = A # Creo una matrice B identica ad A, per semplicità\nC = np.vstack([A, B])\nC\n\narray([[5, 2],\n       [1, 4],\n       [5, 2],\n       [1, 4]])\n\n\nIn maniera analoga, siano \\({\\bf A}\\) e \\({\\bf B}\\) due matrici aventi lo stesso numero di righe e definiamo \\({\\bf C} = \\begin{pmatrix}{\\bf A} & {\\bf B} \\end{pmatrix}\\).\n\nC = np.hstack([A, B])\nC\n\narray([[5, 2, 5, 2],\n       [1, 4, 1, 4]])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-iii",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-iii",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici III",
    "text": "Operazioni sulle matrici III\nSiano \\({\\bf x}\\) e \\({\\bf y}\\) due vettori colonna in \\(\\mathbb{R}^p\\). Allora, il loro è pari a\n\\[\n{\\bf x}^\\intercal {\\bf y} = \\sum_{i=1}^p x_i y_i.\n\\]\nIn Python possiamo usare il comando dot\n\nx = np.array([-4, 2, 6, 10, 22])\ny = np.array([3, 2, 2, 7, 9])\nnp.dot(x, y) # Equivalent a sum(x * y)\n\n272"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-iv",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-iv",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici IV",
    "text": "Operazioni sulle matrici IV\nIn algebra lineare il prodotto tra matrici compatibili \\({\\bf A} {\\bf B}\\) è chiamato prodotto righe per colonne. In Python si usa il comando seguente\n\nA = np.array([[1, 2, 3], [4, 9, 2], [2, 2, 2]])\nB = np.array([[5, 2, 5], [3, 3, 7], [-2, -8, 10]])\n\nnp.matmul(A, B) # Prodotto righe per colonne AB\n\narray([[  5, -16,  49],\n       [ 43,  19, 103],\n       [ 12,  -6,  44]])\n\n\nSe le matrici non sono compatibili Python produce un errore (provateci per esercizio!)\nNota. Il comando A * B indica il prodotto elemento per elemento e non il prodotto righe per colonne.\n\nA * B # Prodotto elemento per elemento\n\narray([[  5,   4,  15],\n       [ 12,  27,  14],\n       [ -4, -16,  20]])"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-v",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-v",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici V",
    "text": "Operazioni sulle matrici V\nSia \\({\\bf A}\\) una matrice quadrata \\(n \\times n\\) a valori reali. La sua matrice inversa \\({\\bf A}^{-1}\\), quando esiste, è l’unica matrice tale per cui\n\\[\n{\\bf A} {\\bf A}^{-1} = {\\bf A}^{-1} {\\bf A} =  I_n.\n\\]\nPer ottenere \\({\\bf A}^{-1}\\) si usa il comando solve.\n\nA = np.array([[1, 2, 3], [4, 9, 2], [2, 2, 2]])\nA1 = np.linalg.inv(A) # Matrice inversa di A\nA1\n\narray([[-0.58333333, -0.08333333,  0.95833333],\n       [ 0.16666667,  0.16666667, -0.41666667],\n       [ 0.41666667, -0.08333333, -0.04166667]])\n\n\n\nnp.around(np.matmul(A, A1), 5) # Operazione di controllo\n\narray([[ 1., -0., -0.],\n       [ 0.,  1.,  0.],\n       [ 0.,  0.,  1.]])\n\n\n\nnp.linalg.det(A) # Calcola il determinante della matrice A\n\n-24.000000000000004"
  },
  {
    "objectID": "lezioni/un_py_A.html#operazioni-sulle-matrici-vi",
    "href": "lezioni/un_py_A.html#operazioni-sulle-matrici-vi",
    "title": "R per l’analisi statistica multivariata",
    "section": "Operazioni sulle matrici VI",
    "text": "Operazioni sulle matrici VI\nNel caso una matrice non sia invertibile, il determinante è pari a \\(0\\). Il comando inv in quel caso produce un errore.\n\n# Esempio di matrice NON invertibile\nA = np.array([[1, 2, 3], [2, 4, 6], [2, 2, 2]])\nnp.linalg.det(A) # Deteminante pari a 0, np.linalg.inv(A) produce un errore\n\n0.0\n\n\nCi sono numerose funzioni per la scomposizione di matrici, il cui output è a volte una lista.\n\nA = np.array([[4, 1], [1, 8]])\nnp.linalg.cholesky(A) # Scomposizione di Cholesky\n\narray([[2.        , 0.        ],\n       [0.5       , 2.78388218]])\n\n\n\nnp.linalg.qr(A) # Scomposizione QR\n\n(array([[-0.9701425 , -0.24253563],\n        [-0.24253563,  0.9701425 ]]),\n array([[-4.12310563, -2.9104275 ],\n        [ 0.        ,  7.51860438]]))\n\n\n\nnp.linalg.eig(A)\n\n(array([3.76393202, 8.23606798]),\n array([[-0.97324899, -0.22975292],\n        [ 0.22975292, -0.97324899]]))"
  },
  {
    "objectID": "lezioni/un_G.html#rappresentazioni-grafiche",
    "href": "lezioni/un_G.html#rappresentazioni-grafiche",
    "title": "R per l’analisi statistica multivariata",
    "section": "Rappresentazioni grafiche",
    "text": "Rappresentazioni grafiche\nÈ possibile rappresentare graficamente i dati di una tabella di contingenza tramite un diagramma a barre, che in R è implementato tramite il comando barplot.\nUna rappresentazione grafica delle frequenze congiunte è pertanto la seguente:\n\nbarplot(tab, beside = TRUE, legend.text = TRUE) # Beside = TRUE \"affianca\" i rettangoli.\n\n\n\n\nSe fossimo interessati a mostrare le frequenze condizionate, possiamo invece usare:\n\nbarplot(prop.table(tab, 2),\n  beside = FALSE,\n  xlab = \"Classe\",\n  legend.text = TRUE\n) # Beside = FALSE \"mette in colonna\" i rettangoli."
  },
  {
    "objectID": "lezioni/un_G.html#qualche-strumento-alternativo",
    "href": "lezioni/un_G.html#qualche-strumento-alternativo",
    "title": "R per l’analisi statistica multivariata",
    "section": "Qualche strumento alternativo",
    "text": "Qualche strumento alternativo\n\nPacchetto ggplot2\n\n\nFlourish\nhttps://flourish.studio"
  },
  {
    "objectID": "lezioni/un_G.html#strumenti-avanzati",
    "href": "lezioni/un_G.html#strumenti-avanzati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Strumenti avanzati",
    "text": "Strumenti avanzati\n\nIl pacchetto ggplot2\nIl cosiddetto R base contiene un’ampia gamma di rappresentazioni grafiche. Ciò nonostante, un pacchetto chiamato ggplot2 ha recentemente acquisito notevole popolarità.\nCarichiamolo anzitutto in memoria\n\nlibrary(ggplot2)\n\nQuindi, il primo grafico mostrato in precedenza si può ottenere con la sintassi:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"dodge\") + \n  theme_bw() + theme(legend.position = \"top\") + \n  scale_fill_brewer(palette = \"Dark2\") + \n  ylab(\"Frequenze assolute\")\n\n\n\n\nMentre il secondo:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"fill\") + \n  theme_bw() + theme(legend.position = \"top\") + \n  scale_fill_brewer(palette = \"Dark2\") + \n  ylab(\"Frequenze relative\")\n\n\n\n\n\n\nGrafici interattivi tramite Flourish\nIn particolar modo nel cosiddetto data journalism, si è diffuso uno strumento per creare grafici interattivi chiamato Flourish. Si veda ad esempio questo recente articolo del sole 24 ore.\nSebbene perfezionabile in moli aspetti, il vantaggio della web-app Flourish è la sua semplicità d’uso e la produzione di grafici esteticamente gradevoli. Un esempio:"
  },
  {
    "objectID": "lezioni/un_G.html#strumenti-grafici-avanzati",
    "href": "lezioni/un_G.html#strumenti-grafici-avanzati",
    "title": "R per l’analisi statistica multivariata",
    "section": "Strumenti grafici avanzati",
    "text": "Strumenti grafici avanzati\n\nIl pacchetto ggplot2\nIl cosiddetto R base contiene un’ampia gamma di rappresentazioni grafiche. Ciò nonostante, un pacchetto chiamato ggplot2 ha recentemente acquisito notevole popolarità.\nCarichiamolo anzitutto in memoria:\n\nlibrary(ggplot2)\n\nQuindi, il primo grafico mostrato in precedenza si può ottenere con la sintassi:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"dodge\") +\n  theme_bw() +\n  theme(legend.position = \"top\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  ylab(\"Frequenze assolute\")\n\n\n\n\nMentre il secondo:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"fill\") +\n  theme_bw() +\n  theme(legend.position = \"top\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  ylab(\"Frequenze relative\")\n\n\n\n\n\n\nGrafici interattivi tramite Flourish\nIn particolar modo nell’ambito del cosiddetto data journalism, si è diffuso uno strumento per creare grafici interattivi chiamato Flourish. Si veda ad esempio questo recente articolo del sole 24 ore.\nSebbene perfezionabile in moli aspetti, il vantaggio della web-app Flourish è la sua semplicità d’uso e la produzione di grafici esteticamente gradevoli. Un esempio:"
  },
  {
    "objectID": "lezioni/un_G.html#strumenti-grafici-avanzati-opzionale",
    "href": "lezioni/un_G.html#strumenti-grafici-avanzati-opzionale",
    "title": "R per l’analisi statistica multivariata",
    "section": "Strumenti grafici avanzati (opzionale)",
    "text": "Strumenti grafici avanzati (opzionale)\n\nIl pacchetto ggplot2\nIl cosiddetto R base contiene un’ampia gamma di rappresentazioni grafiche. Ciò nonostante, un pacchetto chiamato ggplot2 ha recentemente acquisito notevole popolarità.\nCarichiamolo anzitutto in memoria:\n\nlibrary(ggplot2)\n\nQuindi, il primo grafico mostrato in precedenza si può ottenere con la sintassi:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"dodge\") +\n  theme_bw() +\n  theme(legend.position = \"top\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  ylab(\"Frequenze assolute\")\n\n\n\n\nMentre il secondo:\n\nggplot(data = titanic, aes(x = Classe, fill = Salvato)) +\n  geom_bar(position = \"fill\") +\n  theme_bw() +\n  theme(legend.position = \"top\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  ylab(\"Frequenze relative\")\n\n\n\n\n\n\nGrafici interattivi tramite Flourish\nIn particolar modo nell’ambito del cosiddetto data journalism, si è diffuso uno strumento per creare grafici interattivi chiamato Flourish. Si veda ad esempio questo recente articolo del sole 24 ore.\nSebbene perfezionabile in moli aspetti, il vantaggio della web-app Flourish è la sua semplicità d’uso e la produzione di grafici esteticamente gradevoli. Un esempio:"
  }
]