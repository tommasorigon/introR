{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"R per l'analisi statistica multivariata\"\n",
        "subtitle: \"Unità M: proprietà degli stimatori\"\n",
        "author: \"Tommaso Rigon\"\n",
        "institute: \"Università Milano-Bicocca\"\n",
        "editor: visual\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: true\n",
        "editor_options: \n",
        "  chunk_output_type: console\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Argomenti affrontati\n",
        "\n",
        "- Distribuzione di uno stimatore\n",
        "- Distorsione, varianza ed errore quadratico medio\n",
        "\n",
        "::: callout-note\n",
        "#### Nota\n",
        "\n",
        "Gli esercizi **R** associati sono disponibili a [questo link](https://tommasorigon.github.io/introR/exe/es_4.html)\n",
        ":::\n",
        "\n",
        "## Ripasso e notazione I\n",
        "\n",
        "In questa unità discuteremo di **stimatori** e delle loro proprietà. \n",
        "\n",
        "Ricordiamo che, nel caso assolutamente continuo, un **modello statistico** è una collezione di funzioni di densità\n",
        "$$\n",
        "\\mathcal{F} = \\{f(\\cdot; \\theta) : \\theta \\in \\Theta\\},\n",
        "$$\n",
        "indicizzata da un vettori di parametri $\\theta \\in \\Theta$, dove $\\Theta \\subseteq \\mathbb{R}^p$ è lo **spazio parametrico**. \n",
        "\n",
        "Assumiamo inoltre che i dati $y_1,\\dots,y_n$ siano realizzazioni iid di variabili aleatorie $Y_1,\\dots,Y_n$ con legge $f(y; \\theta)$, per un qualche **ignoto** valore del parametro $\\theta$.\n",
        "    \n",
        "Il nostro scopo è stimare l'ignoto valore di $\\theta$ nel miglior modo possibile usando i **dati** osservati $y = (y_1,\\dots,y_n)$.\n",
        "\n",
        "## Ripasso e notazione II\n",
        "\n",
        "Uno **stimatore** $\\hat{\\theta}(Y)$ è una qualsiasi funzione delle variabili aleatorie $Y = (Y_1,\\dots, Y_n)$ che \"si avvicina\" al vero valore di $\\theta$. Lo stimatore è una **variabile aleatoria**. \n",
        "\n",
        "Una **stima** $\\hat{\\theta} = \\hat{\\theta}(y)$ è una qualsiasi funzione dei dati $y = (y_1,\\dots,y_n)$ che ``si avvicina'' al vero valore di~$\\theta$. La stima è la realizzazione di $\\hat{\\theta}(Y)$, perciò è un **numero**.\n",
        "\n",
        "Abbiamo bisogno di **criterio** per stabilire se uno stimatore \"funziona\" o meno. Il sostegno logico e filosofico proviene dal seguente principio (**frequentista**). \n",
        "\n",
        "## Il principio del campionamento ripetuto I (ripasso)\n",
        "\n",
        "Immaginiamo che sia possibile, almeno ipoteticamente, **ripetere l'esperimento** varie volte, ottenendo ogni volta un nuovo campione $y$ e quindi una nuova stima $\\hat{\\theta}$. \n",
        "\n",
        "Di conseguenza, lo stimatore $\\hat{\\theta}(Y)$ è una variabile aleatoria, per la quale possiamo parlare di distribuzione, valore atteso e così via. \n",
        "\n",
        "## Il principio del campionamento ripetuto II (ripasso)\n",
        "\n",
        "Se accettiamo il principio del campionamento ripetuto, valuteremo le bontà della singola stima $\\hat{\\theta}$  sulla base delle **proprietà dello stimatore** $\\hat{\\theta}(Y)$. \n",
        "\n",
        "In altri termini, ci chiediamo come si comporterebbero le varie stime $\\hat{\\theta}$ se potessimo osservare tanti campioni, non solo quello che abbiamo a disposizione.  \n",
        "\n",
        "Ci aspettiamo che **mediamente** la distribuzione di $\\hat{\\theta}(Y)$ sia **concentrata** attorno al vero ed ignoto valore $\\theta$. Ovviamente, questo non è assicurato campione per campione. \n",
        "\n",
        "Una proprietà tipicamente richiesta è che all'aumentare della dimensione del campione $n$, la distribuzione di $\\hat{\\theta}(Y)$ sia **concentrata** attorno a $\\theta$. \n",
        "\n",
        "## Ripasso e notazione III\n",
        "\n",
        "Una prima semplice aspettativa rispetto allo stimatore è che mediamente esso sia corretto o **non distorto**, ovvero\n",
        "    $$\n",
        "    \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\qquad \\theta \\in \\Theta.\n",
        "    $$\n",
        "\n",
        "La **distorsione è infatti definita come la differenza semplice\n",
        "    $$\n",
        "    \\text{bias}\\{\\hat{\\theta}(Y)\\}:= \\mathbb{E}\\{\\hat{\\theta}(Y)\\} - \\theta, \\qquad \\theta \\in \\Theta.\n",
        "    $$\n",
        "\n",
        "Se uno stimatore è non distorto allora ovviamente $\\text{bias}\\{\\hat{\\theta}(Y)\\} = 0$. \n",
        "\n",
        "Un requisito un po' meno stringente è che lo stimatore sia **asintoticamente non distorto**, come è tipicamente la stima di massima verosimiglianza, ovvero\n",
        "$$\n",
        "\\lim_{n \\rightarrow \\infty} \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\qquad \\theta \\in \\Theta,\n",
        "$$\n",
        "dove $n$ è la dimensione campionaria. \n",
        "\n",
        "\n",
        "## Ripasso e notazione IV\n",
        "\n",
        "La non-distorsione (asintotica) è una proprietà auspicabile, ma spesso meno importante dello **errore** o **scarto quadratico medio**. \n",
        "\n",
        "Lo scarto quadratico medio (*mean squared error*) misura la distanza media tra stimatore e vero valore del parametro, ovvero\n",
        "$$\n",
        "    \\text{MSE}\\{\\hat{\\theta}(Y)\\} = \\mathbb{E}\\left\\{\\left[\\hat{\\theta}(Y) - \\theta\\right]^2\\right\\}, \\qquad \\theta \\in \\Theta.\n",
        "$$\n",
        "    \n",
        ":::callout-note\n",
        "#### Esercizio - proprietà\n",
        "\n",
        "Dimostrare che vale la seguente scomposizione:\n",
        "$$\n",
        "\\text{MSE}\\{\\theta(Y)\\} = \\text{var}\\left\\{\\hat{\\theta}(Y)\\right\\} + \\text{bias}\\left\\{\\hat{\\theta}(Y)\\right\\}^2, \\qquad \\theta \\in \\Theta.\n",
        "$$\n",
        "Dedurre che se una stimatore è non-distorto, allora il suo scarto quadratico medio coincide con la varianza dello stimatore. \n",
        ":::\n",
        "\n",
        "## Ripasso e notazione V\n",
        "\n",
        "Uno stimatore si dice **consistente in media quadratica** se\n",
        "$$\n",
        "\\lim_{n \\rightarrow \\infty} \\text{MSE}\\{\\hat{\\theta}(Y)\\} = 0, \\qquad \\theta \\in \\Theta.\n",
        "$$\n",
        "oppure equivalentemente se\n",
        "$$\n",
        "\\lim_{n \\rightarrow \\infty} \\mathbb{E}\\{\\hat{\\theta}(Y)\\} = \\theta, \\quad             \\lim_{n \\rightarrow \\infty} \\text{var}\\{\\hat{\\theta}(Y)\\} = 0, \\qquad \\theta \\in \\Theta.\n",
        "$$\n",
        "    \n",
        "\n",
        "La consistenza in media quadratica implica la **convergenza in probabilità**, per cui scriveremo che\n",
        "$$\n",
        "    \\hat{\\theta}(Y) \\overset{p}{\\longrightarrow} \\theta, \\qquad n \\rightarrow \\infty, \\qquad \\theta \\in \\Theta. \n",
        "$$\n",
        "\n",
        "#### Esercizio \n",
        " \n",
        " Lo studente è invitato a rivedersi la definizione di convergenza in probabilità, le sue proprietà e la sua relazione con la consistenza in media quadratica (in $L^2$).  \n",
        "\n",
        ":::callout-note\n",
        "#### Nota linguistica\n",
        "\n",
        "Il termine \"consistente\" deriva da un'errata traduzione del termine inglese _consistent_. Purtroppo, l'uso del termine è ormai troppo consolidato per porvi rimedio e non resta che subirlo. Lo stesso può dirsi del termine \"stima puntuale\". \n",
        ":::\n",
        "\n",
        "## Inferenza statistica e metodi Monte Carlo\n",
        "\n",
        "Stabiliti i criteri per valutare la bontà di uno stimatore, rimane da capire come utilizzarli in pratica.\n",
        "\n",
        "Nei corsi di Statistica II vengono presentati modelli e stimatori per i quali è possibile calcolare l'MSE analiticamente. Questo capita di rado nelle **applicazioni reali**.  \n",
        "\n",
        "Fortunatamente il metodo **Monte Carlo** che abbiamo visto nell'[unità I](un_I.html) può venire in aiuto in assenza di risultati analitici. \n",
        "\n",
        "Ad esempio, lo scarto quadratico medio è per definizione un valore atteso, che possiamo quindi approssimare tramite **integrazione Monte Carlo**. \n",
        "\n",
        "## Modello gaussiano con varianza nota I\n",
        "\n",
        "Sia $y = (y_1,\\dots,y_n)$ un campione iid da una variabile casuale normale con **media ignota** $\\mu$ e **varianza nota** e pari $\\sigma^2 = 16$, ovvero $Y \\sim \\text{N}(\\mu, 16)$.\n",
        "\n",
        "Il parametro $\\mu$ è **ignoto** e siamo interessati a stimarlo.\n",
        "\n",
        "Uno stima naturale per $\\mu$, che oltretutto coincide con la SMV, è la media aritmetica\n",
        "$$\n",
        "\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n y_i.\n",
        "$$\n",
        "\n",
        "La distribuzione (esatta!) dello stimatore $\\hat{\\mu}(Y)$ è nota ed è pari\n",
        "$$\n",
        "\\hat{\\mu}(Y) \\sim \\text{N}\\left(\\mu, \\frac{16}{n}\\right).\n",
        "$$\n",
        "\n",
        "#### Esercizio\n",
        "\n",
        "Si dimostri che $\\text{MSE}\\{\\hat{\\mu}(Y)\\} = 16 / n$. Se ne deduca che lo stimatore è consistente. \n",
        "\n",
        "## Modello gaussiano con varianza nota II\n",
        "\n",
        "Un secondo possibile stimatore per $\\mu$ è la **mediana** campionaria \\text{Me}.\n",
        "\n",
        "La **distribuzione dello stimatore** $\\text{Me}(Y)$ è ignota. Di conseguenza, anche le relative proprietà sono ignote. \n",
        "\n",
        "La mediana è uno stimatore distorto? Il suo scarto è maggiore o minore di quello della media aritmetica? \n",
        "\n",
        "In assenza di risultati analitici, possiamo provare a fornire una **risposta parziale** tramite Monte Carlo. \n",
        "\n",
        "In altri termini, indagheremo quale stimatore funziona meglio per degli specifici valori di $\\mu$, ad esempio $\\mu = 10$ oppure $\\mu = 15$. \n",
        "\n",
        "## Modello gaussiano con varianza nota III\n",
        "\n",
        "Supponiamo di voler investigare il caso $\\mu = 10$. Supponiamo inoltre che $n = 20$.\n",
        "\n",
        "Cominciamo simulando un singolo campione $y_1,\\dots,y_n$ da una distribuzione $\\text{N}(\\mu, 16)$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(100)\n",
        "n <- 20 # Numerosità campionaria\n",
        "mu <- 10 # Media teorica (solitamente ignota)\n",
        "\n",
        "# Campione y_1,...,y_n\n",
        "y <- rnorm(n, mean = mu, sd = sqrt(16))\n",
        "\n",
        "# Vero valore è mu = 10\n",
        "mean(y) \n",
        "median(y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In questo caso specifico, la mediana si avvicina di più al vero valore della media ($\\mu = 10$). Tuttavia, questo vale per questo **specifico campione**.\n",
        "\n",
        "## Modello gaussiano con varianza nota IV\n",
        "\n",
        "Coerentemente con quanto discusso nei paragrafi precedenti, un modo preciso per valutare la bontà dello stimatore si basa sul **campionamento ripetuto**.\n",
        "\n",
        "In altri termini, vogliamo confrontare gli **scarti quadratici medi** dei due stimatori\n",
        "$$\n",
        "\\text{MSE}\\{\\hat{\\mu}(Y)\\}, \\qquad \\text{MSE}\\{\\text{Me}(Y)\\}. \n",
        "$$\n",
        "\n",
        "Nel caso della media aritmetica con $\\sigma^2 = 16$ ed $n = 20$ i conti analitici implicano che $\\text{MSE}\\{\\hat{\\mu}(Y)\\} = 16 / 20 = 0.8$. Ma nel caso della mediana?\n",
        "\n",
        "Utilizzando il metodo Monte Carlo, ottengo una **stima** dello scarto quadratico medio dello **stimatore** mediana, ovvero\n",
        "$$\n",
        "\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}}.\n",
        "$$\n",
        "\n",
        "#### Esercizio\n",
        "\n",
        "Lo studente rilegga questa frase fino a convincersi della sua correttezza. \n",
        "\n",
        "## Modello gaussiano con varianza nota V\n",
        "\n",
        "L'approssimazione $\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}}$ si basa sul metodo di integrazione Monte Carlo. \n",
        "\n",
        "Si supponga che $\\text{Me}_1, \\dots, \\text{Me}_R$ siano $R$ estrazioni casuali della mediana calcolata su un campione iid gaussiano ($\\mu = 10$, $\\sigma^2 = 16$) di dimensione $n = 20$. \n",
        "\n",
        "Possiamo ottenere $\\text{Me}_1, \\dots, \\text{Me}_R$ simulando $R$ campioni $Y$ e calcolandone la mediana: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(156)\n",
        "R <- 10^5\n",
        "# Ottengo R estrazioni della mediana campionaria Me_1,...Me_R\n",
        "median_hat <- replicate(R, median(rnorm(n = n, mean = mu, sd = sqrt(16))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'**approssimazione Monte Carlo** è quindi pari a\n",
        "$$\n",
        "\\widehat{\\text{MSE}\\{\\text{Me}(Y)\\}} = \\frac{1}{R}\\sum_{r=1}^R(\\text{Me}_r - \\mu)^2 \\approx \\mathbb{E}\\{ (\\text{Me}(Y) - \\mu)^2\\} = \\text{MSE}\\{\\text{Me}(Y)\\}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mean((median_hat - mu)^2) # Stima dello scarto quadratico medio (MSE) della mediana"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modello gaussiano con varianza nota VI\n",
        "\n",
        "La mediana sembra essere **meno efficiente** della media aritmetica, quantomeno se $\\mu = 10, \\sigma^2 =16$ ed $n = 20$. \n",
        "\n",
        "Nel seguito sono riportati alcuni risultati aggiuntivi, incluse le stime Monte Carlo relative alla media aritmetica. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(156)\n",
        "R <- 10^5\n",
        "\n",
        "mu_hat <- replicate(R, mean(rnorm(n = n, mean = mu, sd = sqrt(16))))\n",
        "median_hat <- replicate(R, median(rnorm(n = n, mean = mu, sd = sqrt(16))))\n",
        "\n",
        "mean(mu_hat) - mu # Distorsione dello stimatore; valore teorico: 0\n",
        "mean((mu_hat - mu)^2) # Scarto quadratico medio dello stimatore; valore teorico: 0.8\n",
        "\n",
        "mean(median_hat) - mu # Distorsione dello stimatore; valore teorico: ??\n",
        "mean((median_hat - mu)^2) # Scarto quadratico medio dello stimatore; valore teorico: ??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribuzione degli stimatori"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "par(mfrow = c(1, 2))\n",
        "hist(mu_hat, breaks = 100, freq = F)\n",
        "hist(median_hat, breaks = 100, freq = F)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Commenti conclusivi\n",
        "\n",
        "Le approssimazioni coinvolte in questa ultima discussione sono di due **differenti tipologie**.\n",
        "\n",
        "Da un lato abbiamo la **variabilità** di $\\hat{\\theta}$, che è legata ai dati $y_1,\\dots,y_n$ e alla loro numerosità campionaria $n$. \n",
        "\n",
        "Dall'altro abbiamo la **variabilità Monte Carlo** di $\\widehat{\\text{MSE}\\{\\theta(Y)\\}}$, che è invece legata alle repliche Monte Carlo e al numero di simulazioni $R$. \n",
        "\n",
        "Questi due concetti sono ben distinti e non vanno confusi tra loro. \n",
        "\n",
        "Inoltre, mentre aumentare il numero di simulazioni $R$ è sempre possibile (basta aspettare più tempo), non sempre disponiamo di dati aggiuntivi. \n",
        "\n",
        "## Esercizio riassuntivo\n",
        "\n",
        "Si supponga che $Y_1,\\dots,Y_n$ sono variabili aleatorie iid distribuite come un normale di media nota $\\mathbb{E}(Y_1) = 0$, con $n = 20$. \n",
        "\n",
        "La varianza $\\sigma^2$ è **ignota** e siamo interessati a stimarla.\n",
        "\n",
        "Si calcolino tramite simulazione la **distorsione** e l'**errore quadratico** dei seguenti stimatori della varianza, quando $\\sigma^2 = 16$:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    &S^2_1 = \\frac{1}{n}\\sum_{i=1}^n(Y_i - \\bar{Y})^2, &&\\quad S^2_2 = \\frac{1}{n -1}\\sum_{i=1}^n(Y_i - \\bar{Y})^2, \\\\\n",
        "    &S^2_3 = \\frac{1}{n}\\sum_{i=1}^nY_i^2, && \\quad S_4 = \\frac{1}{n+1}\\sum_{i=1}^n(Y_i - \\bar{Y})^2.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "#### Schema della soluzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(520)\n",
        "R <- 10^5; n <- 20\n",
        "mu <- 0; sigma2 <- 16\n",
        "\n",
        "# Definisco le funzioni che calcolano gli stimatori\n",
        "var1 <- function(x) mean(x^2) - mean(x)^2\n",
        "var2 <- function(x) var(x) # Coincide con la definizione di R\n",
        "var3 <- function(x) mean(x^2)\n",
        "var4 <- function(x) (length(x) - 1) / (length(x) + 1) * var(x)\n",
        "\n",
        "# Esecuzione della simulazione\n",
        "S2_1 <- replicate(R, var1(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\n",
        "S2_2 <- replicate(R, var2(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\n",
        "S2_3 <- replicate(R, var3(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\n",
        "S2_4 <- replicate(R, var4(rnorm(n = n, mean = mu, sd = sqrt(sigma2))))\n",
        "\n",
        "# Distorsioni (approssimate)\n",
        "round(mean(S2_1 - sigma2), 2)\n",
        "round(mean(S2_2 - sigma2), 2)\n",
        "round(mean(S2_3 - sigma2), 2)\n",
        "round(mean(S2_4 - sigma2), 2)\n",
        "\n",
        "# Errore quadratico medio (approssimato)\n",
        "mean((S2_1 - sigma2)^2)\n",
        "mean((S2_2 - sigma2)^2)\n",
        "mean((S2_3 - sigma2)^2)\n",
        "mean((S2_4 - sigma2)^2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consistenza I\n",
        "\n",
        "Sia $y_1,\\dots,y_n$ un campione iid da una distribuzione uniforme in $(0,\\theta)$, dove $\\theta > 0$ è un parametro ignoto. La stima di massima verosimiglianza in questo caso è pari a\n",
        "$$\n",
        "\\hat{\\theta}_n = \\max\\{X_1,\\dots,X_n\\}.\n",
        "$$\n",
        "\n",
        "Vogliamo verificare tramite simulazione se lo stimatore è **consistente**, ovvero se\n",
        "$$\n",
        "\\hat{\\theta}(Y) \\overset{p}{\\longrightarrow} \\theta.\n",
        "$$\n",
        "\n",
        "In pratica, ciò che possiamo fare è simulare alcuni valori di $\\hat{\\theta}$ per valori di $n$ crescenti e controllare se questi si avvicinano sempre più a $\\theta$. \n",
        "\n",
        "## Consistenza II\n",
        "\n",
        "Supponiamo che il **vero valore** del parametro sia $\\theta = 40$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "theta0 <- 40\n",
        "\n",
        "# Numerosità campionarie\n",
        "nn <- c(10, 100, 300, 500, 1000)\n",
        "\n",
        "# Stime di massima verosimiglianza\n",
        "set.seed(123)\n",
        "theta_hat <- c(\n",
        "  max(runif(nn[1], min = 0, max = theta0)),\n",
        "  max(runif(nn[2], min = 0, max = theta0)),\n",
        "  max(runif(nn[3], min = 0, max = theta0)),\n",
        "  max(runif(nn[4], min = 0, max = theta0)),\n",
        "  max(runif(nn[5], min = 0, max = theta0))\n",
        ")\n",
        "theta_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All'aumentare di $n$, lo stimatore **tende** a diventare sempre più preciso. Per valori di $n$ ancora maggiori di $1000$, la precisione aumenta ulteriormente. \n",
        "\n",
        "## Consistenza III"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "par(mfrow=c(1,1))\n",
        "plot(nn, theta_hat,\n",
        "  type = \"b\",\n",
        "  xlab = \"Numerosità campionaria\",\n",
        "  ylab = \"Massima verosimiglianza\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "language": "R",
      "display_name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}