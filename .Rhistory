1.3
sort(d_cop)
which.min(d_cop)
which.max(d_cop)
# la pi? vicina ? Hook of Holland
# la pi? lontana ? Atene
1.4
sort(D, decreasing=FALSE)
sort(D, decreasing=TRUE)
1.5
sum <- 0
for (i in 1:21) {
for (j in 1:21) {
sum <- sum + D[i,j]
}
}
media <- sum/(21*21-21)
media
varcitta1 <- 0
for (i in 1:n) {
for (j in 1:n) {
varcitta1 <- varcitta1 + (D[i,j])^2
}
}
varcitta <- varcitta1/(2*(n)^2)
n <- 21
for (i in 1:n) {
for (j in 1:n) {
varcitta1 <- varcitta1 + (D[i,j])^2
}
}
varcitta <- varcitta1/(2*(n)^2)
varcitta
H <- function(n, alpha) {
sum(1/(1:n)^alpha)
}
H(10,1) # vale 2.928968
dzipf <- function(k,n,alpha) {
(k^(-alpha))/(H(n,alpha))
}
dzipf(5,10,2) # vale 0.02581032
curve(dzipf(x,50,1), type="h")
p <- 1-(sum(dzipf(1:9,100,2)))
rzipf1 <- function(n,alpha) {
sample(dzipf(1:n,n,alpha))
}
rzipf <- function(R,n,alpha) {
replicate(R,rzipf1(n,alpha))
}
T1 <- function(x) {
exp(-mean(x))
}
T2 <- function(x){
mean(x == 0)
}
lambda <- 3
nn <- c(100,200,400,1000)
set.seed(100)
plot(T1(rpois(nn[1], lambda)),nn[1])
plot(T1(rpois(nn[2], lambda)),nn[2], add=TRUE)
plot(T1(rpois(nn[3], lambda)),nn[3], add=TRUE)
plot(T1(rpois(nn[4], lambda)),nn[4], add=TRUE)
T1 <- function(x) {
exp(-mean(x))
}
T2 <- function(x){
mean(x == 0)
}
lambda <- 3
nn <- c(100,200,400,1000)
set.seed(100)
plot(T1(rpois(nn[1], lambda)),nn[1])
plot(T1(rpois(nn[2], lambda)),nn[2], add=TRUE)
plot(T1(rpois(nn[3], lambda)),nn[3], add=TRUE)
plot(T1(rpois(nn[4], lambda)),nn[4], add=TRUE)
plot(T2(rpois(nn[1], lambda)),nn[1])
plot(T2(rpois(nn[2], lambda)),nn[2], add=TRUE)
plot(T2(rpois(nn[3], lambda)),nn[3], add=TRUE)
plot(T2(rpois(nn[4], lambda)),nn[4], add=TRUE)
phi0 <- dpois(0,lambda)
3.2
set.seed(100)
n2 <- 20
sim <- replicate(R, rpois(n2,lambda))
mean(T1(sim)-phi0) # vale circa 0
mean(T2(sim)-phi0) # vale circa 0
3.3
mean((T2(sim)-phi0)^2) # vale circa 2
mean((T1(sim)-phi0)^2) # vale circa 10
data(eurodist)
n <- 21
D <- as.matrix(eurodist)
is.numeric(D)
#a
D_sub <- subset(D, select = c (Milan, Paris, Rome)) #dovrei selezionare anche le righe
#b
d_cop <- subset(D, Copenhagen > 0, select = (Copenhagen))
d_cop <- d_cop[-Copenhagen]
data(eurodist)
n <- 21
D <- as.matrix(eurodist)
is.numeric(D)
#a
D_sub <- subset(D, select = c (Milan, Paris, Rome)) #dovrei selezionare anche le righe
#b
d_cop <- subset(D, Copenhagen > 0, select = (Copenhagen))
d_cop <- d_cop[-Copenhagen]
#c
d_cop_sort <- sort(d_cop)
d_cop[which.max(d_cop)] #distanza tra Copenhagen e la citt? ad essa pi? distante = 3276
d_cop[which.min(d_cop)] #il minimo risulta 0 che per? non va considerato essendo la distanza di Copenhagen con se stessa.
summary(d_cop) #altro modo per ottenere questi valori
#d
sort()
head()
tail()
#e
D_mod <- subset(D, subset = Athens:Vienna > 0)
mean(D_mod)
#a
H <- function (n, alpha){
sum( 1/ ( (1:n)^alpha ) )
}
H(10, 1) #2.928968
#b
dzpif <- function (k, n, alpha){
( k^(-alpha) ) / H(n, alpha)
}
dzpif(5, 10, 2) #0.02581032
#c
n <- 50
alpha <- 1
plot(dzpif(1:n, n, alpha), type="h")
#d
n <- 100
alpha <- 2
sum( dzpif(10:n, n, alpha) ) #0.05823676
#e
rzpif <- function(R, n, alpha){
sample(n, R, replace=TRUE, prob=dzpif)
}
#f
set.seed(123)
R <- 10^5
n <- 50
alpha <- 1
X <- rzpif(R, n, alpha)
mean(X)
#a
lambda0 <- 3
T1 <- function(y){
exp(-mean(y))
}
T2 <- function(y){
mean(y==0)
}
#numerosit? campionarie
nn <- c(300, 500, 1000, 10000, 1000000)
set.seed(123)
lambda_hat1 <- c(
T1(rpois(nn[1], lambda = lambda0)),
T1(rpois(nn[2], lambda = lambda0)),
T1(rpois(nn[3], lambda = lambda0)),
T1(rpois(nn[4], lambda = lambda0)),
T1(rpois(nn[5], lambda = lambda0))
)
lambda_hat1
plot(nn, lambda_hat1,
type = "b",
xlab = "Numerosit? campionaria",
ylab = "Massima verosimiglianza"
)
abline(v=lambda0, col="Deeppink")
#---
set.seed(123)
lambda_hat2 <- c(
T2(rpois(nn[1], lambda = lambda0)),
T2(rpois(nn[2], lambda = lambda0)),
T2(rpois(nn[3], lambda = lambda0)),
T2(rpois(nn[4], lambda = lambda0)),
T2(rpois(nn[5], lambda = lambda0))
)
lambda_hat2
plot(nn, lambda_hat2,
type = "b",
xlab = "Numerosit? campionaria",
ylab = "Massima verosimiglianza"
)
abline(v=lambda0, col="Blue")
#b
set.seed(123)
R <- 10^5
lambda <- 3
n <- 20
mean(lambda_hat1) - lambda0
mean(lambda_hat2) - lambda0
#c
set.seed(123)
R <- 10^5
lambda <- 3
n <- 20
mean((lambda_hat1 - lambda0)^2)
mean((lambda_hat2 - lambda0)^2)
R <- 10^5
n <- 20
T1 <- function(y) {
exp(-mean(y))
}
T2 <- function(y) {
sum(y=0) / n
}
T1_sim <- replicate(R, T1(rpois(n = 20, lambda = 3)))
T2_sim <- replicate(R, T2(rpois(n=20, lambda = 3)))
round(mean(T1_sim - lambda), 2)
round(mean(T2_sim - lambda), 2)
n <- 20
lambda <- 3
mean((T1_sim - lambda)^2)
mean((T2_sim - lambda)^2)
rnorm(100)
esiti <- read.csv("ESITI.csv", sep = ";")
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/introR/esami")
esiti <- read.csv("ESITI.csv", sep = ";")
esiti <- subset(esiti, select=c(Matricola, Esito))
esiti$Esito[esiti$Esito == "31"] <- "30L"
esiti <- esiti[order(esiti$Matricola),]
esiti <- esiti[esiti$Esito != "ASS" & esiti$Esito != "RIT", ]
knitr::kable(esiti,row.names = FALSE, align = c('l', 'l'))
esiti <- read.csv("ESITI.csv", sep = ";")
esiti
esiti <- subset(esiti, select=c(Matricola, Esito))
esiti
esiti$Esito[esiti$Esito == "31"] <- "30L"
esiti <- esiti[order(esiti$Matricola),]
esiti <- esiti[esiti$Esito != "ASS" & esiti$Esito != "RIT", ]
knitr::kable(esiti,row.names = FALSE, align = c('l', 'l'))
#ESERCIZIO 1
#a
data(eurodist)
D<-as.matrix(eurodist)
D
#b
d_cop<-D[7, -7]
d_cop
#b
d_cop<-D[7, -7]
d_cop
#c
citta_ordine<-sort(d_cop, decreasing=F)
citta_ordine
citta_ordine[1]#Hook of Hollland ? la citt? piu vicina a Copenhagen
citta_ordine[20]#Athens ? la citt? pi? lontana
#d
(summary(D))[6,] #dal dataset vediamo che la distanza massima ? associata a Lyons-Athens
a<-matrix(NA)
for (i in nrow(D)){
if(D[i,j]!=0){
a[i,j]<-D[i,j]
}
for(j in ncol(D)){
if(D[i,j]!=0){
a[i,j]<-D[i,j]
}
}
}
#e
n<-21 #numero citt?
N<-21*20 #tutte le possibili combinazioni tra le citt? escluse le combinazioni tra le stesse citt?
dist_media<-sum(D)/N
dist_media
#f
n<-21
somma<-0
for(i in 1:n){
for(j in 1:n){
somma<-somma + D[i,j]^2
}
}
varianza<-somma / (2 * n^2)
varianza
#d
(summary(D))[6,] #dal dataset vediamo che la distanza massima ? associata a Lyons-Athens
a<-matrix(NA)
for (i in nrow(D)){
for(j in ncol(D)){
if(D[i,j]!=0){
a[i,j]<-D[i,j]
}
}
}
#e
n<-21 #numero citt?
N<-21*20 #tutte le possibili combinazioni tra le citt? escluse le combinazioni tra le stesse citt?
dist_media<-sum(D)/N
dist_media
#f
n<-21
somma<-0
for(i in 1:n){
for(j in 1:n){
somma<-somma + D[i,j]^2
}
}
varianza<-somma / (2 * n^2)
varianza
#ESERCIZIO 2
#a
H<-function(n, alpha){
sum(1 / (1:n)^alpha)
}
H(10,1)
#b
dzipf<-function(k, n, alpha){
(k^(-alpha)) / H(n, alpha)
}
dzipf(5,10,2)
#c
n<-50
alpha<-1
curve(dzipf(x, 50, 1), type="h")
#d
n<-100
alpha<-2
sum(dzipf(10:n, 100, 2))
#e
rzipf<-function(R, n, alpha){
sample(1:n, size=R, replace=T, prob=dzipf(1:n, n, alpha) )
}
#f
set.seed(123)
n<-50
alpha<-1
R<-10^5
mean(rzipf(10^5, 50, 1))
#ESERCIZIO 3
rm(list=ls())
T1<-function(y){
exp(-mean(y))
}
T2<-function(x){
mean(x==0)
}
#a
lambda<-3
nn <- c(10, 100, 300, 500, 1000) #numerosit? campionarie
set.seed(123)
lambda_hat <- c(
T1(rpois(nn[1], lambda = lambda)),
T1(rpois(nn[2], lambda = lambda)),
T1(rpois(nn[3], lambda = lambda)),
T1(rpois(nn[4], lambda = lambda)),
T1(rpois(nn[5], lambda = lambda))
)
lambda_hat
par(mfrow=c(1,1))
plot(nn, lambda_hat,
type = "b",
xlab = "Numerosit? campionaria",
ylab = "Massima verosimiglianza"
)
set.seed(123)
lambda_hat2 <- c(
T2(rpois(nn[1], lambda = lambda)),
T2(rpois(nn[2], lambda = lambda)),
T2(rpois(nn[3], lambda = lambda)),
T2(rpois(nn[4], lambda = lambda)),
T2(rpois(nn[5], lambda = lambda))
)
lambda_hat2
par(mfrow=c(1,1))
plot(nn, lambda_hat2,
type = "b",
xlab = "Numerosit? campionaria",
ylab = "Massima verosimiglianza"
)
#b
lambda<-3
set.seed(123)
R<-10^5
n<-20 #numerosit? campionaria
#esecuzione della simulazione
S2.1<-replicate(R, T1(rpois(n = n, lambda=lambda)))
S2.2<-replicate(R, T2(rpois(n=n, lambda=lambda)))
#distorsioni
mean(S2.1-rpois(0,lambda))
mean(S2.2-rpois(0, lambda))
#distorsioni
mean(S2.1-dpois(0,lambda))
mean(S2.2-dpois(0, lambda))
#c
lambda<-3
set.seed(123)
R<-10^5
n<-20
mean((S2.1-dpois(0, lambda))^2)
mean((S2.2-dpois(0, lambda))^2)
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
sum(exp(-1) * 1/(factorial(0:k)))
sum(exp(-1) * 1/(factorial(0:100)))
sum(exp(-1) * (0:100)/(factorial(0:100)))
sum(exp(-1) * (0:100)^2/(factorial(0:100)))
exp(-1) * (0:100)^2/(factorial(0:100))
integrate(function(x) exp(x) / (1 + exp(x))^2, 0, 2)
plogis(2) - plogis(0)
library(ISLR2)
library(ISLR)
MASS::Cars93
MASS::mcycle
plot(MASS::mcycle
)
? mcycle
data("auto")
data("mpg")
library(tidyverse)
data("auto")
data("mpg")
mpg
# echo: TRUE
library(tidyverse)
mpg <- data.frame(mpg) # Conversione da tibble a data.frame
# echo: TRUE
library(tidyverse)
mpg <- data.frame(mpg) # Conversione da tibble a data.frame
# echo: TRUE
library(tidyverse)
mpg <- data.frame(mpg) # Conversione da tibble a data.frame
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
? mpg
str(mpg)
mpg$trans
## exams ----------------------------------------------------------------------------
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/University/Didattica/Laboratorio Statistica/ESAMI/ASM_R_19_07_2023")
## load package
library("exams")
## PRELIMINARY QUESTIONS FOR THE EXAMS
Exam <- c(
"ES_1.Rmd",
"ES_2.Rmd",
"ES_3.Rmd"
)
exams2pdf(Exam,
name = "ASM_R_19_07_2023", dir = "output",
edir = "exercises", template = "templates/plain.tex"
)
