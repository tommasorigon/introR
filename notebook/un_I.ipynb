{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"R per l'analisi statistica multivariata\"\n",
        "subtitle: \"Unità I: metodi Monte Carlo\"\n",
        "author: \"Tommaso Rigon\"\n",
        "institute: \"Università Milano-Bicocca\"\n",
        "editor: visual\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: true\n",
        "editor_options: \n",
        "  chunk_output_type: console\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Argomenti affrontati\n",
        "\n",
        "-   Metodi Monte Carlo\n",
        "-   Approssimazione di un evento tramite Monte Carlo\n",
        "-   Integrazione Monte Carlo\n",
        "-   Istogrammi & densità\n",
        "\n",
        "::: callout-note\n",
        "## Nota\n",
        "\n",
        "Gli esercizi **R** associati sono disponibili a [questo link](https://tommasorigon.github.io/introR/exe/es_3.html)\n",
        ":::\n",
        "\n",
        "## I metodi Monte Carlo\n",
        "\n",
        "Nell'[unità H](un_H.html) abbiamo dedicato moltissime energie per cercare di capire come **simulare** dei valori (pseudo) casuali da variabili aleatorie continue e discrete.\n",
        "\n",
        "Ciò che tuttavia non abbiamo spiegato è l'**utilità** di queste tecniche.\n",
        "\n",
        "Il motivo è semplice: le **possibili applicazioni** sono talmente numerose che è necessario introdurle separatamente in questa lezione... e probabilmente scalfiremo solamente la superficie.\n",
        "\n",
        "::: callout-important\n",
        "## Metodo Monte Carlo\n",
        "\n",
        "Definiamo metodo Monte Carlo una qualsiasi procedura che coinvolga l'utilizzo di **numeri (pseudo) casuali**.\n",
        ":::\n",
        "\n",
        "## Alcuni cenni storici\n",
        "\n",
        "I metodi Monte Carlo hanno una lunga storia; alcuni di essi sono stati usati perfino **prima dell'invenzione dei computer**.\n",
        "\n",
        "I primi utilizzi moderni, ovvero basati su numeri pseudo-casuali, sono stati condotti (tra gli altri) da Enrico Fermi, Nicholas Metropolis, Richard Feynman e John von Neumann tra gli anni '30 e '40.\n",
        "\n",
        "Il neonato metodo Monte Carlo aveva quindi delle importanti applicazioni in **fisica**. In particolare, importanti passi avanti furono fatti all'interno del **progetto Manhattan**.\n",
        "\n",
        "L'**algoritmo di Metropolis**, sviluppato in quegli anni, è tutt'oggi ampiamente usato. Purtroppo è prematuro presentarlo in questo corso: lo vederete più avanti!\n",
        "\n",
        "### Approfondimento\n",
        "\n",
        "-   Hitchcock (2003). A history of the Metropolis-Hastings algorithm. *The American Statistician* **57**(4), 254--257.\n",
        "\n",
        "## \"The Monte Carlo Method\"\n",
        "\n",
        "![](img/paper.png)\n",
        "\n",
        "## Possibili applicazioni\n",
        "\n",
        "I metodi Monte Carlo hanno applicazioni in tutte le discipline scientifiche, incluse la fisica, biologia, medicina, genetica, informatica, matematica.\n",
        "\n",
        "Per ovvie ragioni, noi approfondiremo le applicazioni legate alla **probabilità** e alla **statistica**. Alcuni esempi sono riportati nel seguito.\n",
        "\n",
        "Il metodo **bootstrap** tramite Monte Carlo è valso il \"Nobel per la Statistica\" a Brad Efron nel 2019. Link: <https://en.wikipedia.org/wiki/International_Prize_in_Statistics>.\n",
        "\n",
        "La **statistica bayesiana** moderna fa uso intensivo dei metodi Monte Carlo.\n",
        "\n",
        "Concetti chiave di **data mining & machine learning**, come la suddivisione in insieme di stima & verifica o la convalida incrociata, sono per definizione basati sulla simulazione di numeri casuali.\n",
        "\n",
        "Infine, grazie alla simulazione è possibile verificare la validità dei risultati \"asintotici\" che vengono presentati nei corsi di **inferenza statistica**.\n",
        "\n",
        "## Approssimazione di una probabilità\n",
        "\n",
        "Si supponga di voler calcolare una determinata probabilità $\\pi$ di un certo **esperimento casuale**. Definiamo una variabile aleatoria di bernoulli $Z$ tale che $$\n",
        "\\pi = \\mathbb{P}(Z = 1),\n",
        "$$\n",
        "\n",
        "ovvero un **indicatore binario** che denota se l'evento si è verificato o meno.\n",
        "\n",
        "In molti casi è **difficile** se non praticamente impossibile calcolare $\\pi$ analiticamente.\n",
        "\n",
        "#### Esempio 1\n",
        "\n",
        "Si supponga che $X \\sim \\text{N}(0,1)$ e si ponga $Y = \\cos(X)$. Il calcolo di $$\n",
        "\\pi = \\mathbb{P}(Y > 0) = \\mathbb{P}\\{\\cos(X) > 0\\},\n",
        "$$ non è affatto semplice usando solo \"carta e penna\": provateci, se volete.\n",
        "\n",
        "#### Esempio 2\n",
        "\n",
        "La probabilità di vittoria della tombola $\\pi$ si potrebbe calcolare \"carta e penna\", ma questa operazione sarebbe lunga e faticosa.\n",
        "\n",
        "## Approssimazione di una probabilità\n",
        "\n",
        "Il metodo Monte Carlo prevede di **simulare** tante volte l'esperimento casuale in questione e contare la frazione di volte che l'evento si è verificato (ovvero $Z = 1$).\n",
        "\n",
        "In altri termini, consideriamo delle variabili aleatorie binarie iid $Z_1,\\dots,Z_R$ aventi probabilità $\\pi$. La probabilità $\\pi$ viene stimata tramite la frazione di successi.\n",
        "\n",
        "Il metodo Monte Carlo è di estrema utilità perché permette di **approssimare** una determinata **probabilità** senza fare alcun conto analitico.\n",
        "\n",
        "::: callout-note\n",
        "## Nota\n",
        "\n",
        "Il punto cruciale è che spesso è possibile simulare un esperimento casuale senza conoscere $\\pi$, che infatti è la probabilità che siamo interessati ad approssimare.\n",
        ":::\n",
        "\n",
        "#### Esempio\n",
        "\n",
        "Si supponga nuovamente che $X \\sim \\text{N}(0,1)$ e si ponga $Y = \\cos(X)$. Siamo interessati a calcolare la probabilità: $$\n",
        "    \\pi =\\mathbb{P}(Y > 0) = \\mathbb{P}\\{\\cos(X) > 0\\}.\n",
        "$$\n",
        "\n",
        "Definiamo quindi la **variabile binaria** $$\n",
        "Z = \\mathbb{1}(Y > 0) = \\mathbb{1}\\{\\cos(X) > 0\\},\n",
        "$$ ovvero una variabile aleatoria bernoulliana che vale $1$ se $\\cos(X) > 0$ e vale $0$ altrimenti.\n",
        "\n",
        "É facile verificare (fatelo per esercizio!) che $$\n",
        "\\pi = \\mathbb{P}(Z = 1) = \\mathbb{P}(Y > 0). \n",
        "$$\n",
        "\n",
        "::: callout-note\n",
        "## Risultato chiave\n",
        "\n",
        "Simulare delle copie iid dalla legge di $Z$ è molto semplice, nonostante la probabilità $\\pi$ sia ignota.\n",
        ":::\n",
        "\n",
        "#### Esempio (continua)\n",
        "\n",
        "Per **approssimare** la probabilità $\\pi = \\mathbb{P}(Z = 1) = \\mathbb{P}\\{\\cos(X) > 0\\}$ dobbiamo quindi generare tante copie iid da questa legge, ovvero $Z_1,\\dots,Z_R$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "R <- 5000 # Numero di repliche\n",
        "\n",
        "set.seed(123)\n",
        "X <- rnorm(R, 0, 1) # Ottengo R copie da una distribuzione gaussiana\n",
        "Y <- cos(X) # Ottengo R copie dalla distribuzione di Y\n",
        "Z <- Y > 0 # Vettore logico che verifica se Y > 0 o meno\n",
        "Z[1:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il numero $R$ rappresenta il numero di **repliche** e determina, come vedremo, la precisione della nostra stima Monte Carlo.\n",
        "\n",
        "A questo punto, l'approssimazione si ottiene considerando la proporzione di successi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prop.table(table(Z)) # Considero la frequenza relativa\n",
        "mean(Z) # Oppure, più semplicemente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Errare è l'unica certezza\n",
        "\n",
        "Come tutte le approssimazioni, anche il metodo Monte Carlo comporta un **errore**.\n",
        "\n",
        "La peculiarità delle **approssimazioni Monte Carlo** è che sono, per definizione, casuali.\n",
        "\n",
        "Questo significa che ogni volta che eseguiamo la procedura otteniamo un valore **leggermente diverso**. Ad esempio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(100) # Imposto un seed diverso da prima\n",
        "Z <- cos(rnorm(R, 0, 1)) > 0 # Calcolo gli indicatori (codice in forma compatta)\n",
        "mean(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per cui sia la **stima** ottenuta che l'**errore** commesso sono **aleatori**!\n",
        "\n",
        "Fortunatamente, questo è un contesto che dovreste conoscere molto bene. La nostra procedura Monte Carlo è infatti, a tutti gli effetti, uno **stimatore** di $\\pi$. \n",
        "\n",
        "## Come mai funziona?\n",
        "\n",
        "Siano $Z_1,\\dots,Z_R$ delle variabili aleatorie binarie indipendenti ed identicamente distribuite, aventi la stessa distribuzione della variabile $Z \\sim \\text{Ber}(\\pi)$. Lo **stimatore** $$\n",
        "\\hat{\\pi} = \\frac{1}{R}\\sum_{r=1}^R Z_r = (\\text{``Proporzione di successi''}),\n",
        "$$ coincide con l'**approssimazione Monte Carlo**.\n",
        "\n",
        "Lo stimatore $\\hat{\\pi}$ ha delle ottime proprietà inferenziali, che si studiano in un qualsiasi corso di **inferenza statistica**; torneremo a parlare di stimatori nell'[unità M](un_M.html).\n",
        "\n",
        "In primo luogo, lo stimatore $\\hat{\\pi}$ è **non distorto**, infatti: $$\n",
        "\\mathbb{E}(\\hat{\\pi}) = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}(Z_r) =  \\frac{1}{R}\\sum_{r=1}^R \\mathbb{P}(Z = 1) =  \\mathbb{P}(Z = 1) = \\pi.\n",
        "$$\n",
        "\n",
        "Inoltre, lo stimatore $\\hat{\\pi}$ è **consistente**, infatti per la legge (forte) dei grandi numeri si ottiene che: $$\n",
        "\\hat{\\pi}  = \\frac{1}{R}\\sum_{r=1}^R Z_r \\overset{\\text{q.c.}}{\\longrightarrow} \\mathbb{P}(Z = 1) = \\pi, \\qquad R \\rightarrow \\infty.\n",
        "$$\n",
        "\n",
        "## La varianza dello stimatore I\n",
        "\n",
        "Possiamo infine calcolare la **varianza** di $\\hat{\\pi}$, che risulta pari alla seguente quantità $$\n",
        "\\begin{aligned}\n",
        "        \\text{var}(\\hat{\\pi}) = \\frac{1}{R^2}\\sum_{r=1}^R\\text{var}(Z_r) = \\frac{1}{R^2}\\sum_{r=1}^R \\pi(1-\\pi) = \\frac{\\pi ( 1- \\pi)}{R}.\n",
        "        \\end{aligned}\n",
        "$$\n",
        "\n",
        "Da questa equazione è evidente il ruolo chiave del numero di repliche $R$.\n",
        "\n",
        "Il numero di **repliche** $R$ si può interpretare come se fosse una sorta di **numerosità campionaria**, che idealmente noi possiamo aumentare a piacere.\n",
        "\n",
        "Un numero di repliche elevato aumenta quindi la **precisione** ma ha un costo in termini di risorse computazionali (= il computer impiega più tempo).\n",
        "\n",
        "::: callout-note\n",
        "## Nota\n",
        "\n",
        "La varianza $\\text{var}(\\hat{\\pi})$ dipende dal valore di $\\pi$, che è ignoto. Per cui una stima della varianza si ottiene rimpiazzando $\\pi$ con la sua stima $\\hat{\\pi}$.\n",
        ":::\n",
        "\n",
        "Vogliamo valutare l'impatto della scelta di $R$ ed implementiamo quindi la funzione `MonteCarlo`, che calcola sia l'approssimazione che la sua **deviazione standard**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MonteCarlo <- function(R) {\n",
        "  Z <- cos(rnorm(R, 0, 1)) > 0\n",
        "  estimate <- mean(Z)\n",
        "  std.error <- sqrt(estimate * (1 - estimate) / R)\n",
        "  out <- c(estimate, std.error)\n",
        "  names(out) <- c(\"estimate\", \"std.error\") # Aggiungo solo per ragioni estetiche\n",
        "  out\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proviamo con alcuni valori diversi di $R$. Si nota un progressivo miglioramento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MonteCarlo(100) # R = 100 conduce a uno std.error elevato\n",
        "MonteCarlo(5000) # R = 5000 conduce a uno std.error ragionevole\n",
        "MonteCarlo(10^6) # R = 10^6 conduce a uno std.error basso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esercizio riassuntivo I\n",
        "\n",
        "Sia $X$ una normale standard. Si approssimi tramite Monte Carlo la probabilità seguente $$\n",
        "\\pi = \\mathbb{P}(1 < X < 2).\n",
        "$$\n",
        "\n",
        "-   Si ottenga quindi una stima Monte Carlo dell'errore commesso. - Si ripeta la procedura per diversi valori del numero di repliche $R$.\n",
        "\n",
        "-   Si confrontino i risultati con il **vero valore** di $\\mathbb{P}(1 < X < 2)$. Le approssimazioni Monte Carlo migliorano al crescere di $R$?\n",
        "\n",
        "-   (Difficile) Si ottenga un intervallo di confidenza per lo stimatore $\\hat{\\pi}$ di livello approssimato $1 - \\alpha = 0.95$.\n",
        "\n",
        "#### Schema della soluzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MonteCarlo <- function(R) {\n",
        "  X <- rnorm(R)\n",
        "  Z <- (X > 1) & (X < 2)\n",
        "  estimate <- mean(Z)\n",
        "  std.error <- sqrt(estimate * (1 - estimate) / R)\n",
        "  out <- c(estimate, std.error)\n",
        "  names(out) <- c(\"estimate\", \"std.error\")\n",
        "  out\n",
        "}\n",
        "\n",
        "# Vero valore\n",
        "pnorm(2) - pnorm(1)\n",
        "\n",
        "MonteCarlo(100) # R = 100 conduce a std.error elevato\n",
        "MonteCarlo(5000) # R = 5000 conduce a std.error ragionevole\n",
        "MonteCarlo(10^6) # R = 10^6 conduce a std.error basso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrazione Monte Carlo I\n",
        "\n",
        "L'idea di approssimare una probabilità tramite simulazione può essere **generalizzata**.\n",
        "\n",
        "In particolare, supponiamo di voler calcolare un generico **integrale** del tipo $$\n",
        "\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\mathbb{E}\\{g(X)\\},\n",
        "$$ dove $f(x)$ è la densità una variabile aleatoria $X$ avente supporto $\\mathcal{X}$.\n",
        "\n",
        "La **probabilità di un evento** è un **caso particolare** di questo contesto. Infatti se $g(x) = \\mathbb{1}(x \\in B)$ si ottiene $$\n",
        "\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\int_B f(x) \\mathrm{d}x = \\mathbb{P}(X \\in B). \n",
        "$$\n",
        "\n",
        "Esattamente come per la probabilità di un evento, vogliamo usare la simulazione per ottenere un'**approssimazione** di $\\mathcal{I}$.\n",
        "\n",
        "## Integrazione Monte Carlo II\n",
        "\n",
        "Sia $X \\sim f(x)$. Per approssimare l'integrale $$\n",
        "\\mathcal{I} = \\int_{\\mathcal{X}} g(x) f(x) \\mathrm{d}x = \\mathbb{E}\\{g(X)\\}\n",
        "$$ si **simulano** dei valori $X_1,\\dots,X_R$ da $f(x)$. Si calcolano quindi i valori $g(X_1),\\dots, g(X_R)$ ed infine si considera la loro **media campionaria**.\n",
        "\n",
        "La stima Monte Carlo $\\hat{\\mathcal{I}}$ è tale che $$\n",
        "\\hat{\\mathcal{I}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r) \\approx \\mathbb{E}\\{g(X)\\} = \\mathcal{I}.\n",
        "$$\n",
        "\n",
        "::: callout-note\n",
        "## Nota\n",
        "\n",
        "Il metodo descritto può essere in realtà usato per approssimare un qualsiasi valore atteso $\\mathbb{E}\\{g(X)\\}$, anche quando la variabile aleatoria $X$ è **discreta**.\n",
        ":::\n",
        "\n",
        "#### Esempio\n",
        "\n",
        "Supponiamo di voler calcolare il valore del seguente integrale $$\n",
        "\\mathcal{I} = \\int_0^1[\\cos(50x) + \\sin(20x)]^2\\mathrm{d}x. \n",
        "$$\n",
        "\n",
        "Si noti che questo integrale coincide con il valore atteso di una trasformazione di una variabile aleatoria uniforme $U$, ovvero $$\n",
        "\\mathcal{I} = \\mathbb{E}[\\{\\cos(50 U) + \\sin(20 U)\\}^2], \\qquad U \\sim \\text{Unif}(0,1). \n",
        "$$\n",
        "\n",
        "In **R** pertanto possiamo calcolare $\\hat{\\mathcal{I}}$ come segue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "U <- runif(10^6)\n",
        "I_hat <- mean((cos(50 * U) + sin(20 * U))^2)\n",
        "I_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questa funzione in realtà può essere integrata analiticamente: vale che $\\mathcal{I} \\approx 0.965201$. Pertanto, l'approssimazione Monte Carlo sembra essere accurata.\n",
        "\n",
        "Il grafico della funzione integranda nell'intervallo $(0,1)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curve((cos(50 * x) + sin(20 * x))^2, n = 400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Come mai funziona? Procediamo come prima...\n",
        "\n",
        "Siano $X_1,\\dots,X_R$ delle copie iid aventi densità $f(x)$. Consideriamo quindi lo **stimatore** seguente $$\n",
        "\\hat{\\mathcal{I}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r),\n",
        "$$ ovvero l'**approssimazione Monte Carlo** di $\\mathcal{I}$ che abbiamo descritto.\n",
        "\n",
        "Anche in questo caso, otteniamo che $\\hat{\\mathcal{I}}$ è uno stimatore di $\\mathcal{I}$ con ottime proprietà inferenziali.\n",
        "\n",
        "Come in precedenza, lo stimatore \\$\\hat{\\mathcal{I}} \\$ risulta essere **non distorto**, infatti: $$\n",
        "\\mathbb{E}(\\hat{\\mathcal{I}}) = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X_r)\\} =  \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X)\\} =  \\mathbb{E}\\{g(X)\\} = \\mathcal{I}.\n",
        "$$\n",
        "\n",
        "Inoltre, lo stimatore $\\hat{\\mathcal{I}}$ è **consistente**. Infatti per la legge (forte) dei grandi numeri $$\n",
        "\\hat{\\mathcal{I}}  = \\frac{1}{R}\\sum_{r=1}^R \\mathbb{E}\\{g(X_r)\\} \\overset{\\text{q.c.}}{\\longrightarrow} \\mathbb{E}\\{g(X)\\} = \\mathcal{I}, \\qquad R \\rightarrow \\infty.\n",
        "$$\n",
        "\n",
        "## La varianza dello stimatore I\n",
        "\n",
        "Anche in questo caso possiamo calcolare la **varianza** dello stimatore $\\hat{\\mathcal{I}}$: $$\n",
        "\\text{var}(\\hat{\\mathcal{I}}) = \\frac{1}{R^2}\\sum_{r=1}^R\\text{var}\\{g(X_r)\\} = \\frac{1}{R}\\text{var}\\{g(X)\\},\n",
        "$$ con $X \\sim f(x)$.\n",
        "\n",
        "La varianza $\\text{var}\\{g(X)\\}$ è tipicamente ignota, ma può essere stimata utilizzando gli stessi valori usati per stimare $\\mathcal{I}$, ad esempio tramite la **varianza campionaria**: $$\n",
        "    \\widehat{\\text{var}\\{g(X)\\}} = \\frac{1}{R}\\sum_{r=1}^R g(X_r)^2 - \\left(\\frac{1}{R}\\sum_{r=1}^R g(X_r)\\right)^2. \n",
        "$$\n",
        "\n",
        "Come in precedenza, un numero di repliche $R$ elevato aumenta quindi la **precisione** ma ha un **costo computazionale**.\n",
        "\n",
        "## La varianza dello stimatore II\n",
        "\n",
        "L'implementazione in **R** si ottiene come segue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MonteCarlo <- function(R) {\n",
        "  U <- runif(R)\n",
        "  hU <- (cos(50 * U) + sin(20 * U))^2\n",
        "  estimate <- mean(hU)\n",
        "  std.error <- sd(hU) / sqrt(R)\n",
        "  out <- c(estimate, std.error)\n",
        "  names(out) <- c(\"estimate\", \"std.error\") # Aggiungo solo per ragioni estetiche\n",
        "  out\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proviamo con alcuni valori diversi di $R$. Si nota un progressivo miglioramento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MonteCarlo(100) # R = 100 conduce a uno std.error elevato\n",
        "MonteCarlo(5000) # R = 5000 conduce a uno std.error ragionevole\n",
        "MonteCarlo(10^6) # R = 10^6 conduce a uno std.error basso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Istogrammi e densità\n",
        "\n",
        "Supponiamo di simulare delle variabili aleatorie continue $X_1,\\dots, X_R$, aventi una certa **densità** $f(x)$.\n",
        "\n",
        "Se disegniamo l'**istogramma** di tali numeri, intuitivamente ci aspetteremo un'alta densità nell'istogramma in corrispondenza dei valori molto probabili.\n",
        "\n",
        "In realtà, il legame tra istogrammi e densità è molto più stretto. Consideriamo $\\lambda = 1 / R$ (si veda [unità D](un_D.html) per la definizione), ovvero il valore che rende la somma delle aree dei rettangoli pari a $1$.\n",
        "\n",
        "In tale contesto, l'istogramma costituisce un'approssimazione della densità.\n",
        "\n",
        "In termini più precisi, diremo che l'**istogramma** è uno **stimatore** nonparametrico della **densità** $f(x)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X <- rnorm(10^5)\n",
        "hist(X, freq = FALSE, breaks = 100)\n",
        "curve(dnorm(x), add = TRUE) # add = TRUE Aggiunge la curva al grafico precedente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Istogrammi e densità\n",
        "\n",
        "L'idea è approssimare la funzione $f(x)$ con dei **rettangoli**. Quanti più rettangoli consideriamo, tanto più accurata sarà l'approssimazione.\n",
        "\n",
        "Ricordiamo che se $X \\sim f(x)$ allora vale che $$\n",
        "\\mathbb{P}(a < X < b) = \\int_a^bf(x)\\mathrm{d}x.\n",
        "$$\n",
        "\n",
        "Quindi idealmente l'altezza del rettangolo di base $(a, b)$ dev'essere tale che $$\n",
        "(\\text{``Altezza rettangolo''}) = \\frac{\\mathbb{P}(a < X < b)}{b - a},\n",
        "$$ in maniera tale che l'**area del rettangolo** risulti pari a $\\mathbb{P}(a < X < b)$.\n",
        "\n",
        "Le probabilità $\\mathbb{P}(a < X < b)$ sono ulteriormente **approssimate** tramite Monte Carlo e sono poste pari alla proporzioni di valori $X_1,\\dots,X_R$ contenuti nell'intervallo $(a,b)$.\n",
        "\n",
        "## Approssimazione di una distribuzione discreta\n",
        "\n",
        "Un principio simile a visto per istogrammi / densità vale anche nel **caso discreto**.\n",
        "\n",
        "Sia $X$ una variabile aleatoria discreta. In questo contesto, possiamo direttamente approssimare la **funzione di probabilità** $$\n",
        "p(x) = \\mathbb{P}(X = x),\n",
        "$$ utilizzando un metodo Monte Carlo.\n",
        "\n",
        "Supponendo di poter simulare $X_1,\\dots,X_R$. Allora, una stima per $p(x)$ è semplicemente pari alla proporzione di valori pari $x$ che abbiamo ottenuto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X <- rpois(10^5, 10) # Simulazione di R variabili Poisson con media 10\n",
        "freq_rel <- table(X) / sum(X) # Calcolo delle frequenze relative\n",
        "\n",
        "par(mfrow = c(1, 2)) # Grafici\n",
        "plot(freq_rel, ylab = \"P(X = k)\", xlab = \"k\", main = \"Distribuzione empirica\")\n",
        "plot(0:28, dpois(0:28, 10),\n",
        "  type = \"h\", ylab = \"P(X = k)\",\n",
        "  xlab = \"k\", main = \"Distribuzione teorica\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esercizio riassuntivo I\n",
        "\n",
        "Si calcoli tramite Monte Carlo il valore del seguente integrale e se ne quantifichi l'incertezza $$\n",
        "\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty\\sin^2(x)e^{-x^2/2}\\mathrm{d}x. \n",
        "$$\n",
        "\n",
        "Si confronti il risultato con la funzione `integrate`.\n",
        "\n",
        "#### Schema della soluzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X <- rnorm(10^5)\n",
        "hX <- sin(X)^2\n",
        "mean(hX) # Estimate\n",
        "sd(hX) / sqrt(10^5) # Std.error\n",
        "\n",
        "# Integrazione numerica\n",
        "integrate(function(x) sin(x)^2 * dnorm(x), -Inf, Inf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esercizio riassuntivo II\n",
        "\n",
        "Si supponga di voler approssimare tramite Monte Carlo il seguente valore atteso $$\n",
        "\\mathbb{E}(X^2), \\qquad X \\sim \\text{Ga}(3, 3).\n",
        "$$\n",
        "\n",
        "Si dica, motivando la risposta, quale codice produce il risultato corretto.\n",
        "\n",
        "#### Codice 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mean(rgamma(10^5, 3, 3) * rgamma(10^5, 3, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Codice 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X <- rgamma(10^5, 3, 3)\n",
        "mean(X * X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esercizio riassuntivo III\n",
        "\n",
        "Nel seguente video YouTube del canale **Veritasium**, viene introdotto un **enigma** che coinvolge un numero $n = 100$ di prigionieri.\n",
        "\n",
        "Utilizzando la cosiddetta \"*loop strategy*\" che viene descritta nel video, si approssimi tramite Monte Carlo la probabilità di successo dei prigionieri, per $n = 100$.\n",
        "\n",
        "I risultati della simulazione sono coerenti con quanto descritto nel video?\n",
        "\n",
        "{{< video https://www.youtube.com/embed/iSNsgj1OCLA >}}\n",
        "\n",
        "#### Schema della soluzione\n",
        "\n",
        "I numeri nelle scatole (`boxes`), sconosciuti ai prigionieri, vengono generati casualmente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(400)\n",
        "n <- 100 # Numero di prigionieri\n",
        "boxes <- sample(1:n) # Effettua una permutazione dei numeri 1:n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per cui in questo caso (con questo `seed`), nella scatola `51` è contenuto il numero `97`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "boxes[51]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In questa caso, le scatole contengono i numeri seguenti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Controlliamo ora se, tramite la \"*loop strategy*\", i prigionieri riescono ad individuare il loro numero all'interno delle scatole (`boxes`). Partiamo dal primo prigioniero, che verificherà se il suo numero è presente nella prima scatola. In altri termini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "found <- boxes[1] == 1 # TRUE se il PRIMO prigioniero ha trovato il suo numero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se no, il prigionieri controlla anche in tutte le scatole seguenti, ovvero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Loop strategy, per il PRIMO prigioniero\n",
        "found <- FALSE\n",
        "box_checked <- 1 # Il PRIMO prigioniero parte dalla prima scatola\n",
        "for (i in 1:(n / 2)) { # I prigionieri possono fare n / 2 tentativi\n",
        "  if (boxes[box_checked] == 1) {\n",
        "    found <- TRUE\n",
        "  }\n",
        "  box_checked <- boxes[box_checked] # Il numero successivo è pari al numero nella scatola corrente\n",
        "}\n",
        "found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il primo prigioniero ha trovato il suo numero. Ora verifichiamo se **tutti i prigionieri** riescono a fare lo stesso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "found <- rep(FALSE, n) # Vettore di TRUE/FALSE che identifica se i prigionieri hanno trovato il proprio numero.\n",
        "\n",
        "for (j in 1:n) {\n",
        "  box_checked <- j # Il j-esimo prigioniero, parte dalla j-esima scatola\n",
        "  for (i in 1:(n / 2)) {\n",
        "    if (boxes[box_checked] == j) {\n",
        "      found[j] <- TRUE\n",
        "    }\n",
        "    box_checked <- boxes[box_checked]\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alcuni prigionieri riescono a trovare la loro scatola. In questo caso, tuttavia, non tutti individuano il proprio numero. Infatti:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "found\n",
        "all(found) # TRUE solamente se tutti i valori del vettore sono TRUE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mettiamo quindi tutti i pezzi assieme, per poter svolgere la simulazione Monte Carlo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loop_strategy <- function(n) {\n",
        "  boxes <- sample(1:n)\n",
        "  found <- rep(FALSE, n)\n",
        "\n",
        "  for (j in 1:n) {\n",
        "    box_checked <- j\n",
        "    for (i in 1:(n / 2)) {\n",
        "      if (boxes[box_checked] == j) {\n",
        "        found[j] <- TRUE\n",
        "      }\n",
        "      box_checked <- boxes[box_checked]\n",
        "    }\n",
        "  }\n",
        "  all(found)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Effettuo la simulazione, per R = 10000\n",
        "R <- 10000\n",
        "set.seed(200)\n",
        "Z <- replicate(R, loop_strategy(n = 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La probabilità di successo viene quindi approssimata tramite Monte Carlo come fatto in precedenza:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "estimate <- mean(Z) # Stima della probabilità di successo\n",
        "estimate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questa stima coincide, a meno dell'errore Monte Carlo, con quanto discusso nel video.\n",
        "\n",
        "## Esercizi aggiuntivi (non risolti)\n",
        "\n",
        "#### Esercizio 1\n",
        "\n",
        "Si ottenga un'approssimazione Monte Carlo del seguente integrale $$\n",
        "\\int_0^\\infty x^4 e^{-x}\\mathrm{d}x\n",
        "$$ e si quantifichi l'errore commesso. Si confronti il risultato con la funzione `integrate`.\n",
        "\n",
        "#### Esercizio 2\n",
        "\n",
        "Si ottenga un'approssimazione Monte Carlo del seguente integrale $$\n",
        "\\int_0^1 x^{1/2}(1 - x)^{1/2}\\mathrm{d}x\n",
        "$$ e si quantifichi l'errore commesso. Si confronti il risultato con la funzione `integrate`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "language": "R",
      "display_name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}